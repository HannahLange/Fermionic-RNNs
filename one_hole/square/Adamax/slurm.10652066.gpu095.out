1.13.1+cu117
GPU is available
Namespace(Jp=1.0, Jz=1.0, U=1.0, t=3.0, density=1.0, Nx=4, Ny=4, bounds=1, boundsx=0, boundsy=0, load_model=0, sym=0.0, antisym=0.0, hd=50)
4x4_qubits/periodic/Jp=1.0Jz=1.0t=0.0den=1.00/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 30000
rnn.b1: 50
rnn.W2: 30000
rnn.b2: 50
rnn.Wmerge: 5000
lin1.weight: 150
lin1.bias: 3
lin2.weight: 150
lin2.bias: 3
Total number of parameters in the network: 65406
0.0
tensor(9.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 20000/ t/epoch=1.98............. Loss: -1.54291350, mean(E): -0.63715064-0.00119862j, var(E): 1.85819518
0.0
tensor(9.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 20000/ t/epoch=0.35............. Loss: -1.34090169, mean(E): -0.65926782+0.00018731j, var(E): 1.83828827
0.0
tensor(9.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 20000/ t/epoch=0.35............. Loss: -1.52029990, mean(E): -0.81053193-0.03536688j, var(E): 1.62812550
0.0
tensor(9.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 20000/ t/epoch=0.35............. Loss: -3.17288488, mean(E): -2.22206785-0.09881411j, var(E): 2.58183461
0.0
tensor(9.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 20000/ t/epoch=0.35............. Loss: -0.35048742, mean(E): -5.83777752-0.13679366j, var(E): 5.47543052
0.0
tensor(10.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 20000/ t/epoch=0.35............. Loss: -1.02921226, mean(E): -6.62000133-0.09029417j, var(E): 3.15104709
0.0
tensor(10.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 20000/ t/epoch=0.35............. Loss: 1.28036438, mean(E): -7.25425012-0.06749474j, var(E): 6.05408559
0.0
tensor(10.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 20000/ t/epoch=0.35............. Loss: -0.34083950, mean(E): -7.50148328+0.00981946j, var(E): 3.82412768
0.0
tensor(10.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 20000/ t/epoch=0.35............. Loss: 1.60896853, mean(E): -8.12789488-0.14525340j, var(E): 4.85515065
0.0
tensor(10.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 20000/ t/epoch=0.35............. Loss: 2.06334495, mean(E): -8.49686327+0.05403530j, var(E): 5.33853181
0.0
tensor(10.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 20000/ t/epoch=0.35............. Loss: 0.43965713, mean(E): -8.84918899-0.01168688j, var(E): 6.02857513
0.0
tensor(10.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 20000/ t/epoch=0.35............. Loss: 3.22949884, mean(E): -9.46521617-0.17358968j, var(E): 6.94188433
0.0
tensor(10.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 20000/ t/epoch=0.35............. Loss: -0.09188940, mean(E): -9.90783808-0.11217678j, var(E): 7.49123906
0.0
tensor(10.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 20000/ t/epoch=0.35............. Loss: -0.19295131, mean(E): -11.21765891+0.31179633j, var(E): 8.40666159
0.0
tensor(10.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 20000/ t/epoch=0.35............. Loss: -1.88222562, mean(E): -12.08899466-0.02612109j, var(E): 8.40994602
0.0
tensor(10.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 20000/ t/epoch=0.35............. Loss: 3.07799931, mean(E): -12.78594639-0.17920882j, var(E): 7.74585934
0.0
tensor(10.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 20000/ t/epoch=0.35............. Loss: -1.61358693, mean(E): -13.50707456+0.14634964j, var(E): 6.78394454
0.0
tensor(10.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 20000/ t/epoch=0.36............. Loss: 1.78233992, mean(E): -13.89798049-0.07473790j, var(E): 6.71868021
0.0
tensor(10.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 20000/ t/epoch=0.36............. Loss: 2.40321013, mean(E): -14.05449759-0.00942591j, var(E): 5.84614245
0.0
tensor(10.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 20000/ t/epoch=0.35............. Loss: 0.49123092, mean(E): -14.57196949-0.04566386j, var(E): 6.93095559
0.0
tensor(11.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 20000/ t/epoch=0.35............. Loss: 0.18788407, mean(E): -14.31144643-0.08956295j, var(E): 5.72285887
0.0
tensor(11.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 20000/ t/epoch=0.35............. Loss: 0.13516400, mean(E): -14.66946939+0.00259158j, var(E): 5.61995588
0.0
tensor(11.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 20000/ t/epoch=0.36............. Loss: 1.77208694, mean(E): -14.70362434-0.06866483j, var(E): 6.26060976
0.0
tensor(11.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 20000/ t/epoch=0.35............. Loss: 0.41633970, mean(E): -14.88194940+0.10289506j, var(E): 5.63373639
0.0
tensor(11.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 20000/ t/epoch=0.35............. Loss: 1.06161255, mean(E): -14.86944047+0.00425426j, var(E): 5.23504470
0.0
tensor(11.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 20000/ t/epoch=0.36............. Loss: 0.66198000, mean(E): -15.58462635-0.03865759j, var(E): 5.60916119
0.0
tensor(11.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 20000/ t/epoch=0.35............. Loss: 0.17660355, mean(E): -15.76608638-0.05628582j, var(E): 5.90746476
0.0
tensor(11.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 20000/ t/epoch=0.35............. Loss: 2.92282851, mean(E): -16.01490545+0.10451318j, var(E): 6.77473452
0.0
tensor(11.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 20000/ t/epoch=0.35............. Loss: -0.33126816, mean(E): -16.51119574-0.12755639j, var(E): 6.39339752
0.0
tensor(11.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 20000/ t/epoch=0.35............. Loss: 0.40875468, mean(E): -17.29205855+0.13677468j, var(E): 7.07416491
0.0
tensor(11.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 20000/ t/epoch=0.35............. Loss: -0.90003850, mean(E): -17.15584981+0.04920767j, var(E): 6.96794810
0.0
tensor(11.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 20000/ t/epoch=0.35............. Loss: 0.10869876, mean(E): -17.62514972+0.00426962j, var(E): 4.98402069
0.0
tensor(11.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 20000/ t/epoch=0.36............. Loss: -1.56640848, mean(E): -17.41756949+0.01044360j, var(E): 5.32096365
0.0
tensor(11.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 20000/ t/epoch=0.36............. Loss: 0.51636195, mean(E): -17.56689478+0.02189976j, var(E): 5.63815191
0.0
tensor(11.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 20000/ t/epoch=0.36............. Loss: -1.10391823, mean(E): -18.03838065-0.02448978j, var(E): 4.57362099
0.0
tensor(11.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 20000/ t/epoch=0.35............. Loss: 1.34866813, mean(E): -17.96895583-0.07968636j, var(E): 4.83555471
0.0
tensor(11.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 20000/ t/epoch=0.35............. Loss: -0.66189362, mean(E): -17.86219529-0.06341335j, var(E): 3.43288338
0.0
tensor(11.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 20000/ t/epoch=0.36............. Loss: -0.75330497, mean(E): -18.00495819+0.02146495j, var(E): 3.33467815
0.0
tensor(11.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 20000/ t/epoch=0.35............. Loss: 0.92928798, mean(E): -18.05140306-0.09131004j, var(E): 3.55809877
0.0
tensor(11.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 20000/ t/epoch=0.36............. Loss: 0.02773234, mean(E): -18.31136370-0.01935326j, var(E): 3.02220764
0.0
tensor(11.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 20000/ t/epoch=0.36............. Loss: -1.09640798, mean(E): -18.08928657-0.05094812j, var(E): 2.93483663
0.0
tensor(11.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 20000/ t/epoch=0.36............. Loss: 0.99105829, mean(E): -18.08967293-0.01811224j, var(E): 2.90409656
0.0
tensor(11.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 20000/ t/epoch=0.36............. Loss: -0.87629356, mean(E): -18.35814913-0.02116237j, var(E): 4.11066430
0.0
tensor(11.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 20000/ t/epoch=0.36............. Loss: 0.35176850, mean(E): -18.35205435-0.03593601j, var(E): 3.28672428
0.0
tensor(11.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 20000/ t/epoch=0.36............. Loss: 0.00020321, mean(E): -18.29899949+0.02623543j, var(E): 2.52720906
0.0
tensor(11.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 20000/ t/epoch=0.36............. Loss: -1.18300240, mean(E): -18.51936790-0.04717463j, var(E): 2.71378625
0.0
tensor(11.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 20000/ t/epoch=0.36............. Loss: -1.20788898, mean(E): -18.40438444+0.02593632j, var(E): 2.37546884
0.0
tensor(11.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 20000/ t/epoch=0.36............. Loss: 0.35482793, mean(E): -18.37643064-0.03338043j, var(E): 2.07362411
0.0
tensor(11.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 20000/ t/epoch=0.36............. Loss: -0.15284818, mean(E): -18.41456615+0.03698669j, var(E): 3.28352023
0.0
tensor(11.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 20000/ t/epoch=0.36............. Loss: -0.85131449, mean(E): -18.55095621-0.02780236j, var(E): 2.76994978
0.0
tensor(11.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 20000/ t/epoch=0.36............. Loss: -0.03639016, mean(E): -18.40762636+0.00201133j, var(E): 2.17981600
0.0
tensor(11.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 20000/ t/epoch=0.36............. Loss: 0.08342056, mean(E): -18.34243935-0.03172343j, var(E): 2.51251041
0.0
tensor(11.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 20000/ t/epoch=0.36............. Loss: 0.55057451, mean(E): -18.39473548-0.02249329j, var(E): 1.83993809
0.0
tensor(11.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 20000/ t/epoch=0.36............. Loss: 0.21776344, mean(E): -18.59527947+0.00140466j, var(E): 2.38163232
0.0
tensor(11.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 20000/ t/epoch=0.36............. Loss: -1.03813258, mean(E): -18.55421164-0.00140348j, var(E): 2.39741608
0.0
tensor(11.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 20000/ t/epoch=0.36............. Loss: -1.35074536, mean(E): -18.44504743-0.01472725j, var(E): 2.15273903
0.0
tensor(11.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 20000/ t/epoch=0.36............. Loss: -0.75343903, mean(E): -18.62338377+0.03456530j, var(E): 2.25621294
0.0
tensor(11.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 20000/ t/epoch=0.36............. Loss: 0.03037960, mean(E): -18.49615515+0.01065919j, var(E): 2.01396460
0.0
tensor(11.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 20000/ t/epoch=0.36............. Loss: -0.11323737, mean(E): -18.32796427+0.03909548j, var(E): 1.79973455
0.0
tensor(11.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 20000/ t/epoch=0.36............. Loss: -0.44203815, mean(E): -18.49083716-0.01787964j, var(E): 2.20130237
0.0
tensor(11.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 20000/ t/epoch=0.36............. Loss: 1.59786110, mean(E): -18.67834968-0.00957199j, var(E): 2.10608605
0.0
tensor(11.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 20000/ t/epoch=0.36............. Loss: 0.15403067, mean(E): -18.75945365-0.03558206j, var(E): 2.44038862
0.0
tensor(11.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 20000/ t/epoch=0.36............. Loss: -0.27922446, mean(E): -18.55612610-0.02764233j, var(E): 2.71452495
0.0
tensor(11.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 20000/ t/epoch=0.36............. Loss: -0.55882218, mean(E): -18.53006412-0.01365485j, var(E): 2.11926774
0.0
tensor(11.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 20000/ t/epoch=0.36............. Loss: -1.65713569, mean(E): -18.53216387-0.04478276j, var(E): 1.97071994
0.0
tensor(11.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 20000/ t/epoch=0.36............. Loss: -0.19738721, mean(E): -18.67163675-0.02427443j, var(E): 1.85723079
0.0
tensor(11.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 20000/ t/epoch=0.36............. Loss: -0.03901156, mean(E): -18.62248857+0.03271679j, var(E): 1.44003209
0.0
tensor(11.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 20000/ t/epoch=0.36............. Loss: -0.78159788, mean(E): -18.85150761+0.03484095j, var(E): 1.83446496
0.0
tensor(11.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 20000/ t/epoch=0.36............. Loss: 0.47844311, mean(E): -18.64583029-0.00379296j, var(E): 2.24740564
0.0
tensor(11.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 20000/ t/epoch=0.36............. Loss: -0.65877746, mean(E): -18.69182152+0.01797552j, var(E): 1.73275527
0.0
tensor(11.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 20000/ t/epoch=0.36............. Loss: -0.18441336, mean(E): -18.66880797+0.00182458j, var(E): 1.65337652
0.0
tensor(11.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 20000/ t/epoch=0.36............. Loss: 0.19847754, mean(E): -18.66847581+0.04103336j, var(E): 1.35461525
0.0
tensor(11.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 20000/ t/epoch=0.36............. Loss: -0.06217755, mean(E): -18.80704954+0.00139867j, var(E): 1.80957454
0.0
tensor(11.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 20000/ t/epoch=0.36............. Loss: -0.46643075, mean(E): -18.78575763+0.02868191j, var(E): 1.74788401
0.0
tensor(11.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 20000/ t/epoch=0.36............. Loss: 0.09579135, mean(E): -18.55881536+0.04268432j, var(E): 1.40091783
0.0
tensor(11.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 20000/ t/epoch=0.36............. Loss: -0.86042954, mean(E): -18.76580660+0.04187917j, var(E): 1.57394315
0.0
tensor(11.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 20000/ t/epoch=0.36............. Loss: -0.39590730, mean(E): -18.71926574+0.02440358j, var(E): 1.45142115
0.0
tensor(11.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 20000/ t/epoch=0.36............. Loss: -0.35662308, mean(E): -18.68960282-0.01423570j, var(E): 1.30135289
0.0
tensor(11.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 20000/ t/epoch=0.36............. Loss: -0.23482889, mean(E): -18.77841887+0.07233739j, var(E): 1.55284929
0.0
tensor(11.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 20000/ t/epoch=0.36............. Loss: -0.86079647, mean(E): -18.57537717+0.02817042j, var(E): 1.50326388
0.0
tensor(11.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 20000/ t/epoch=0.36............. Loss: -0.20124458, mean(E): -18.65415383-0.00174088j, var(E): 1.54413139
0.0
tensor(11.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 20000/ t/epoch=0.36............. Loss: -0.77709100, mean(E): -18.74544059+0.02387761j, var(E): 1.49200709
0.0
tensor(12.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 20000/ t/epoch=0.36............. Loss: -0.35850884, mean(E): -18.76543211+0.02032489j, var(E): 1.80058660
0.0
tensor(12.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 20000/ t/epoch=0.36............. Loss: -0.20197053, mean(E): -18.73487881+0.01468430j, var(E): 1.25580626
0.0
tensor(12.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 20000/ t/epoch=0.36............. Loss: -0.52269361, mean(E): -18.75054277+0.01843228j, var(E): 1.32189591
0.0
tensor(12.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 20000/ t/epoch=0.36............. Loss: -0.18777955, mean(E): -18.73972122+0.01307779j, var(E): 1.61502773
0.0
tensor(12.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 20000/ t/epoch=0.36............. Loss: 1.04712760, mean(E): -18.76130021+0.03821420j, var(E): 1.22354462
0.0
tensor(12.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 20000/ t/epoch=0.36............. Loss: 0.54203197, mean(E): -18.89436320+0.02640637j, var(E): 1.35570665
0.0
tensor(12.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 20000/ t/epoch=0.36............. Loss: 0.03740803, mean(E): -18.92046907+0.02612685j, var(E): 1.47695336
0.0
tensor(12.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 20000/ t/epoch=0.36............. Loss: -1.20112476, mean(E): -18.80038866-0.03556197j, var(E): 1.35291052
0.0
tensor(12.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 20000/ t/epoch=0.36............. Loss: 0.19736819, mean(E): -18.79200457+0.02201965j, var(E): 1.20961080
0.0
tensor(12.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 20000/ t/epoch=0.36............. Loss: -0.07730540, mean(E): -18.90422639-0.03837190j, var(E): 1.32457479
0.0
tensor(12.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 20000/ t/epoch=0.36............. Loss: 0.00327637, mean(E): -18.86936790+0.02663541j, var(E): 1.53077812
0.0
tensor(12.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 20000/ t/epoch=0.36............. Loss: 0.00808738, mean(E): -18.68688624-0.01051647j, var(E): 1.42311043
0.0
tensor(12.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 20000/ t/epoch=0.36............. Loss: -0.78627688, mean(E): -18.81376015-0.00372635j, var(E): 1.31563256
0.0
tensor(12.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 20000/ t/epoch=0.36............. Loss: -0.96026602, mean(E): -18.80974172+0.02041325j, var(E): 1.46738533
0.0
tensor(12.1105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 20000/ t/epoch=0.36............. Loss: -0.76266910, mean(E): -18.65526588-0.00968202j, var(E): 1.53962837
0.0
tensor(12.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 20000/ t/epoch=0.36............. Loss: 0.73777951, mean(E): -18.83661499+0.03296051j, var(E): 1.32143866
0.0
tensor(12.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 20000/ t/epoch=0.36............. Loss: -0.10339161, mean(E): -18.74801434-0.02718644j, var(E): 1.58086453
0.0
tensor(12.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 20000/ t/epoch=0.36............. Loss: -0.74666917, mean(E): -18.75751257-0.03774276j, var(E): 1.35164075
0.0
tensor(12.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 20000/ t/epoch=0.36............. Loss: 1.18159359, mean(E): -18.69733551-0.01749055j, var(E): 1.15753513
-0.0
tensor(12.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 20000/ t/epoch=0.36............. Loss: 0.09445193, mean(E): -18.83139868+0.00286723j, var(E): 1.18483777
-0.0
tensor(12.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 20000/ t/epoch=0.36............. Loss: -0.46180429, mean(E): -18.82629577-0.02167589j, var(E): 1.18973853
-0.0
tensor(12.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 20000/ t/epoch=0.36............. Loss: -0.82642713, mean(E): -18.70358022+0.01287957j, var(E): 1.35357278
-0.0
tensor(12.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 20000/ t/epoch=0.36............. Loss: -0.42557179, mean(E): -18.83649645-0.03618720j, var(E): 1.27393654
-0.0
tensor(12.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 20000/ t/epoch=0.36............. Loss: -0.34343862, mean(E): -18.85256808+0.00678580j, var(E): 1.37536955
-0.0
tensor(12.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 20000/ t/epoch=0.36............. Loss: -0.10926993, mean(E): -18.87201746+0.00320523j, var(E): 1.01252661
-0.0
tensor(12.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 20000/ t/epoch=0.36............. Loss: 0.51982674, mean(E): -18.89051452+0.04002633j, var(E): 1.17703370
-0.0
tensor(12.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 20000/ t/epoch=0.36............. Loss: -0.05203379, mean(E): -18.81231799-0.02149545j, var(E): 1.03622865
-0.0
tensor(12.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 20000/ t/epoch=0.36............. Loss: -0.37526696, mean(E): -18.88887375-0.02451273j, var(E): 1.07054088
-0.0
tensor(12.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 20000/ t/epoch=0.36............. Loss: 0.35581899, mean(E): -18.74200636-0.02234688j, var(E): 1.31307382
-0.0
tensor(12.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 20000/ t/epoch=0.36............. Loss: -0.56854077, mean(E): -18.87863343+0.01264009j, var(E): 1.22422492
-0.0
tensor(12.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 20000/ t/epoch=0.36............. Loss: -0.56421806, mean(E): -19.02062125+0.00866222j, var(E): 1.33042121
-0.0
tensor(12.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 20000/ t/epoch=0.36............. Loss: -0.60302602, mean(E): -18.92410799-0.01580606j, var(E): 1.05566195
-0.0
tensor(12.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 20000/ t/epoch=0.36............. Loss: 0.10351476, mean(E): -18.85572977-0.00852623j, var(E): 1.28297553
-0.0
tensor(12.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 20000/ t/epoch=0.36............. Loss: -0.17179925, mean(E): -18.85181641-0.02663401j, var(E): 1.48493233
-0.0
tensor(12.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 20000/ t/epoch=0.36............. Loss: -0.06018922, mean(E): -18.80136062-0.00203533j, var(E): 1.12443757
-0.0
tensor(12.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 20000/ t/epoch=0.36............. Loss: -0.04195072, mean(E): -18.84160495-0.01870843j, var(E): 1.18268890
-0.0
tensor(12.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 20000/ t/epoch=0.36............. Loss: -0.69463820, mean(E): -18.89558220+0.00547518j, var(E): 1.14995116
-0.0
tensor(12.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 20000/ t/epoch=0.36............. Loss: -0.82403433, mean(E): -18.77332096+0.01960644j, var(E): 1.17225631
-0.0
tensor(12.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 20000/ t/epoch=0.36............. Loss: -0.48098392, mean(E): -18.83305265+0.04511335j, var(E): 1.14846768
-0.0
tensor(12.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 20000/ t/epoch=0.36............. Loss: -1.16852927, mean(E): -18.88353874-0.01166096j, var(E): 0.99828764
-0.0
tensor(12.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 20000/ t/epoch=0.36............. Loss: 0.37250967, mean(E): -18.99028309-0.01320814j, var(E): 1.31633614
-0.0
tensor(12.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 20000/ t/epoch=0.36............. Loss: -0.34519518, mean(E): -18.86976972+0.01456281j, var(E): 1.24849079
-0.0
tensor(12.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 20000/ t/epoch=0.36............. Loss: 0.17028436, mean(E): -18.91908999-0.01947718j, var(E): 1.20507291
-0.0
tensor(12.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 20000/ t/epoch=0.36............. Loss: -0.57238183, mean(E): -18.79279369-0.02071305j, var(E): 1.08493657
-0.0
tensor(12.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 20000/ t/epoch=0.36............. Loss: 0.02296360, mean(E): -18.93254226+0.02407312j, var(E): 1.18954739
-0.0
tensor(12.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 20000/ t/epoch=0.36............. Loss: -0.53414252, mean(E): -18.82469298-0.01174740j, var(E): 1.00223176
-0.0
tensor(12.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 20000/ t/epoch=0.36............. Loss: -0.27943363, mean(E): -18.73880126-0.00181053j, var(E): 1.00203595
-0.0
tensor(12.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 20000/ t/epoch=0.36............. Loss: -0.91052555, mean(E): -19.00329737+0.00942951j, var(E): 0.93681743
-0.0
tensor(12.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 20000/ t/epoch=0.36............. Loss: -0.56859311, mean(E): -18.96478220-0.00376151j, var(E): 1.10331640
-0.0
tensor(12.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 20000/ t/epoch=0.36............. Loss: -0.07446322, mean(E): -19.01170289-0.01359909j, var(E): 1.29825787
-0.0
tensor(12.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 20000/ t/epoch=0.36............. Loss: -0.48587767, mean(E): -18.93754977-0.01018340j, var(E): 1.14730255
-0.0
tensor(12.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 20000/ t/epoch=0.36............. Loss: -0.15313915, mean(E): -18.94903842-0.02350455j, var(E): 1.28243133
-0.0
tensor(12.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 20000/ t/epoch=0.36............. Loss: -0.62263927, mean(E): -18.90628805+0.00139411j, var(E): 1.08849829
-0.0
tensor(12.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 20000/ t/epoch=0.36............. Loss: -0.48080929, mean(E): -18.93413223+0.03178121j, var(E): 1.07955197
-0.0
tensor(12.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 20000/ t/epoch=0.36............. Loss: -0.46665851, mean(E): -18.85231886-0.00456843j, var(E): 0.95304607
-0.0
tensor(12.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 20000/ t/epoch=0.36............. Loss: -0.81561302, mean(E): -18.99979427+0.02317286j, var(E): 0.89824617
-0.0
tensor(12.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 20000/ t/epoch=0.36............. Loss: -0.32331106, mean(E): -18.94207130+0.00038060j, var(E): 1.12618879
-0.0
tensor(12.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 20000/ t/epoch=0.36............. Loss: 0.12219038, mean(E): -18.98071411+0.02138578j, var(E): 0.94938259
-0.0
tensor(12.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 20000/ t/epoch=0.36............. Loss: 0.05571865, mean(E): -19.06255351+0.02346757j, var(E): 1.04798628
-0.0
tensor(12.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 20000/ t/epoch=0.36............. Loss: 0.15371585, mean(E): -18.91773447+0.02907676j, var(E): 1.13504459
-0.0
tensor(12.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 20000/ t/epoch=0.36............. Loss: -0.29135533, mean(E): -18.90193024+0.02760645j, var(E): 0.97888750
-0.0
tensor(12.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 20000/ t/epoch=0.36............. Loss: -0.19666102, mean(E): -19.01841870+0.01315287j, var(E): 0.95052734
-0.0
tensor(12.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 20000/ t/epoch=0.36............. Loss: -0.28120767, mean(E): -19.01669308-0.01580662j, var(E): 0.97504266
-0.0
tensor(12.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 20000/ t/epoch=0.36............. Loss: -1.09761332, mean(E): -18.93498184-0.00478563j, var(E): 1.00349537
-0.0
tensor(12.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 20000/ t/epoch=0.36............. Loss: -0.03348469, mean(E): -18.91547475+0.02825308j, var(E): 0.87926142
-0.0
tensor(12.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 20000/ t/epoch=0.36............. Loss: 0.00843309, mean(E): -19.01458300-0.01791050j, var(E): 0.97785480
-0.0
tensor(12.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 20000/ t/epoch=0.36............. Loss: -0.17223013, mean(E): -18.97541927+0.03619471j, var(E): 1.09188975
-0.0
tensor(12.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 20000/ t/epoch=0.36............. Loss: -0.43143876, mean(E): -19.04402892+0.01666664j, var(E): 0.90526102
-0.0
tensor(12.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 20000/ t/epoch=0.36............. Loss: -0.48318715, mean(E): -19.01045122+0.03058300j, var(E): 0.93693735
-0.0
tensor(12.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 20000/ t/epoch=0.36............. Loss: -0.10845296, mean(E): -18.94990721-0.00890876j, var(E): 0.96292519
-0.0
tensor(12.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 20000/ t/epoch=0.36............. Loss: -0.83347816, mean(E): -18.90297813-0.00944700j, var(E): 0.92264776
-0.0
tensor(12.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 20000/ t/epoch=0.36............. Loss: -0.31002790, mean(E): -18.97961354+0.02157408j, var(E): 0.80953470
-0.0
tensor(12.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 20000/ t/epoch=0.36............. Loss: -0.59425717, mean(E): -18.97811042-0.02389264j, var(E): 0.89707192
-0.0
tensor(12.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 20000/ t/epoch=0.36............. Loss: -1.04866990, mean(E): -19.02006197-0.03039640j, var(E): 0.81363726
-0.0
tensor(12.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 20000/ t/epoch=0.36............. Loss: -0.37119852, mean(E): -18.88200034+0.02436849j, var(E): 0.71777734
-0.0
tensor(12.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 20000/ t/epoch=0.36............. Loss: -0.28839667, mean(E): -19.05448072-0.00859333j, var(E): 0.80704425
-0.0
tensor(12.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 20000/ t/epoch=0.36............. Loss: -0.13352729, mean(E): -19.02307319+0.00545752j, var(E): 0.70574604
-0.0
tensor(12.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 20000/ t/epoch=0.36............. Loss: -0.47470642, mean(E): -18.98604382+0.00265696j, var(E): 0.95474536
-0.0
tensor(12.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 20000/ t/epoch=0.36............. Loss: -0.06842864, mean(E): -19.06979947+0.00595255j, var(E): 0.69646727
-0.0
tensor(12.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 20000/ t/epoch=0.36............. Loss: -0.10949467, mean(E): -19.04144086-0.01124438j, var(E): 0.74926014
-0.0
tensor(12.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 20000/ t/epoch=0.36............. Loss: 0.12011135, mean(E): -19.13756494+0.01006129j, var(E): 0.90114100
-0.0
tensor(12.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 20000/ t/epoch=0.36............. Loss: -0.22806752, mean(E): -19.10550919-0.00461101j, var(E): 0.90091531
-0.0
tensor(12.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 20000/ t/epoch=0.36............. Loss: -0.53909148, mean(E): -19.09463975+0.00471352j, var(E): 0.79389167
-0.0
tensor(12.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 20000/ t/epoch=0.36............. Loss: -0.36679248, mean(E): -19.10467848+0.01645819j, var(E): 0.71989423
-0.0
tensor(12.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 20000/ t/epoch=0.36............. Loss: -0.42575470, mean(E): -18.90806192+0.01651386j, var(E): 0.94708638
-0.0
tensor(12.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 20000/ t/epoch=0.36............. Loss: -0.38689766, mean(E): -18.95918547+0.00625833j, var(E): 0.87719020
-0.0
tensor(12.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 20000/ t/epoch=0.36............. Loss: 0.13000656, mean(E): -19.07606418-0.03015895j, var(E): 0.97163760
-0.0
tensor(12.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 20000/ t/epoch=0.36............. Loss: -0.31489440, mean(E): -19.05855257-0.00277688j, var(E): 0.78979907
-0.0
tensor(12.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 20000/ t/epoch=0.36............. Loss: 0.04203752, mean(E): -19.01631010+0.00886372j, var(E): 0.72268743
-0.0
tensor(12.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 20000/ t/epoch=0.36............. Loss: -0.73336093, mean(E): -19.01923967+0.00054986j, var(E): 0.59543653
-0.0
tensor(12.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 20000/ t/epoch=0.36............. Loss: -0.06932023, mean(E): -19.00878811+0.00130863j, var(E): 0.79200743
-0.0
tensor(12.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 20000/ t/epoch=0.36............. Loss: 0.43948381, mean(E): -18.94585826+0.00247000j, var(E): 0.78996292
-0.0
tensor(12.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 20000/ t/epoch=0.36............. Loss: -0.24504262, mean(E): -18.98896570-0.03189207j, var(E): 0.76904309
-0.0
tensor(12.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 20000/ t/epoch=0.36............. Loss: 0.26739240, mean(E): -19.00823274-0.01839984j, var(E): 0.64148824
-0.0
tensor(12.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 20000/ t/epoch=0.36............. Loss: -0.39463012, mean(E): -18.99674622-0.01241790j, var(E): 0.74727105
-0.0
tensor(12.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 20000/ t/epoch=0.36............. Loss: -0.86245209, mean(E): -19.05413647-0.00435707j, var(E): 0.82134218
-0.0
tensor(12.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 20000/ t/epoch=0.36............. Loss: -0.10822401, mean(E): -19.03708090+0.01278123j, var(E): 0.74245279
-0.0
tensor(12.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 20000/ t/epoch=0.36............. Loss: -0.36547729, mean(E): -19.08896283-0.01037468j, var(E): 0.72332545
-0.0
tensor(12.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 20000/ t/epoch=0.36............. Loss: -0.19051287, mean(E): -19.01963849+0.01342190j, var(E): 0.65051154
-0.0
tensor(12.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 20000/ t/epoch=0.36............. Loss: -0.09558841, mean(E): -19.02654835+0.00871565j, var(E): 0.68165709
-0.0
tensor(12.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 20000/ t/epoch=0.36............. Loss: 0.43579462, mean(E): -19.08401015+0.00489694j, var(E): 0.76810742
-0.0
tensor(12.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 20000/ t/epoch=0.36............. Loss: -0.62793968, mean(E): -19.13932276-0.00443322j, var(E): 0.58427008
-0.0
tensor(12.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 20000/ t/epoch=0.36............. Loss: 0.00078534, mean(E): -19.14198938+0.01413192j, var(E): 0.66815879
-0.0
tensor(12.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 20000/ t/epoch=0.36............. Loss: -0.12173308, mean(E): -19.09959239-0.00316980j, var(E): 0.64117166
-0.0
tensor(12.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 20000/ t/epoch=0.36............. Loss: 0.05824605, mean(E): -19.08319657-0.00705457j, var(E): 0.70481148
-0.0
tensor(12.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 20000/ t/epoch=0.36............. Loss: 0.40165024, mean(E): -19.07931772-0.03525413j, var(E): 0.58858357
-0.0
tensor(12.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 20000/ t/epoch=0.36............. Loss: 0.41054585, mean(E): -19.04531781+0.00000968j, var(E): 0.77511511
-0.0
tensor(12.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 20000/ t/epoch=0.36............. Loss: -0.40508450, mean(E): -19.04853507-0.00170568j, var(E): 0.62103872
-0.0
tensor(12.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 20000/ t/epoch=0.36............. Loss: -0.78162705, mean(E): -19.16279424-0.00248582j, var(E): 0.87418605
-0.0
tensor(12.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 20000/ t/epoch=0.36............. Loss: 0.71687084, mean(E): -19.10718573+0.01989169j, var(E): 0.76986429
-0.0
tensor(12.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 20000/ t/epoch=0.36............. Loss: -0.31856341, mean(E): -19.07793908-0.02567956j, var(E): 0.78238151
-0.0
tensor(12.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 20000/ t/epoch=0.36............. Loss: -0.12261190, mean(E): -19.04120959+0.01840253j, var(E): 0.63435661
-0.0
tensor(12.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 20000/ t/epoch=0.36............. Loss: -0.40769272, mean(E): -19.12792043+0.01120948j, var(E): 0.67494906
-0.0
tensor(12.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 20000/ t/epoch=0.36............. Loss: -0.16307642, mean(E): -19.18035466-0.01965086j, var(E): 0.78274116
-0.0
tensor(12.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 20000/ t/epoch=0.36............. Loss: 0.12633110, mean(E): -19.03403535+0.00494113j, var(E): 0.62068286
-0.0
tensor(12.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 20000/ t/epoch=0.36............. Loss: -0.69125821, mean(E): -19.17328276+0.02645979j, var(E): 0.57756786
-0.0
tensor(12.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 20000/ t/epoch=0.36............. Loss: -0.51841890, mean(E): -18.97305559+0.01802028j, var(E): 0.84452503
-0.0
tensor(12.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 20000/ t/epoch=0.36............. Loss: -0.05685582, mean(E): -19.09809275+0.00585868j, var(E): 0.55822838
-0.0
tensor(12.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 20000/ t/epoch=0.36............. Loss: -0.55577459, mean(E): -19.04439993+0.00141803j, var(E): 0.70582983
-0.0
tensor(12.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 20000/ t/epoch=0.36............. Loss: 0.00496986, mean(E): -19.20047624+0.01821505j, var(E): 0.63968894
-0.0
tensor(12.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 20000/ t/epoch=0.36............. Loss: 0.15263933, mean(E): -19.12122971+0.01829031j, var(E): 0.65105283
-0.0
tensor(12.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 20000/ t/epoch=0.36............. Loss: -0.08521580, mean(E): -19.02850118+0.01461834j, var(E): 0.77035481
-0.0
tensor(12.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 20000/ t/epoch=0.36............. Loss: -0.36128556, mean(E): -19.02174211+0.00579432j, var(E): 0.62424317
-0.0
tensor(12.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 20000/ t/epoch=0.36............. Loss: -0.04542543, mean(E): -19.08547722-0.01585344j, var(E): 0.81524318
-0.0
tensor(12.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 20000/ t/epoch=0.36............. Loss: -0.09158724, mean(E): -19.05526332+0.00297361j, var(E): 0.70020038
-0.0
tensor(12.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 20000/ t/epoch=0.36............. Loss: -0.30502939, mean(E): -19.16485611-0.03270931j, var(E): 0.56429133
-0.0
tensor(12.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 20000/ t/epoch=0.36............. Loss: 0.06602463, mean(E): -19.14986250+0.01915335j, var(E): 0.69574058
-0.0
tensor(12.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 20000/ t/epoch=0.36............. Loss: -0.46775474, mean(E): -18.98716635+0.00610674j, var(E): 0.62775649
-0.0
tensor(12.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 20000/ t/epoch=0.36............. Loss: -0.38331799, mean(E): -19.10082899+0.03278760j, var(E): 0.60984617
-0.0
tensor(13.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 20000/ t/epoch=0.36............. Loss: 0.31545432, mean(E): -19.14856621+0.01175676j, var(E): 0.65110682
-0.0
tensor(13.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 20000/ t/epoch=0.36............. Loss: -0.30018738, mean(E): -19.10913203-0.01331508j, var(E): 0.77736179
-0.0
tensor(13.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 20000/ t/epoch=0.36............. Loss: -0.69747449, mean(E): -19.11386845-0.01810047j, var(E): 0.55302781
-0.0
tensor(13.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 20000/ t/epoch=0.36............. Loss: -0.04607567, mean(E): -19.09867897+0.00417630j, var(E): 0.64317642
-0.0
tensor(13.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 20000/ t/epoch=0.36............. Loss: -0.22499869, mean(E): -19.12813637+0.00143569j, var(E): 0.58893060
-0.0
tensor(13.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 20000/ t/epoch=0.36............. Loss: 0.02627492, mean(E): -19.02688368-0.00861397j, var(E): 0.73546499
-0.0
tensor(13.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 20000/ t/epoch=0.36............. Loss: -0.16930969, mean(E): -19.08416599+0.00663408j, var(E): 0.67107367
-0.0
tensor(13.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 20000/ t/epoch=0.36............. Loss: 0.22900396, mean(E): -19.11589765+0.02923478j, var(E): 0.54765128
-0.0
tensor(13.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 20000/ t/epoch=0.36............. Loss: -0.03140884, mean(E): -19.08067963+0.01837503j, var(E): 0.52159768
-0.0
tensor(13.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 20000/ t/epoch=0.36............. Loss: -0.80482479, mean(E): -19.12046677-0.00416830j, var(E): 0.59929627
-0.0
tensor(13.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 20000/ t/epoch=0.36............. Loss: -0.57687476, mean(E): -19.14349509-0.00947821j, var(E): 0.65435850
-0.0
tensor(13.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 20000/ t/epoch=0.36............. Loss: -0.17153654, mean(E): -19.07530716-0.02138294j, var(E): 0.52133959
-0.0
tensor(13.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 20000/ t/epoch=0.36............. Loss: 0.04232342, mean(E): -19.18419044+0.02050046j, var(E): 0.59678654
-0.0
tensor(13.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 20000/ t/epoch=0.36............. Loss: -0.48261705, mean(E): -19.19561436-0.01830075j, var(E): 0.66133761
-0.0
tensor(13.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 20000/ t/epoch=0.36............. Loss: -0.09382100, mean(E): -19.13831646-0.00149398j, var(E): 0.56697231
-0.0
tensor(13.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 20000/ t/epoch=0.36............. Loss: -0.14622036, mean(E): -19.14929011-0.00150676j, var(E): 0.69313546
-0.0
tensor(13.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 20000/ t/epoch=0.36............. Loss: 0.20368115, mean(E): -19.13161181+0.01543305j, var(E): 0.48864825
-0.0
tensor(13.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 20000/ t/epoch=0.36............. Loss: 0.67679772, mean(E): -19.22984012+0.00115189j, var(E): 0.58803623
-0.0
tensor(13.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 20000/ t/epoch=0.36............. Loss: -0.05585906, mean(E): -19.14600796-0.00530167j, var(E): 0.49605174
-0.0
tensor(13.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 20000/ t/epoch=0.36............. Loss: 0.00905973, mean(E): -19.21090041+0.02267951j, var(E): 0.74618825
-0.0
tensor(13.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 20000/ t/epoch=0.36............. Loss: -0.26589877, mean(E): -19.06805501-0.00220251j, var(E): 0.73442727
-0.0
tensor(13.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 20000/ t/epoch=0.36............. Loss: -0.60818024, mean(E): -19.10180691-0.03318626j, var(E): 0.58596193
-0.0
tensor(13.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 20000/ t/epoch=0.36............. Loss: -0.06560641, mean(E): -19.03239246+0.00947230j, var(E): 0.80064497
-0.0
tensor(13.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 20000/ t/epoch=0.36............. Loss: -0.00308576, mean(E): -19.12696376+0.00187375j, var(E): 0.55671663
-0.0
tensor(13.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 20000/ t/epoch=0.36............. Loss: -0.63949110, mean(E): -19.03682046+0.02465977j, var(E): 0.62183717
-0.0
tensor(13.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 20000/ t/epoch=0.36............. Loss: -0.50391060, mean(E): -19.12709730+0.00401121j, var(E): 0.69199960
-0.0
tensor(13.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 20000/ t/epoch=0.36............. Loss: -0.50736949, mean(E): -19.10492010-0.00893504j, var(E): 0.58662335
-0.0
tensor(13.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 20000/ t/epoch=0.36............. Loss: -0.04424128, mean(E): -19.18134264-0.00117323j, var(E): 0.62359276
-0.0
tensor(13.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 20000/ t/epoch=0.36............. Loss: -0.17990683, mean(E): -19.20736983+0.01337331j, var(E): 0.71753943
-0.0
tensor(13.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 20000/ t/epoch=0.36............. Loss: -0.14770809, mean(E): -19.08153168+0.00457779j, var(E): 0.59912091
-0.0
tensor(13.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 20000/ t/epoch=0.36............. Loss: -0.75924999, mean(E): -19.14689880-0.01100334j, var(E): 0.69153692
-0.0
tensor(13.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 20000/ t/epoch=0.36............. Loss: 0.25893474, mean(E): -19.26815610-0.01942716j, var(E): 0.71091471
-0.0
tensor(13.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 20000/ t/epoch=0.36............. Loss: -0.32032814, mean(E): -19.06574965-0.00578828j, var(E): 0.62226441
-0.0
tensor(13.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 20000/ t/epoch=0.36............. Loss: -0.04241528, mean(E): -19.11330215-0.01499698j, var(E): 0.59512833
-0.0
tensor(13.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 20000/ t/epoch=0.36............. Loss: -0.69857082, mean(E): -19.11700096+0.01530116j, var(E): 0.55078211
-0.0
tensor(13.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 20000/ t/epoch=0.36............. Loss: -0.44416709, mean(E): -19.07700168+0.01206915j, var(E): 0.57493185
-0.0
tensor(13.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 20000/ t/epoch=0.36............. Loss: -0.24135760, mean(E): -19.17538632+0.01048270j, var(E): 0.49588418
-0.0
tensor(13.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 20000/ t/epoch=0.36............. Loss: -0.31991512, mean(E): -19.13293396-0.01396442j, var(E): 0.50909366
-0.0
tensor(13.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 20000/ t/epoch=0.36............. Loss: -0.17357961, mean(E): -19.29139501+0.00563803j, var(E): 0.56659589
-0.0
tensor(13.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 20000/ t/epoch=0.36............. Loss: 0.18035975, mean(E): -19.17868533-0.02440817j, var(E): 0.54443466
-0.0
tensor(13.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 20000/ t/epoch=0.36............. Loss: -0.00306606, mean(E): -19.24701147-0.00720504j, var(E): 0.54780598
-0.0
tensor(13.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 20000/ t/epoch=0.36............. Loss: -0.37592169, mean(E): -19.14594510+0.01127804j, var(E): 0.48277133
-0.0
tensor(13.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 20000/ t/epoch=0.36............. Loss: 0.14614143, mean(E): -19.11103429+0.01719145j, var(E): 0.46315649
-0.0
tensor(13.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 20000/ t/epoch=0.36............. Loss: 0.18634806, mean(E): -19.13240220+0.00058953j, var(E): 0.52073329
-0.0
tensor(13.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 20000/ t/epoch=0.36............. Loss: 0.36245734, mean(E): -19.22849378+0.00171612j, var(E): 0.60844655
-0.0
tensor(13.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 20000/ t/epoch=0.36............. Loss: 0.62929789, mean(E): -19.19075500-0.02554625j, var(E): 0.39628632
-0.0
tensor(13.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 20000/ t/epoch=0.36............. Loss: 0.20081654, mean(E): -19.13595349-0.01372673j, var(E): 0.45988664
-0.0
tensor(13.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 20000/ t/epoch=0.36............. Loss: 0.52396720, mean(E): -19.12380402-0.00510158j, var(E): 0.44233608
-0.0
tensor(13.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 20000/ t/epoch=0.36............. Loss: -0.03430346, mean(E): -19.12564321-0.00228127j, var(E): 0.45125235
-0.0
tensor(13.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 20000/ t/epoch=0.36............. Loss: -0.25249937, mean(E): -19.15927030-0.00732738j, var(E): 0.50501696
-0.0
tensor(13.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 20000/ t/epoch=0.36............. Loss: 0.42533475, mean(E): -19.21379335+0.00546834j, var(E): 0.78922235
-0.0
tensor(13.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 20000/ t/epoch=0.36............. Loss: 0.35426953, mean(E): -19.14667591+0.00494695j, var(E): 0.48086239
-0.0
tensor(13.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 20000/ t/epoch=0.36............. Loss: -0.48743681, mean(E): -19.07076610-0.00059473j, var(E): 0.70077892
-0.0
tensor(13.2930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 20000/ t/epoch=0.36............. Loss: -0.11310016, mean(E): -19.10153307-0.02757857j, var(E): 0.58613055
-0.0
tensor(13.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 20000/ t/epoch=0.36............. Loss: -0.23073840, mean(E): -19.10022171+0.01771665j, var(E): 0.48543329
-0.0
tensor(13.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 20000/ t/epoch=0.36............. Loss: 0.33960810, mean(E): -19.14054464-0.00350685j, var(E): 0.43658857
-0.0
tensor(13.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 20000/ t/epoch=0.36............. Loss: 0.08349235, mean(E): -19.12202734+0.00338407j, var(E): 0.45541049
-0.0
tensor(13.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 20000/ t/epoch=0.36............. Loss: 0.25126157, mean(E): -19.15771907-0.01331034j, var(E): 0.43331652
-0.0
tensor(13.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 20000/ t/epoch=0.36............. Loss: -0.22286891, mean(E): -19.16176583-0.00280127j, var(E): 0.45837665
-0.0
tensor(13.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 20000/ t/epoch=0.36............. Loss: -0.00777047, mean(E): -19.13474380-0.00657872j, var(E): 0.45805416
-0.0
tensor(13.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 20000/ t/epoch=0.36............. Loss: 0.83295549, mean(E): -19.18460683+0.02617021j, var(E): 0.44990740
-0.0
tensor(13.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 20000/ t/epoch=0.36............. Loss: 0.17993701, mean(E): -19.12869912-0.01574775j, var(E): 0.67794338
-0.0
tensor(13.3391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 20000/ t/epoch=0.36............. Loss: -0.52912850, mean(E): -19.12354430-0.01644972j, var(E): 0.55357809
-0.0
tensor(13.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 20000/ t/epoch=0.36............. Loss: -0.79189871, mean(E): -19.13226237-0.00862781j, var(E): 0.69134610
-0.0
tensor(13.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 20000/ t/epoch=0.36............. Loss: -0.16014871, mean(E): -19.13589500+0.00774472j, var(E): 0.78219620
-0.0
tensor(13.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 20000/ t/epoch=0.36............. Loss: -0.44036627, mean(E): -19.09249885+0.00119586j, var(E): 0.39786119
-0.0
tensor(13.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 20000/ t/epoch=0.36............. Loss: -0.39338276, mean(E): -19.18239907+0.01098621j, var(E): 0.39523141
-0.0
tensor(13.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 20000/ t/epoch=0.36............. Loss: 0.42546471, mean(E): -19.12947991-0.01981407j, var(E): 0.51801568
-0.0
tensor(13.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 20000/ t/epoch=0.36............. Loss: -0.08729623, mean(E): -19.15379728-0.05672001j, var(E): 0.47534407
-0.0
tensor(13.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 20000/ t/epoch=0.36............. Loss: -0.34773621, mean(E): -19.15203342-0.01290248j, var(E): 0.43208454
-0.0
tensor(13.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 20000/ t/epoch=0.36............. Loss: -0.63172955, mean(E): -19.11628038+0.00834178j, var(E): 0.41514660
-0.0
tensor(13.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 20000/ t/epoch=0.36............. Loss: -0.17461159, mean(E): -19.09574913+0.00960506j, var(E): 0.71112295
-0.0
tensor(13.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 20000/ t/epoch=0.36............. Loss: -0.00550775, mean(E): -19.19235128-0.01031869j, var(E): 0.45761705
-0.0
tensor(13.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 20000/ t/epoch=0.36............. Loss: -0.16396527, mean(E): -19.16761805-0.02420633j, var(E): 0.48737173
-0.0
tensor(13.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 20000/ t/epoch=0.36............. Loss: -0.32513812, mean(E): -19.20154296-0.02159985j, var(E): 0.32288505
-0.0
tensor(13.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 20000/ t/epoch=0.36............. Loss: 0.67375954, mean(E): -19.09891389+0.02031564j, var(E): 0.42665540
-0.0
tensor(13.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 20000/ t/epoch=0.36............. Loss: -0.42425661, mean(E): -19.12309553-0.04022691j, var(E): 0.58078763
-0.0
tensor(13.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 20000/ t/epoch=0.36............. Loss: -0.24320320, mean(E): -19.10297805-0.00880611j, var(E): 0.62852475
-0.0
tensor(13.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 20000/ t/epoch=0.36............. Loss: -0.32143448, mean(E): -19.10040786-0.01605670j, var(E): 0.42620479
-0.0
tensor(13.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 20000/ t/epoch=0.36............. Loss: -0.46811944, mean(E): -19.16265631+0.00925331j, var(E): 0.43580904
-0.0
tensor(13.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 20000/ t/epoch=0.36............. Loss: -0.24155212, mean(E): -19.13609999+0.02139467j, var(E): 0.50056156
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 20000/ t/epoch=0.36............. Loss: -0.23435979, mean(E): -19.18115870-0.00455116j, var(E): 0.42898313
-0.0
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 20000/ t/epoch=0.36............. Loss: -0.48197948, mean(E): -19.09923755-0.00769253j, var(E): 0.48593901
-0.0
tensor(13.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 20000/ t/epoch=0.36............. Loss: -0.32872503, mean(E): -19.15755151+0.02332140j, var(E): 0.45852454
-0.0
tensor(13.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 20000/ t/epoch=0.36............. Loss: -0.39650256, mean(E): -19.07109758-0.00823909j, var(E): 0.43546294
-0.0
tensor(13.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 20000/ t/epoch=0.36............. Loss: 0.15349221, mean(E): -19.18546359-0.00133688j, var(E): 0.50434926
-0.0
tensor(13.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 20000/ t/epoch=0.36............. Loss: 0.34850758, mean(E): -19.12284015+0.00993035j, var(E): 0.40956080
-0.0
tensor(13.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 20000/ t/epoch=0.36............. Loss: 0.25206873, mean(E): -19.15413825-0.01725085j, var(E): 0.64693068
-0.0
tensor(13.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 20000/ t/epoch=0.36............. Loss: 0.02572560, mean(E): -19.09510622+0.00726813j, var(E): 0.43650397
-0.0
tensor(13.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 20000/ t/epoch=0.36............. Loss: 0.08473583, mean(E): -19.20037165-0.01074405j, var(E): 0.48540195
-0.0
tensor(13.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 20000/ t/epoch=0.36............. Loss: 0.50035385, mean(E): -19.13012857-0.02096835j, var(E): 0.41834331
-0.0
tensor(13.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 20000/ t/epoch=0.36............. Loss: -0.36434643, mean(E): -19.11843919+0.01350948j, var(E): 0.39930783
-0.0
tensor(13.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 20000/ t/epoch=0.36............. Loss: 0.03220402, mean(E): -19.11487318+0.00108492j, var(E): 0.33470497
-0.0
tensor(13.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 20000/ t/epoch=0.36............. Loss: 0.19257002, mean(E): -19.20468751+0.01076347j, var(E): 0.43129347
-0.0
tensor(13.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 20000/ t/epoch=0.36............. Loss: -0.24323052, mean(E): -19.17775567+0.02337314j, var(E): 0.59576321
-0.0
tensor(13.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 20000/ t/epoch=0.36............. Loss: -0.41064906, mean(E): -19.12352357-0.00025640j, var(E): 0.50145656
-0.0
tensor(13.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 20000/ t/epoch=0.36............. Loss: 0.08132418, mean(E): -19.24828143-0.01555639j, var(E): 0.43364816
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 20000/ t/epoch=0.36............. Loss: -0.33881425, mean(E): -19.09061648+0.02248598j, var(E): 0.44231236
-0.0
tensor(13.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 20000/ t/epoch=0.36............. Loss: 0.61036282, mean(E): -19.22513026+0.02442386j, var(E): 0.43988738
-0.0
tensor(13.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 20000/ t/epoch=0.36............. Loss: -0.01682481, mean(E): -19.06450636+0.01018740j, var(E): 0.46104970
-0.0
tensor(13.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 20000/ t/epoch=0.36............. Loss: 0.21766391, mean(E): -19.14625004+0.00347448j, var(E): 0.44043220
-0.0
tensor(13.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 20000/ t/epoch=0.36............. Loss: 0.03162739, mean(E): -19.20617686+0.00834747j, var(E): 0.39640089
-0.0
tensor(13.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 20000/ t/epoch=0.36............. Loss: -0.72372143, mean(E): -19.14201235-0.02301507j, var(E): 0.32047714
-0.0
tensor(13.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 20000/ t/epoch=0.36............. Loss: -0.05215800, mean(E): -19.14997798+0.01468678j, var(E): 0.38286346
-0.0
tensor(13.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 20000/ t/epoch=0.36............. Loss: -0.02252011, mean(E): -19.21877795-0.00428554j, var(E): 0.42108541
-0.0
tensor(13.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 20000/ t/epoch=0.36............. Loss: -0.18940974, mean(E): -19.17720162+0.01468657j, var(E): 0.37664155
-0.0
tensor(13.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 20000/ t/epoch=0.36............. Loss: 0.01555093, mean(E): -19.18929309-0.01680132j, var(E): 0.48886855
-0.0
tensor(13.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 20000/ t/epoch=0.36............. Loss: -0.64399651, mean(E): -19.08721320+0.00883784j, var(E): 0.41232056
-0.0
tensor(13.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 20000/ t/epoch=0.36............. Loss: 0.18489734, mean(E): -19.14826646+0.01537962j, var(E): 0.47694039
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 20000/ t/epoch=0.36............. Loss: -0.09050169, mean(E): -19.06899199-0.02174602j, var(E): 0.38468764
-0.0
tensor(13.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 20000/ t/epoch=0.36............. Loss: 0.56212486, mean(E): -19.14487921-0.03144342j, var(E): 0.49378372
-0.0
tensor(13.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 20000/ t/epoch=0.36............. Loss: -0.10389718, mean(E): -19.14028284-0.00360084j, var(E): 0.55301933
-0.0
tensor(13.5503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 20000/ t/epoch=0.36............. Loss: -0.11582979, mean(E): -19.21807449+0.00178497j, var(E): 0.50900476
-0.0
tensor(13.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 20000/ t/epoch=0.36............. Loss: 0.11336496, mean(E): -19.17265216-0.03517707j, var(E): 0.42241299
-0.0
tensor(13.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 20000/ t/epoch=0.36............. Loss: 0.12121663, mean(E): -19.14895158+0.01248639j, var(E): 0.49536331
-0.0
tensor(13.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 20000/ t/epoch=0.36............. Loss: 0.07847908, mean(E): -19.15207396-0.02184375j, var(E): 0.48333618
-0.0
tensor(13.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 20000/ t/epoch=0.36............. Loss: 0.10977860, mean(E): -19.13060109+0.01883066j, var(E): 0.28338783
-0.0
tensor(13.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 20000/ t/epoch=0.36............. Loss: -0.12101384, mean(E): -19.22102606+0.00039748j, var(E): 0.44722196
-0.0
tensor(13.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 20000/ t/epoch=0.36............. Loss: -0.41199644, mean(E): -19.17335906-0.00272634j, var(E): 0.36318480
-0.0
tensor(13.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 20000/ t/epoch=0.36............. Loss: 0.07905239, mean(E): -19.08925529+0.02285384j, var(E): 0.41120171
-0.0
tensor(13.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 20000/ t/epoch=0.36............. Loss: 0.20021974, mean(E): -19.09428620-0.00120064j, var(E): 0.37463444
-0.0
tensor(13.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 20000/ t/epoch=0.36............. Loss: -0.08344333, mean(E): -19.16421913-0.00075907j, var(E): 0.39990980
-0.0
tensor(13.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 20000/ t/epoch=0.36............. Loss: -0.00447303, mean(E): -19.16010305+0.02329786j, var(E): 0.32579601
-0.0
tensor(13.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 20000/ t/epoch=0.36............. Loss: -0.23327198, mean(E): -19.12571513-0.01009811j, var(E): 0.42460720
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 20000/ t/epoch=0.36............. Loss: 0.12978544, mean(E): -19.16997274+0.02310738j, var(E): 0.40120004
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 20000/ t/epoch=0.36............. Loss: -0.10976676, mean(E): -19.20209002-0.00375495j, var(E): 0.45602658
-0.0
tensor(13.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 20000/ t/epoch=0.36............. Loss: -0.27596102, mean(E): -19.13686867+0.00834902j, var(E): 0.46124854
-0.0
tensor(13.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 20000/ t/epoch=0.36............. Loss: -0.05642462, mean(E): -19.20511577-0.00007223j, var(E): 0.38752345
-0.0
tensor(13.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 20000/ t/epoch=0.36............. Loss: 0.22968528, mean(E): -19.20248173+0.01579180j, var(E): 0.37701046
-0.0
tensor(13.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 20000/ t/epoch=0.36............. Loss: 0.39676072, mean(E): -19.14082741-0.01274654j, var(E): 0.44495429
-0.0
tensor(13.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 20000/ t/epoch=0.36............. Loss: -0.04389788, mean(E): -19.14352651-0.01030725j, var(E): 0.41317236
-0.0
tensor(13.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 20000/ t/epoch=0.36............. Loss: -0.69884934, mean(E): -19.11727307-0.00681026j, var(E): 0.36498905
-0.0
tensor(13.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 20000/ t/epoch=0.36............. Loss: 0.11857418, mean(E): -19.17347492-0.01151137j, var(E): 0.36646641
-0.0
tensor(13.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 20000/ t/epoch=0.36............. Loss: 0.07280239, mean(E): -19.18370278+0.00472891j, var(E): 0.34112825
-0.0
tensor(13.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 20000/ t/epoch=0.36............. Loss: 0.38655844, mean(E): -19.14865645+0.03119399j, var(E): 0.36940495
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 20000/ t/epoch=0.36............. Loss: 0.00854656, mean(E): -19.07461664+0.00826330j, var(E): 0.44663796
-0.0
tensor(13.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 20000/ t/epoch=0.36............. Loss: -0.07843981, mean(E): -19.11387909-0.00950802j, var(E): 0.37260412
-0.0
tensor(13.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 20000/ t/epoch=0.36............. Loss: 0.06925286, mean(E): -19.07087900-0.02427920j, var(E): 0.36849557
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 20000/ t/epoch=0.36............. Loss: 0.09508711, mean(E): -19.10606647+0.00910409j, var(E): 0.37668578
-0.0
tensor(13.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 20000/ t/epoch=0.36............. Loss: 0.05159637, mean(E): -19.22828555+0.00496985j, var(E): 0.27605097
-0.0
tensor(13.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 20000/ t/epoch=0.36............. Loss: 0.04107533, mean(E): -19.16264952+0.04420377j, var(E): 0.27305116
-0.0
tensor(13.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 20000/ t/epoch=0.37............. Loss: -0.45071166, mean(E): -19.07501193-0.00518181j, var(E): 0.26258643
-0.0
tensor(13.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 20000/ t/epoch=0.36............. Loss: -0.20245209, mean(E): -19.13364408-0.02017129j, var(E): 0.43419091
-0.0
tensor(13.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 20000/ t/epoch=0.36............. Loss: -0.08104895, mean(E): -19.16350547-0.00982513j, var(E): 0.32504790
-0.0
tensor(13.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 20000/ t/epoch=0.36............. Loss: -0.50677565, mean(E): -19.17415683-0.00712116j, var(E): 0.36194168
-0.0
tensor(13.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 20000/ t/epoch=0.36............. Loss: 0.15479043, mean(E): -19.21681997+0.02832640j, var(E): 0.33216230
-0.0
tensor(13.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 20000/ t/epoch=0.36............. Loss: -0.26601908, mean(E): -19.15350817+0.02033460j, var(E): 0.34344706
-0.0
tensor(13.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 20000/ t/epoch=0.36............. Loss: -0.02864533, mean(E): -19.17413729+0.02100422j, var(E): 0.34451081
-0.0
tensor(13.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 20000/ t/epoch=0.36............. Loss: -0.47902821, mean(E): -19.14518033+0.01660542j, var(E): 0.36923371
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 20000/ t/epoch=0.36............. Loss: -0.27227882, mean(E): -19.14351402+0.01581252j, var(E): 0.35285269
-0.0
tensor(13.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 20000/ t/epoch=0.36............. Loss: -0.46124807, mean(E): -19.10129463-0.02745436j, var(E): 0.38506376
-0.0
tensor(13.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 20000/ t/epoch=0.36............. Loss: 0.05572083, mean(E): -19.21358795-0.01103097j, var(E): 0.31671737
-0.0
tensor(13.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 20000/ t/epoch=0.36............. Loss: -0.15056574, mean(E): -19.14068053-0.02063053j, var(E): 0.32035091
-0.0
tensor(13.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 20000/ t/epoch=0.36............. Loss: 0.09068818, mean(E): -19.16971437-0.01558683j, var(E): 0.42318037
-0.0
tensor(13.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 20000/ t/epoch=0.36............. Loss: -0.41228312, mean(E): -19.15282683-0.00300142j, var(E): 0.32418417
-0.0
tensor(13.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 20000/ t/epoch=0.36............. Loss: -0.27301957, mean(E): -19.04352235+0.02511577j, var(E): 0.31293894
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 20000/ t/epoch=0.36............. Loss: -0.04393156, mean(E): -19.20130574+0.03664356j, var(E): 0.35905771
-0.0
tensor(13.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 20000/ t/epoch=0.36............. Loss: 0.00105341, mean(E): -19.16223903-0.00385936j, var(E): 0.31133237
-0.0
tensor(13.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 20000/ t/epoch=0.36............. Loss: -0.18023432, mean(E): -19.17816825-0.01295041j, var(E): 0.37055674
-0.0
tensor(13.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 20000/ t/epoch=0.36............. Loss: -0.10585680, mean(E): -19.16061013-0.00105013j, var(E): 0.33222869
-0.0
tensor(13.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 20000/ t/epoch=0.36............. Loss: -0.29353709, mean(E): -19.22513180-0.00465616j, var(E): 0.19965690
-0.0
tensor(13.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 20000/ t/epoch=0.36............. Loss: -0.15073202, mean(E): -19.14653872-0.01318801j, var(E): 0.26498497
-0.0
tensor(13.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 20000/ t/epoch=0.36............. Loss: 0.22022495, mean(E): -19.18737705-0.00336932j, var(E): 0.50154215
-0.0
tensor(13.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 20000/ t/epoch=0.36............. Loss: -0.23230089, mean(E): -19.16527075-0.00858166j, var(E): 0.29294691
-0.0
tensor(13.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 20000/ t/epoch=0.36............. Loss: -0.25177645, mean(E): -19.14429071-0.01154734j, var(E): 0.34327208
-0.0
tensor(13.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 20000/ t/epoch=0.36............. Loss: -0.22536555, mean(E): -19.16180850+0.01128792j, var(E): 0.45186740
-0.0
tensor(13.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 20000/ t/epoch=0.36............. Loss: 0.10984175, mean(E): -19.13521723-0.02698230j, var(E): 0.40772422
-0.0
tensor(13.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 20000/ t/epoch=0.36............. Loss: 0.43831349, mean(E): -19.14881473+0.01324582j, var(E): 0.36495093
-0.0
tensor(13.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 20000/ t/epoch=0.36............. Loss: -0.23518845, mean(E): -19.13167203-0.00234293j, var(E): 0.34794818
-0.0
tensor(13.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 20000/ t/epoch=0.36............. Loss: 0.24668293, mean(E): -19.17339131+0.01118935j, var(E): 0.28675015
-0.0
tensor(13.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 20000/ t/epoch=0.36............. Loss: 0.07167404, mean(E): -19.16965576-0.03402372j, var(E): 0.47159473
-0.0
tensor(13.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 20000/ t/epoch=0.36............. Loss: -0.24256120, mean(E): -19.15819046+0.02291436j, var(E): 0.25125973
-0.0
tensor(13.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 20000/ t/epoch=0.36............. Loss: 0.15158278, mean(E): -19.12586411+0.01366976j, var(E): 0.34870600
-0.0
tensor(13.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 20000/ t/epoch=0.36............. Loss: 0.66348489, mean(E): -19.27687488-0.01139950j, var(E): 0.42493301
-0.0
tensor(13.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 20000/ t/epoch=0.36............. Loss: 0.19134453, mean(E): -19.16386970+0.01943113j, var(E): 0.44331257
-0.0
tensor(13.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 20000/ t/epoch=0.36............. Loss: 0.18353298, mean(E): -19.17845145-0.01427540j, var(E): 0.28389679
-0.0
tensor(13.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 20000/ t/epoch=0.36............. Loss: -0.02832560, mean(E): -19.18691204-0.00504070j, var(E): 0.36530888
-0.0
tensor(13.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 20000/ t/epoch=0.36............. Loss: -0.53769550, mean(E): -19.21782755+0.00423401j, var(E): 0.41521902
-0.0
tensor(13.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 20000/ t/epoch=0.36............. Loss: 0.34269425, mean(E): -19.20100226+0.00815175j, var(E): 0.29068163
-0.0
tensor(13.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 20000/ t/epoch=0.36............. Loss: 0.16325384, mean(E): -19.22641468+0.01752373j, var(E): 0.21848460
-0.0
tensor(13.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 20000/ t/epoch=0.36............. Loss: -0.56986839, mean(E): -19.18727201+0.01180590j, var(E): 0.32134644
-0.0
tensor(13.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 20000/ t/epoch=0.36............. Loss: -0.21462053, mean(E): -19.12317373+0.01187643j, var(E): 0.33463581
-0.0
tensor(13.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 20000/ t/epoch=0.36............. Loss: -0.40975524, mean(E): -19.13658613+0.00234976j, var(E): 0.30354564
-0.0
tensor(13.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 20000/ t/epoch=0.36............. Loss: 0.04175803, mean(E): -19.11570428+0.02078274j, var(E): 0.32771030
-0.0
tensor(13.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 20000/ t/epoch=0.36............. Loss: 0.11405966, mean(E): -19.24182029+0.02699600j, var(E): 0.51111592
-0.0
tensor(13.8333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 20000/ t/epoch=0.36............. Loss: 0.30102765, mean(E): -19.24643147+0.00934835j, var(E): 0.30435662
-0.0
tensor(13.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 20000/ t/epoch=0.36............. Loss: -0.32499190, mean(E): -19.09950707-0.01720969j, var(E): 0.32435851
-0.0
tensor(13.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 20000/ t/epoch=0.36............. Loss: 0.20131753, mean(E): -19.23024973+0.00267154j, var(E): 0.32107560
-0.0
tensor(13.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 20000/ t/epoch=0.36............. Loss: 0.34045455, mean(E): -19.13443803-0.00708651j, var(E): 0.33682537
-0.0
tensor(13.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 20000/ t/epoch=0.36............. Loss: 0.37929348, mean(E): -19.20456461-0.04287841j, var(E): 0.29718168
-0.0
tensor(13.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 20000/ t/epoch=0.36............. Loss: -0.27607593, mean(E): -19.09775075+0.02747657j, var(E): 0.38209706
-0.0
tensor(13.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 20000/ t/epoch=0.36............. Loss: 0.40108762, mean(E): -19.15425639+0.00529523j, var(E): 0.33813564
-0.0
tensor(13.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 20000/ t/epoch=0.36............. Loss: -0.36801987, mean(E): -19.18959898+0.00761098j, var(E): 0.37373310
-0.0
tensor(13.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 20000/ t/epoch=0.36............. Loss: -0.26056207, mean(E): -19.17765906-0.00182110j, var(E): 0.36570106
-0.0
tensor(13.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 20000/ t/epoch=0.36............. Loss: 0.30908518, mean(E): -19.20464252+0.02121931j, var(E): 0.42922382
-0.0
tensor(13.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 20000/ t/epoch=0.36............. Loss: -0.26562760, mean(E): -19.17578242-0.01131492j, var(E): 0.25886179
-0.0
tensor(13.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 20000/ t/epoch=0.36............. Loss: 0.42430426, mean(E): -19.15542472+0.00583538j, var(E): 0.35639278
-0.0
tensor(13.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 20000/ t/epoch=0.36............. Loss: -0.01980696, mean(E): -19.17519512+0.01638144j, var(E): 0.24065068
-0.0
tensor(13.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 20000/ t/epoch=0.37............. Loss: 0.35610064, mean(E): -19.14219274-0.01225798j, var(E): 0.27879622
-0.0
tensor(13.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 20000/ t/epoch=0.36............. Loss: 0.42837030, mean(E): -19.18460952+0.01155301j, var(E): 0.38036366
-0.0
tensor(13.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 20000/ t/epoch=0.36............. Loss: -0.23340261, mean(E): -19.21917973+0.00992603j, var(E): 0.33646847
-0.0
tensor(13.8884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 20000/ t/epoch=0.36............. Loss: 0.18087419, mean(E): -19.16090626-0.00037215j, var(E): 0.24735210
-0.0
tensor(13.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 20000/ t/epoch=0.36............. Loss: -0.17047170, mean(E): -19.19693194-0.01884848j, var(E): 0.27766187
-0.0
tensor(13.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 20000/ t/epoch=0.36............. Loss: -0.17701400, mean(E): -19.22693187+0.00678379j, var(E): 0.21662233
-0.0
tensor(13.8978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 20000/ t/epoch=0.36............. Loss: 0.41162323, mean(E): -19.22103391-0.02184961j, var(E): 0.43810783
-0.0
tensor(13.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 20000/ t/epoch=0.36............. Loss: -0.38964077, mean(E): -19.16888342-0.00397328j, var(E): 0.28051129
-0.0
tensor(13.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 20000/ t/epoch=0.37............. Loss: -0.22722720, mean(E): -19.14124667-0.00926171j, var(E): 0.24705640
-0.0
tensor(13.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 20000/ t/epoch=0.36............. Loss: 0.24454569, mean(E): -19.21543415-0.01135455j, var(E): 0.29137759
-0.0
tensor(13.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 20000/ t/epoch=0.36............. Loss: -0.15363515, mean(E): -19.22233715-0.01273133j, var(E): 0.25218677
-0.0
tensor(13.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 20000/ t/epoch=0.36............. Loss: -0.59918422, mean(E): -19.16025344+0.01180311j, var(E): 0.33476366
-0.0
tensor(13.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 20000/ t/epoch=0.36............. Loss: 0.17672907, mean(E): -19.19782890-0.01475338j, var(E): 0.32146715
-0.0
tensor(13.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 20000/ t/epoch=0.36............. Loss: 0.33255596, mean(E): -19.19304700+0.00339678j, var(E): 0.26810238
-0.0
tensor(13.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 20000/ t/epoch=0.36............. Loss: 0.01038404, mean(E): -19.18518006-0.01110020j, var(E): 0.28843099
-0.0
tensor(13.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 20000/ t/epoch=0.36............. Loss: 0.40183515, mean(E): -19.23315612-0.00485592j, var(E): 0.36777762
-0.0
tensor(13.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 20000/ t/epoch=0.36............. Loss: -0.16929141, mean(E): -19.14743977+0.00242769j, var(E): 0.32546296
-0.0
tensor(13.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 20000/ t/epoch=0.36............. Loss: -0.21998346, mean(E): -19.13944062+0.00741034j, var(E): 0.30858131
-0.0
tensor(13.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 20000/ t/epoch=0.36............. Loss: -0.03355826, mean(E): -19.14391915-0.00761909j, var(E): 0.24190249
-0.0
tensor(13.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 20000/ t/epoch=0.36............. Loss: -0.03010466, mean(E): -19.22886113-0.00080916j, var(E): 0.30703285
-0.0
tensor(13.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 20000/ t/epoch=0.36............. Loss: 0.13529958, mean(E): -19.14617243-0.01159354j, var(E): 0.32730097
-0.0
tensor(13.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 20000/ t/epoch=0.36............. Loss: 0.29564920, mean(E): -19.17083317-0.01948883j, var(E): 0.38562299
-0.0
tensor(13.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 20000/ t/epoch=0.36............. Loss: -0.41389411, mean(E): -19.16570584+0.03592981j, var(E): 0.30776506
-0.0
tensor(13.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 20000/ t/epoch=0.36............. Loss: 0.15538402, mean(E): -19.19841904-0.01023356j, var(E): 0.32570026
-0.0
tensor(13.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 20000/ t/epoch=0.36............. Loss: -0.23430458, mean(E): -19.20675155+0.00090904j, var(E): 0.25561093
-0.0
tensor(13.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 20000/ t/epoch=0.36............. Loss: -0.70370209, mean(E): -19.15137818-0.02388912j, var(E): 0.37122703
-0.0
tensor(13.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 20000/ t/epoch=0.36............. Loss: -0.24685145, mean(E): -19.10173629+0.01866985j, var(E): 0.31166788
-0.0
tensor(13.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 20000/ t/epoch=0.36............. Loss: -0.12270962, mean(E): -19.15664899+0.01139553j, var(E): 0.29925607
-0.0
tensor(13.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 20000/ t/epoch=0.36............. Loss: -0.06367865, mean(E): -19.12055816+0.01859462j, var(E): 0.36435363
-0.0
tensor(13.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 20000/ t/epoch=0.36............. Loss: -0.31596776, mean(E): -19.10637013+0.01872565j, var(E): 0.36948778
-0.0
tensor(13.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 20000/ t/epoch=0.36............. Loss: -0.34564967, mean(E): -19.16631434-0.02549520j, var(E): 0.32727790
-0.0
tensor(13.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 20000/ t/epoch=0.36............. Loss: 0.34048010, mean(E): -19.17437460+0.00575581j, var(E): 0.24972741
-0.0
tensor(13.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 20000/ t/epoch=0.36............. Loss: -0.31494992, mean(E): -19.17964923+0.01083957j, var(E): 0.36207823
-0.0
tensor(13.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 20000/ t/epoch=0.36............. Loss: 0.17389831, mean(E): -19.21530676-0.02329641j, var(E): 0.21668719
-0.0
tensor(14.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 20000/ t/epoch=0.36............. Loss: -0.48917532, mean(E): -19.15491044-0.00349679j, var(E): 0.25011340
-0.0
tensor(14.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 20000/ t/epoch=0.36............. Loss: -0.47642836, mean(E): -19.15921842+0.03790154j, var(E): 0.28244454
-0.0
tensor(14.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 20000/ t/epoch=0.36............. Loss: 0.20748246, mean(E): -19.19830464+0.00315304j, var(E): 0.20200979
-0.0
tensor(14.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 20000/ t/epoch=0.36............. Loss: 0.35331290, mean(E): -19.21146420-0.00486249j, var(E): 0.32738515
-0.0
tensor(14.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 20000/ t/epoch=0.36............. Loss: -0.19549548, mean(E): -19.17569484+0.03825462j, var(E): 0.20182122
-0.0
tensor(14.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 20000/ t/epoch=0.36............. Loss: -0.03197648, mean(E): -19.21615623+0.01336098j, var(E): 0.23207069
-0.0
tensor(14.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 20000/ t/epoch=0.36............. Loss: 0.30423367, mean(E): -19.23961421+0.00491041j, var(E): 0.38094593
-0.0
tensor(14.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 20000/ t/epoch=0.36............. Loss: 0.11985205, mean(E): -19.15896040-0.02558857j, var(E): 0.42185760
-0.0
tensor(14.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 20000/ t/epoch=0.36............. Loss: -0.09950314, mean(E): -19.24873968+0.01236558j, var(E): 0.33251001
-0.0
tensor(14.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 20000/ t/epoch=0.36............. Loss: -0.07361059, mean(E): -19.17366510-0.00732104j, var(E): 0.20926214
-0.0
tensor(14.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 20000/ t/epoch=0.36............. Loss: -0.16186536, mean(E): -19.14058641-0.01537955j, var(E): 0.33513586
-0.0
tensor(14.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 20000/ t/epoch=0.36............. Loss: -0.33406025, mean(E): -19.16329550-0.02923405j, var(E): 0.28443565
-0.0
tensor(14.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 20000/ t/epoch=0.36............. Loss: 0.52743085, mean(E): -19.19416615-0.00985627j, var(E): 0.24582774
-0.0
tensor(14.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 20000/ t/epoch=0.36............. Loss: 0.12408091, mean(E): -19.21824260-0.01601802j, var(E): 0.23396960
-0.0
tensor(14.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 20000/ t/epoch=0.36............. Loss: 0.05547355, mean(E): -19.20722585-0.00219738j, var(E): 0.20909116
-0.0
tensor(14.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 20000/ t/epoch=0.36............. Loss: 0.01571327, mean(E): -19.15178888-0.00335848j, var(E): 0.15027880
-0.0
tensor(14.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 20000/ t/epoch=0.36............. Loss: -0.00140327, mean(E): -19.15961248+0.00118410j, var(E): 0.28380443
-0.0
tensor(14.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 20000/ t/epoch=0.36............. Loss: 0.42974878, mean(E): -19.13344261+0.00738378j, var(E): 0.24772697
-0.0
tensor(14.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 20000/ t/epoch=0.36............. Loss: 0.02132249, mean(E): -19.12918958-0.01033670j, var(E): 0.34598867
-0.0
tensor(14.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 20000/ t/epoch=0.36............. Loss: -0.36334203, mean(E): -19.17125019+0.00090419j, var(E): 0.31070760
-0.0
tensor(14.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 20000/ t/epoch=0.36............. Loss: -0.03910260, mean(E): -19.19447651+0.00681956j, var(E): 0.40183475
-0.0
tensor(14.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 20000/ t/epoch=0.36............. Loss: -0.33858539, mean(E): -19.20485226+0.00422153j, var(E): 0.31624014
-0.0
tensor(14.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 20000/ t/epoch=0.36............. Loss: -0.03029366, mean(E): -19.16972431+0.02601880j, var(E): 0.26538348
-0.0
tensor(14.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 20000/ t/epoch=0.36............. Loss: -0.28580100, mean(E): -19.13950928+0.00014777j, var(E): 0.24330716
-0.0
tensor(14.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 20000/ t/epoch=0.36............. Loss: -0.16549405, mean(E): -19.15261813+0.00986491j, var(E): 0.22090843
-0.0
tensor(14.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 20000/ t/epoch=0.36............. Loss: 0.21215214, mean(E): -19.19297576-0.01715720j, var(E): 0.30840045
-0.0
tensor(14.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 20000/ t/epoch=0.36............. Loss: -0.00832383, mean(E): -19.17658637-0.01159364j, var(E): 0.37903317
-0.0
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 20000/ t/epoch=0.36............. Loss: 0.08423889, mean(E): -19.22164831+0.00815637j, var(E): 0.19983185
-0.0
tensor(14.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 20000/ t/epoch=0.36............. Loss: 0.28632855, mean(E): -19.19841681+0.01559263j, var(E): 0.23279082
-0.0
tensor(14.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 20000/ t/epoch=0.36............. Loss: -0.07641758, mean(E): -19.18565830+0.00433173j, var(E): 0.23927189
-0.0
tensor(14.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 20000/ t/epoch=0.36............. Loss: 0.10158596, mean(E): -19.12597456+0.00395998j, var(E): 0.24891001
-0.0
tensor(14.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 20000/ t/epoch=0.36............. Loss: -0.14413330, mean(E): -19.20442950+0.00445535j, var(E): 0.30046962
-0.0
tensor(14.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 20000/ t/epoch=0.36............. Loss: 0.22655506, mean(E): -19.20491411+0.01750531j, var(E): 0.28636767
-0.0
tensor(14.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 20000/ t/epoch=0.36............. Loss: -0.18709914, mean(E): -19.20725370-0.00407426j, var(E): 0.28029368
-0.0
tensor(14.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 20000/ t/epoch=0.36............. Loss: -0.32465845, mean(E): -19.15911512-0.00137233j, var(E): 0.22674169
-0.0
tensor(14.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 20000/ t/epoch=0.36............. Loss: 0.07886484, mean(E): -19.18338546-0.00636002j, var(E): 0.23724221
-0.0
tensor(14.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 20000/ t/epoch=0.36............. Loss: -0.23504371, mean(E): -19.14333367-0.02278608j, var(E): 0.40010147
-0.0
tensor(14.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 20000/ t/epoch=0.36............. Loss: -0.45809655, mean(E): -19.11780890-0.00699738j, var(E): 0.26740207
-0.0
tensor(14.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 20000/ t/epoch=0.36............. Loss: 0.16966878, mean(E): -19.23340643+0.02127383j, var(E): 0.25045932
-0.0
tensor(14.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 20000/ t/epoch=0.36............. Loss: -0.32830076, mean(E): -19.20371537+0.00218508j, var(E): 0.35150292
-0.0
tensor(14.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 20000/ t/epoch=0.36............. Loss: 0.22610267, mean(E): -19.15838969-0.00313082j, var(E): 0.22658350
-0.0
tensor(14.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 20000/ t/epoch=0.36............. Loss: 0.05761681, mean(E): -19.21199046+0.01458217j, var(E): 0.32594435
-0.0
tensor(14.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 20000/ t/epoch=0.36............. Loss: 0.28179253, mean(E): -19.17934547-0.01838495j, var(E): 0.32161916
-0.0
tensor(14.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 20000/ t/epoch=0.36............. Loss: -0.11377331, mean(E): -19.21796870+0.03934018j, var(E): 0.22435446
-0.0
tensor(14.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 20000/ t/epoch=0.36............. Loss: -0.01870639, mean(E): -19.22207494-0.01526577j, var(E): 0.26046296
-0.0
tensor(14.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 20000/ t/epoch=0.36............. Loss: -0.22290377, mean(E): -19.19725854-0.01848172j, var(E): 0.19585259
-0.0
tensor(14.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 20000/ t/epoch=0.36............. Loss: 0.10234588, mean(E): -19.19159392+0.00134138j, var(E): 0.28457027
-0.0
tensor(14.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 20000/ t/epoch=0.36............. Loss: 0.01859935, mean(E): -19.16821131+0.00170490j, var(E): 0.20931399
-0.0
tensor(14.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 20000/ t/epoch=0.36............. Loss: -0.03180838, mean(E): -19.21142284+0.02447467j, var(E): 0.19740518
-0.0
tensor(14.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 20000/ t/epoch=0.36............. Loss: -0.11315326, mean(E): -19.16319662+0.00445579j, var(E): 0.22216443
-0.0
tensor(14.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 20000/ t/epoch=0.36............. Loss: 0.21733740, mean(E): -19.23139661-0.01801940j, var(E): 0.22872622
-0.0
tensor(14.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 20000/ t/epoch=0.36............. Loss: -0.33850059, mean(E): -19.14398373-0.01274626j, var(E): 0.25044451
-0.0
tensor(14.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 20000/ t/epoch=0.36............. Loss: 0.27563984, mean(E): -19.18051508-0.01350185j, var(E): 0.21249265
-0.0
tensor(14.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 20000/ t/epoch=0.37............. Loss: -0.45641062, mean(E): -19.12283983-0.00182351j, var(E): 0.19337841
-0.0
tensor(14.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 20000/ t/epoch=0.36............. Loss: 0.01514856, mean(E): -19.18506606-0.01718700j, var(E): 0.34908120
-0.0
tensor(14.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 20000/ t/epoch=0.36............. Loss: 0.32530287, mean(E): -19.23633569+0.01925839j, var(E): 0.25415553
-0.0
tensor(14.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 20000/ t/epoch=0.36............. Loss: -0.46126309, mean(E): -19.11620094+0.00693552j, var(E): 0.28148101
-0.0
tensor(14.1676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 20000/ t/epoch=0.36............. Loss: -0.10644024, mean(E): -19.20598662+0.02249159j, var(E): 0.25575702
-0.0
tensor(14.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 20000/ t/epoch=0.36............. Loss: -0.25306363, mean(E): -19.25257436+0.00267124j, var(E): 0.20493354
-0.0
tensor(14.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 20000/ t/epoch=0.36............. Loss: -0.22595499, mean(E): -19.13961951-0.01327820j, var(E): 0.16902308
-0.0
tensor(14.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 20000/ t/epoch=0.37............. Loss: 0.17703455, mean(E): -19.21972910+0.00471981j, var(E): 0.25708751
-0.0
tensor(14.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 20000/ t/epoch=0.36............. Loss: -0.06731573, mean(E): -19.24388537+0.02517478j, var(E): 0.18169501
-0.0
tensor(14.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 20000/ t/epoch=0.36............. Loss: -0.17018041, mean(E): -19.18281215-0.00135832j, var(E): 0.28774343
-0.0
tensor(14.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 20000/ t/epoch=0.37............. Loss: -0.08331084, mean(E): -19.17652508+0.00134090j, var(E): 0.18258798
-0.0
tensor(14.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 20000/ t/epoch=0.37............. Loss: -0.44964955, mean(E): -19.16576173+0.03831174j, var(E): 0.26140100
-0.0
tensor(14.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 20000/ t/epoch=0.36............. Loss: -0.27728307, mean(E): -19.20268516-0.00490813j, var(E): 0.20789166
-0.0
tensor(14.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 20000/ t/epoch=0.36............. Loss: 0.25834344, mean(E): -19.20513758-0.00335682j, var(E): 0.21899747
-0.0
tensor(14.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 20000/ t/epoch=0.36............. Loss: -0.33687369, mean(E): -19.15464221-0.00595304j, var(E): 0.22569418
-0.0
tensor(14.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 20000/ t/epoch=0.36............. Loss: -0.49231380, mean(E): -19.21452671-0.00176235j, var(E): 0.25666138
-0.0
tensor(14.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 20000/ t/epoch=0.36............. Loss: 0.16336656, mean(E): -19.19916918-0.00446954j, var(E): 0.30123870
-0.0
tensor(14.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 20000/ t/epoch=0.36............. Loss: -0.13463573, mean(E): -19.19035341-0.02716851j, var(E): 0.18284894
-0.0
tensor(14.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 20000/ t/epoch=0.36............. Loss: 0.28718270, mean(E): -19.20193766+0.01076412j, var(E): 0.27390017
-0.0
tensor(14.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 20000/ t/epoch=0.36............. Loss: 0.07604092, mean(E): -19.16371729-0.00631810j, var(E): 0.19846221
-0.0
tensor(14.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 20000/ t/epoch=0.36............. Loss: -0.04667058, mean(E): -19.20763473-0.01640326j, var(E): 0.32009163
-0.0
tensor(14.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 20000/ t/epoch=0.36............. Loss: -0.19052034, mean(E): -19.16904665+0.01312224j, var(E): 0.19541739
-0.0
tensor(14.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 20000/ t/epoch=0.36............. Loss: 0.21546540, mean(E): -19.21027269+0.00787852j, var(E): 0.28218280
-0.0
tensor(14.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 20000/ t/epoch=0.36............. Loss: -0.40451024, mean(E): -19.15999635-0.01594301j, var(E): 0.47230927
-0.0
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 20000/ t/epoch=0.36............. Loss: -0.12719675, mean(E): -19.20569501+0.00449980j, var(E): 0.24664193
-0.0
tensor(14.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 20000/ t/epoch=0.36............. Loss: 0.08973357, mean(E): -19.16944445-0.00582114j, var(E): 0.23459205
-0.0
tensor(14.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 20000/ t/epoch=0.36............. Loss: -0.28014117, mean(E): -19.16899056+0.01112706j, var(E): 0.22021838
-0.0
tensor(14.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 20000/ t/epoch=0.36............. Loss: -0.09188891, mean(E): -19.23045406-0.00236070j, var(E): 0.21901233
-0.0
tensor(14.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 20000/ t/epoch=0.36............. Loss: 0.02349760, mean(E): -19.25065600+0.00920493j, var(E): 0.26468651
-0.0
tensor(14.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 20000/ t/epoch=0.36............. Loss: -0.22492808, mean(E): -19.16511973-0.00970576j, var(E): 0.21903470
-0.0
tensor(14.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 20000/ t/epoch=0.36............. Loss: 0.04094645, mean(E): -19.18223652+0.00132593j, var(E): 0.24906086
-0.0
tensor(14.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 20000/ t/epoch=0.36............. Loss: -0.15377998, mean(E): -19.18897626-0.00715154j, var(E): 0.20863401
-0.0
tensor(14.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 20000/ t/epoch=0.36............. Loss: -0.26054095, mean(E): -19.16543087-0.00273397j, var(E): 0.23260607
-0.0
tensor(14.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 20000/ t/epoch=0.36............. Loss: 0.01422245, mean(E): -19.24229058-0.00096449j, var(E): 0.18947806
-0.0
tensor(14.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 20000/ t/epoch=0.36............. Loss: 0.23702478, mean(E): -19.22200041-0.00505688j, var(E): 0.22111025
-0.0
tensor(14.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 20000/ t/epoch=0.36............. Loss: -0.03102054, mean(E): -19.20434050-0.03018927j, var(E): 0.14617682
-0.0
tensor(14.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 20000/ t/epoch=0.36............. Loss: -0.27205254, mean(E): -19.20129617+0.01564362j, var(E): 0.16531785
-0.0
tensor(14.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 20000/ t/epoch=0.36............. Loss: 0.18090830, mean(E): -19.17168984-0.00635518j, var(E): 0.17065152
-0.0
tensor(14.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 20000/ t/epoch=0.36............. Loss: 0.22302184, mean(E): -19.17579628-0.00739383j, var(E): 0.13162925
-0.0
tensor(14.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 20000/ t/epoch=0.36............. Loss: 0.35950344, mean(E): -19.17381367-0.00327059j, var(E): 0.21981250
-0.0
tensor(14.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 20000/ t/epoch=0.36............. Loss: -0.01386034, mean(E): -19.19138992+0.02261378j, var(E): 0.30951259
-0.0
tensor(14.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 20000/ t/epoch=0.37............. Loss: -0.14444437, mean(E): -19.13196243+0.01303470j, var(E): 0.30178042
-0.0
tensor(14.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 20000/ t/epoch=0.36............. Loss: 0.29348526, mean(E): -19.18526252-0.01743051j, var(E): 0.24653369
-0.0
tensor(14.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 20000/ t/epoch=0.36............. Loss: 0.09642826, mean(E): -19.24450886+0.00039211j, var(E): 0.24370207
-0.0
tensor(14.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 20000/ t/epoch=0.36............. Loss: -0.09646439, mean(E): -19.22354296-0.02208495j, var(E): 0.21984934
-0.0
tensor(14.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 20000/ t/epoch=0.36............. Loss: -0.17658574, mean(E): -19.17272422-0.01876162j, var(E): 0.22871607
-0.0
tensor(14.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 20000/ t/epoch=0.36............. Loss: -0.19701760, mean(E): -19.15665957+0.00775417j, var(E): 0.18791880
-0.0
tensor(14.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 20000/ t/epoch=0.37............. Loss: 0.29621285, mean(E): -19.21576484+0.00025641j, var(E): 0.21162719
-0.0
tensor(14.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 20000/ t/epoch=0.36............. Loss: 0.01326304, mean(E): -19.19133682-0.00311856j, var(E): 0.24727148
-0.0
tensor(14.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 20000/ t/epoch=0.37............. Loss: -0.25655485, mean(E): -19.20762127+0.00602574j, var(E): 0.20211310
-0.0
tensor(14.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 20000/ t/epoch=0.37............. Loss: -0.07555512, mean(E): -19.19300017-0.01167151j, var(E): 0.22274625
-0.0
tensor(14.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 20000/ t/epoch=0.36............. Loss: 0.05083946, mean(E): -19.17583915-0.00717961j, var(E): 0.29737556
-0.0
tensor(14.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 20000/ t/epoch=0.37............. Loss: 0.05095514, mean(E): -19.19825403-0.00974525j, var(E): 0.19750700
-0.0
tensor(14.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 20000/ t/epoch=0.37............. Loss: -0.08344188, mean(E): -19.16690761+0.00010926j, var(E): 0.17912666
-0.0
tensor(14.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 20000/ t/epoch=0.36............. Loss: -0.27890647, mean(E): -19.20679518+0.00090612j, var(E): 0.20591755
-0.0
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 20000/ t/epoch=0.36............. Loss: -0.37812023, mean(E): -19.16578130+0.00638778j, var(E): 0.25773901
-0.0
tensor(14.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 20000/ t/epoch=0.37............. Loss: 0.18093787, mean(E): -19.21674862+0.00637846j, var(E): 0.19985619
-0.0
tensor(14.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 20000/ t/epoch=0.36............. Loss: 0.32857204, mean(E): -19.21793471-0.01074987j, var(E): 0.20111063
-0.0
tensor(14.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 20000/ t/epoch=0.36............. Loss: -0.20416609, mean(E): -19.14424103-0.00870384j, var(E): 0.17600591
-0.0
tensor(14.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 20000/ t/epoch=0.36............. Loss: 0.54733358, mean(E): -19.21457860-0.00594170j, var(E): 0.16070388
-0.0
tensor(14.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 20000/ t/epoch=0.37............. Loss: 0.09848677, mean(E): -19.25403168-0.00772690j, var(E): 0.17891849
-0.0
tensor(14.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 20000/ t/epoch=0.36............. Loss: -0.21644560, mean(E): -19.20730836+0.00595355j, var(E): 0.15652299
-0.0
tensor(14.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 20000/ t/epoch=0.36............. Loss: 0.19540798, mean(E): -19.22279572-0.00575774j, var(E): 0.21836493
-0.0
tensor(14.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 20000/ t/epoch=0.37............. Loss: 0.20980021, mean(E): -19.19882187+0.00175193j, var(E): 0.29061346
-0.0
tensor(14.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 20000/ t/epoch=0.36............. Loss: 0.01796959, mean(E): -19.18754705-0.01844106j, var(E): 0.15428970
-0.0
tensor(14.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 20000/ t/epoch=0.36............. Loss: 0.14424265, mean(E): -19.24541654-0.01020536j, var(E): 0.20799068
-0.0
tensor(14.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 20000/ t/epoch=0.36............. Loss: -0.03966104, mean(E): -19.21007758-0.01891752j, var(E): 0.22976753
-0.0
tensor(14.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 20000/ t/epoch=0.36............. Loss: 0.49483307, mean(E): -19.27300923+0.00535891j, var(E): 0.22997111
-0.0
tensor(14.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 20000/ t/epoch=0.36............. Loss: 0.21144650, mean(E): -19.22165052-0.01195898j, var(E): 0.20978193
-0.0
tensor(14.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 20000/ t/epoch=0.36............. Loss: 0.04778425, mean(E): -19.17455932-0.00174796j, var(E): 0.20076788
-0.0
tensor(14.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 20000/ t/epoch=0.36............. Loss: 0.33791737, mean(E): -19.21721396-0.00697643j, var(E): 0.19555317
-0.0
tensor(14.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 20000/ t/epoch=0.36............. Loss: 0.11327379, mean(E): -19.16722994+0.01004039j, var(E): 0.26631643
-0.0
tensor(14.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 20000/ t/epoch=0.36............. Loss: 0.08215517, mean(E): -19.20742538+0.01388544j, var(E): 0.20183196
-0.0
tensor(14.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 20000/ t/epoch=0.36............. Loss: -0.01991850, mean(E): -19.18568874-0.00756138j, var(E): 0.21163823
-0.0
tensor(14.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 20000/ t/epoch=0.36............. Loss: -0.17376594, mean(E): -19.19846679+0.00607200j, var(E): 0.21522077
-0.0
tensor(14.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 20000/ t/epoch=0.37............. Loss: 0.31394847, mean(E): -19.27118032+0.01686320j, var(E): 0.25366690
-0.0
tensor(14.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 20000/ t/epoch=0.36............. Loss: 0.19006461, mean(E): -19.20304111-0.00481253j, var(E): 0.21478212
-0.0
tensor(14.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 20000/ t/epoch=0.36............. Loss: 0.14243089, mean(E): -19.21084288+0.00990968j, var(E): 0.15459843
-0.0
tensor(14.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 20000/ t/epoch=0.36............. Loss: 0.44126936, mean(E): -19.20884403-0.00597933j, var(E): 0.24831975
-0.0
tensor(14.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 20000/ t/epoch=0.36............. Loss: 0.19558746, mean(E): -19.20987988+0.00004817j, var(E): 0.19684844
-0.0
tensor(14.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 20000/ t/epoch=0.36............. Loss: 0.08601203, mean(E): -19.23990430+0.00324012j, var(E): 0.25245523
-0.0
tensor(14.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 20000/ t/epoch=0.36............. Loss: -0.10002336, mean(E): -19.21962739+0.00220143j, var(E): 0.13180692
-0.0
tensor(14.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 20000/ t/epoch=0.36............. Loss: 0.13193013, mean(E): -19.21881427+0.00670374j, var(E): 0.19702203
-0.0
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 20000/ t/epoch=0.36............. Loss: 0.26360607, mean(E): -19.19263323+0.01638682j, var(E): 0.17579622
-0.0
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 20000/ t/epoch=0.37............. Loss: -0.31888617, mean(E): -19.16091372-0.01286421j, var(E): 0.38088430
-0.0
tensor(14.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 20000/ t/epoch=0.36............. Loss: -0.06515362, mean(E): -19.21626113+0.00661840j, var(E): 0.19679574
-0.0
tensor(14.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 20000/ t/epoch=0.36............. Loss: 0.04504161, mean(E): -19.20768768+0.00482147j, var(E): 0.17698499
-0.0
tensor(14.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 20000/ t/epoch=0.36............. Loss: 0.15240418, mean(E): -19.18921414-0.03311397j, var(E): 0.24143316
-0.0
tensor(14.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 20000/ t/epoch=0.36............. Loss: 0.28823905, mean(E): -19.20070890-0.00745883j, var(E): 0.25899594
-0.0
tensor(14.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 20000/ t/epoch=0.37............. Loss: -0.06967799, mean(E): -19.18961598+0.00885594j, var(E): 0.20789296
-0.0
tensor(14.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 20000/ t/epoch=0.37............. Loss: -0.15884994, mean(E): -19.20821020-0.02183589j, var(E): 0.23193110
-0.0
tensor(14.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 20000/ t/epoch=0.36............. Loss: 0.08598480, mean(E): -19.18210260-0.00604623j, var(E): 0.14411940
-0.0
tensor(14.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 20000/ t/epoch=0.36............. Loss: -0.06514631, mean(E): -19.20645317+0.00377244j, var(E): 0.18747949
-0.0
tensor(14.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 20000/ t/epoch=0.37............. Loss: -0.25717237, mean(E): -19.21117016+0.00431519j, var(E): 0.12392412
-0.0
tensor(14.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 20000/ t/epoch=0.36............. Loss: 0.14840586, mean(E): -19.23585727-0.01772422j, var(E): 0.25315740
-0.0
tensor(14.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 20000/ t/epoch=0.36............. Loss: -0.27535755, mean(E): -19.17146948+0.00331122j, var(E): 0.18448884
-0.0
tensor(14.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 20000/ t/epoch=0.36............. Loss: 0.19304865, mean(E): -19.22001949-0.01551106j, var(E): 0.21534270
-0.0
tensor(14.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 20000/ t/epoch=0.36............. Loss: -0.52549437, mean(E): -19.20607764-0.01824221j, var(E): 0.18545601
-0.0
tensor(14.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 20000/ t/epoch=0.37............. Loss: -0.38600217, mean(E): -19.21246699-0.00765012j, var(E): 0.15207733
-0.0
tensor(14.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 20000/ t/epoch=0.36............. Loss: 0.10976034, mean(E): -19.19239042-0.00495652j, var(E): 0.18841751
-0.0
tensor(14.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 20000/ t/epoch=0.36............. Loss: -0.39569741, mean(E): -19.15217345-0.00908187j, var(E): 0.30689392
-0.0
tensor(14.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 20000/ t/epoch=0.36............. Loss: -0.13972717, mean(E): -19.17230703+0.01479708j, var(E): 0.27703356
-0.0
tensor(14.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 20000/ t/epoch=0.37............. Loss: -0.18627899, mean(E): -19.18737025-0.01184151j, var(E): 0.17892062
-0.0
tensor(14.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 20000/ t/epoch=0.36............. Loss: 0.06469215, mean(E): -19.20015779+0.02437469j, var(E): 0.19437368
-0.0
tensor(14.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 20000/ t/epoch=0.36............. Loss: -0.06491643, mean(E): -19.22732317+0.00424190j, var(E): 0.18200955
-0.0
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 20000/ t/epoch=0.37............. Loss: -0.03382417, mean(E): -19.19425674+0.00854797j, var(E): 0.15997482
-0.0
tensor(14.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 20000/ t/epoch=0.36............. Loss: -0.51806679, mean(E): -19.17875152-0.00747268j, var(E): 0.15355132
-0.0
tensor(14.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 20000/ t/epoch=0.36............. Loss: -0.24144072, mean(E): -19.25135224+0.01120497j, var(E): 0.14535668
-0.0
tensor(14.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 20000/ t/epoch=0.36............. Loss: -0.13978021, mean(E): -19.21307235+0.00936877j, var(E): 0.19551801
-0.0
tensor(14.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 20000/ t/epoch=0.36............. Loss: -0.00995319, mean(E): -19.15168487-0.00416785j, var(E): 0.23541749
-0.0
tensor(14.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 20000/ t/epoch=0.36............. Loss: 0.15146807, mean(E): -19.19103598+0.00181343j, var(E): 0.16171266
-0.0
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 20000/ t/epoch=0.36............. Loss: -0.02496106, mean(E): -19.15414465+0.00189951j, var(E): 0.20998977
-0.0
tensor(14.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 20000/ t/epoch=0.36............. Loss: 0.06345999, mean(E): -19.21742427-0.01394515j, var(E): 0.18104305
-0.0
tensor(14.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 20000/ t/epoch=0.36............. Loss: -0.12332367, mean(E): -19.19769856+0.00402453j, var(E): 0.16964634
-0.0
tensor(14.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 20000/ t/epoch=0.36............. Loss: -0.02328506, mean(E): -19.20529237-0.00614712j, var(E): 0.20865963
-0.0
tensor(14.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 20000/ t/epoch=0.36............. Loss: -0.01539872, mean(E): -19.20775393+0.00346918j, var(E): 0.16058813
-0.0
tensor(14.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 20000/ t/epoch=0.37............. Loss: -0.00968205, mean(E): -19.18640028-0.00180903j, var(E): 0.15807493
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 20000/ t/epoch=0.36............. Loss: 0.31778196, mean(E): -19.23292197+0.00323175j, var(E): 0.15174028
-0.0
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 20000/ t/epoch=0.36............. Loss: 0.17800160, mean(E): -19.19586916-0.00624984j, var(E): 0.19992246
-0.0
tensor(14.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 20000/ t/epoch=0.36............. Loss: -0.12024599, mean(E): -19.20262235-0.03299758j, var(E): 0.15930688
-0.0
tensor(14.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 20000/ t/epoch=0.36............. Loss: -0.25782504, mean(E): -19.14894561-0.00183623j, var(E): 0.21437023
-0.0
tensor(14.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 20000/ t/epoch=0.37............. Loss: 0.21423866, mean(E): -19.22126130-0.00908953j, var(E): 0.24026300
-0.0
tensor(14.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 20000/ t/epoch=0.37............. Loss: -0.04331698, mean(E): -19.16780731-0.00982596j, var(E): 0.18429991
-0.0
tensor(14.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 20000/ t/epoch=0.36............. Loss: 0.23945387, mean(E): -19.22420461-0.01342535j, var(E): 0.13245777
-0.0
tensor(14.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 20000/ t/epoch=0.37............. Loss: 0.38682958, mean(E): -19.24857555+0.01596424j, var(E): 0.16561609
-0.0
tensor(14.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 20000/ t/epoch=0.36............. Loss: -0.15439208, mean(E): -19.20638299+0.00889431j, var(E): 0.22549001
-0.0
tensor(14.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 20000/ t/epoch=0.36............. Loss: 0.15359984, mean(E): -19.25375139-0.02557336j, var(E): 0.09181441
-0.0
tensor(14.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 20000/ t/epoch=0.36............. Loss: 0.28944585, mean(E): -19.22904837+0.00963901j, var(E): 0.23917145
-0.0
tensor(14.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 20000/ t/epoch=0.36............. Loss: 0.19234398, mean(E): -19.21333696+0.00722334j, var(E): 0.15091497
-0.0
tensor(14.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 20000/ t/epoch=0.36............. Loss: 0.11873161, mean(E): -19.22085738-0.00964878j, var(E): 0.16979867
-0.0
tensor(14.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 20000/ t/epoch=0.36............. Loss: -0.25974116, mean(E): -19.14792438-0.00942535j, var(E): 0.21570971
-0.0
tensor(14.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 20000/ t/epoch=0.36............. Loss: -0.00682836, mean(E): -19.22236138+0.00853519j, var(E): 0.22377210
-0.0
tensor(14.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 20000/ t/epoch=0.37............. Loss: -0.06324724, mean(E): -19.20412796+0.02046330j, var(E): 0.12922872
-0.0
tensor(14.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 20000/ t/epoch=0.37............. Loss: -0.19579443, mean(E): -19.18268891-0.00984705j, var(E): 0.15129967
-0.0
tensor(14.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 20000/ t/epoch=0.36............. Loss: 0.34518378, mean(E): -19.26535632-0.01295844j, var(E): 0.17614727
-0.0
tensor(14.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 20000/ t/epoch=0.36............. Loss: 0.00959832, mean(E): -19.21011266-0.00841128j, var(E): 0.13412658
-0.0
tensor(14.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 20000/ t/epoch=0.36............. Loss: 0.17053154, mean(E): -19.22759452-0.00532331j, var(E): 0.30258213
-0.0
tensor(14.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 20000/ t/epoch=0.36............. Loss: 0.15225627, mean(E): -19.23853761+0.01625888j, var(E): 0.22848871
-0.0
tensor(14.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 20000/ t/epoch=0.36............. Loss: 0.10280089, mean(E): -19.19623462-0.01560108j, var(E): 0.28983283
-0.0
tensor(14.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 20000/ t/epoch=0.37............. Loss: 0.27802245, mean(E): -19.23609148-0.00459215j, var(E): 0.18697229
-0.0
tensor(14.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 20000/ t/epoch=0.37............. Loss: -0.10363904, mean(E): -19.15353480-0.00397915j, var(E): 0.14411677
-0.0
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 20000/ t/epoch=0.36............. Loss: -0.05997666, mean(E): -19.23738188+0.00342469j, var(E): 0.14543108
-0.0
tensor(14.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 20000/ t/epoch=0.36............. Loss: -0.16303734, mean(E): -19.18393193-0.00729156j, var(E): 0.19375405
-0.0
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 20000/ t/epoch=0.36............. Loss: -0.03780367, mean(E): -19.19796988-0.01766711j, var(E): 0.20727892
-0.0
tensor(14.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 20000/ t/epoch=0.36............. Loss: -0.13905981, mean(E): -19.18417540+0.01323341j, var(E): 0.20310708
-0.0
tensor(14.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 20000/ t/epoch=0.36............. Loss: 0.01146439, mean(E): -19.20139623+0.00520300j, var(E): 0.27539115
-0.0
tensor(14.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 20000/ t/epoch=0.36............. Loss: 0.15225995, mean(E): -19.25723821-0.00194079j, var(E): 0.17120711
-0.0
tensor(14.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 20000/ t/epoch=0.36............. Loss: 0.04315941, mean(E): -19.21667927+0.00632102j, var(E): 0.16573130
-0.0
tensor(14.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 20000/ t/epoch=0.37............. Loss: -0.22370219, mean(E): -19.17801618+0.00618449j, var(E): 0.14866532
-0.0
tensor(14.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 20000/ t/epoch=0.37............. Loss: -0.18092813, mean(E): -19.23618804+0.01836292j, var(E): 0.21449229
-0.0
tensor(14.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 20000/ t/epoch=0.37............. Loss: -0.23553819, mean(E): -19.23148563+0.00790435j, var(E): 0.23238896
-0.0
tensor(14.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 20000/ t/epoch=0.37............. Loss: -0.13496540, mean(E): -19.20874515+0.01049361j, var(E): 0.18885226
-0.0
tensor(14.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 20000/ t/epoch=0.36............. Loss: 0.15062305, mean(E): -19.18469816+0.00271652j, var(E): 0.15057822
-0.0
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 20000/ t/epoch=0.37............. Loss: 0.06427649, mean(E): -19.19316612-0.00173815j, var(E): 0.19043046
-0.0
tensor(14.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 20000/ t/epoch=0.36............. Loss: 0.17472747, mean(E): -19.17475145-0.00214310j, var(E): 0.15068353
-0.0
tensor(14.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 20000/ t/epoch=0.37............. Loss: -0.00685328, mean(E): -19.23413407-0.00461803j, var(E): 0.19422081
-0.0
tensor(14.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 20000/ t/epoch=0.36............. Loss: -0.37808898, mean(E): -19.17977328-0.00189226j, var(E): 0.24603048
-0.0
tensor(14.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 20000/ t/epoch=0.36............. Loss: -0.01206266, mean(E): -19.20572921-0.00298595j, var(E): 0.18679963
-0.0
tensor(14.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 20000/ t/epoch=0.36............. Loss: -0.02563722, mean(E): -19.21433699+0.01217718j, var(E): 0.11838324
-0.0
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 20000/ t/epoch=0.37............. Loss: 0.06193765, mean(E): -19.17490075+0.00405882j, var(E): 0.17678549
-0.0
tensor(14.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 20000/ t/epoch=0.36............. Loss: 0.19323559, mean(E): -19.17302368-0.00107888j, var(E): 0.28124957
-0.0
tensor(14.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 20000/ t/epoch=0.37............. Loss: 0.26715003, mean(E): -19.22040472-0.02890202j, var(E): 0.27668822
-0.0
tensor(14.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 20000/ t/epoch=0.37............. Loss: -0.02581579, mean(E): -19.17366619-0.00071551j, var(E): 0.24587497
-0.0
tensor(14.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 20000/ t/epoch=0.37............. Loss: 0.01414425, mean(E): -19.22546061+0.02148452j, var(E): 0.17785148
-0.0
tensor(14.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 20000/ t/epoch=0.37............. Loss: 0.02750613, mean(E): -19.21734518-0.01335257j, var(E): 0.17115264
-0.0
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 20000/ t/epoch=0.37............. Loss: 0.26053610, mean(E): -19.26123192+0.00106795j, var(E): 0.13574852
-0.0
tensor(14.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 20000/ t/epoch=0.37............. Loss: -0.32028784, mean(E): -19.16735656+0.01147670j, var(E): 0.16261012
-0.0
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 20000/ t/epoch=0.36............. Loss: 0.08174399, mean(E): -19.18837133+0.01264948j, var(E): 0.19497398
-0.0
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 20000/ t/epoch=0.36............. Loss: -0.05296512, mean(E): -19.16934273+0.00292455j, var(E): 0.13715616
-0.0
tensor(14.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 20000/ t/epoch=0.36............. Loss: -0.03183987, mean(E): -19.16885850-0.01358348j, var(E): 0.18939314
-0.0
tensor(14.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 20000/ t/epoch=0.36............. Loss: 0.31542851, mean(E): -19.23871627+0.01575244j, var(E): 0.17697918
-0.0
tensor(14.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 20000/ t/epoch=0.37............. Loss: -0.09562478, mean(E): -19.19843341+0.00576866j, var(E): 0.20977287
-0.0
tensor(14.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 20000/ t/epoch=0.37............. Loss: -0.18102743, mean(E): -19.18077813+0.00938785j, var(E): 0.23544703
-0.0
tensor(14.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 20000/ t/epoch=0.37............. Loss: -0.32107403, mean(E): -19.12815776-0.00541167j, var(E): 0.19706939
-0.0
tensor(14.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 20000/ t/epoch=0.37............. Loss: -0.11024660, mean(E): -19.19848573-0.00736035j, var(E): 0.19951475
-0.0
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 20000/ t/epoch=0.37............. Loss: 0.02818013, mean(E): -19.18019736-0.00709874j, var(E): 0.16139892
-0.0
tensor(14.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 20000/ t/epoch=0.37............. Loss: -0.02489173, mean(E): -19.20762064-0.00565648j, var(E): 0.14408362
-0.0
tensor(14.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 20000/ t/epoch=0.37............. Loss: -0.30939273, mean(E): -19.18237324-0.00101966j, var(E): 0.18385438
-0.0
tensor(14.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 20000/ t/epoch=0.37............. Loss: -0.02749448, mean(E): -19.19757597+0.00331734j, var(E): 0.18785476
-0.0
tensor(14.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 20000/ t/epoch=0.36............. Loss: -0.10149703, mean(E): -19.16371812+0.00816196j, var(E): 0.15975920
-0.0
tensor(14.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 20000/ t/epoch=0.37............. Loss: -0.12349904, mean(E): -19.19383439-0.00370475j, var(E): 0.10215161
-0.0
tensor(14.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 20000/ t/epoch=0.36............. Loss: -0.17102448, mean(E): -19.18568449+0.00540255j, var(E): 0.18499612
-0.0
tensor(14.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 20000/ t/epoch=0.36............. Loss: -0.03173587, mean(E): -19.21037978+0.00163318j, var(E): 0.24082103
-0.0
tensor(14.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 20000/ t/epoch=0.37............. Loss: 0.29521907, mean(E): -19.21127064-0.00489786j, var(E): 0.20289326
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 20000/ t/epoch=0.37............. Loss: 0.23450915, mean(E): -19.21011532-0.01717299j, var(E): 0.20840014
-0.0
tensor(14.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 20000/ t/epoch=0.37............. Loss: 0.15251515, mean(E): -19.19590095+0.00892410j, var(E): 0.22160389
-0.0
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 20000/ t/epoch=0.36............. Loss: -0.10511247, mean(E): -19.20337723+0.00291559j, var(E): 0.19356664
-0.0
tensor(14.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 20000/ t/epoch=0.36............. Loss: -0.20074511, mean(E): -19.17095325-0.00315662j, var(E): 0.16465829
-0.0
tensor(14.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 20000/ t/epoch=0.36............. Loss: 0.32914971, mean(E): -19.18607243-0.00984478j, var(E): 0.17163814
-0.0
tensor(14.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 20000/ t/epoch=0.36............. Loss: -0.13685832, mean(E): -19.19301487-0.00053960j, var(E): 0.16980803
-0.0
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 20000/ t/epoch=0.37............. Loss: -0.24008485, mean(E): -19.17936036-0.00521284j, var(E): 0.14500144
-0.0
tensor(14.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 20000/ t/epoch=0.36............. Loss: -0.17891685, mean(E): -19.23785440-0.01414921j, var(E): 0.13562214
-0.0
tensor(14.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 20000/ t/epoch=0.36............. Loss: 0.18657531, mean(E): -19.20957956-0.01309859j, var(E): 0.16730748
-0.0
tensor(14.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 20000/ t/epoch=0.36............. Loss: 0.10607979, mean(E): -19.17177025+0.00667909j, var(E): 0.11853660
-0.0
tensor(14.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 20000/ t/epoch=0.36............. Loss: 0.02642777, mean(E): -19.21248244-0.02288225j, var(E): 0.18085779
-0.0
tensor(14.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 20000/ t/epoch=0.36............. Loss: 0.03358792, mean(E): -19.23294768-0.01020026j, var(E): 0.15409204
-0.0
tensor(14.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 20000/ t/epoch=0.36............. Loss: -0.16268267, mean(E): -19.20814257+0.00746449j, var(E): 0.19920675
-0.0
tensor(14.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 20000/ t/epoch=0.36............. Loss: -0.04118886, mean(E): -19.20930397-0.00555158j, var(E): 0.09451687
-0.0
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 20000/ t/epoch=0.36............. Loss: 0.05329387, mean(E): -19.24068535+0.01791178j, var(E): 0.20300969
-0.0
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 20000/ t/epoch=0.36............. Loss: -0.13947468, mean(E): -19.23714203-0.00571454j, var(E): 0.11016547
-0.0
tensor(14.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 20000/ t/epoch=0.36............. Loss: -0.27494139, mean(E): -19.22500411+0.00516722j, var(E): 0.14998946
-0.0
tensor(14.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 20000/ t/epoch=0.36............. Loss: -0.02898716, mean(E): -19.23717738+0.00001986j, var(E): 0.15235205
-0.0
tensor(14.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 20000/ t/epoch=0.36............. Loss: -0.09177791, mean(E): -19.20999758+0.01041236j, var(E): 0.16321500
-0.0
tensor(14.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 20000/ t/epoch=0.36............. Loss: -0.06362007, mean(E): -19.22767088-0.01827943j, var(E): 0.11796350
-0.0
tensor(14.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 20000/ t/epoch=0.37............. Loss: -0.27797430, mean(E): -19.21765503-0.00706172j, var(E): 0.18891324
-0.0
tensor(14.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 20000/ t/epoch=0.37............. Loss: -0.02096970, mean(E): -19.21038162-0.01648392j, var(E): 0.11895757
-0.0
tensor(14.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 20000/ t/epoch=0.37............. Loss: -0.18742084, mean(E): -19.18506380-0.00424940j, var(E): 0.15653543
-0.0
tensor(14.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 20000/ t/epoch=0.36............. Loss: -0.17259477, mean(E): -19.14583028-0.00600183j, var(E): 0.21264517
-0.0
tensor(14.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 20000/ t/epoch=0.36............. Loss: 0.16556360, mean(E): -19.20049800+0.01615294j, var(E): 0.16710134
-0.0
tensor(14.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 20000/ t/epoch=0.36............. Loss: -0.02297047, mean(E): -19.17886723-0.00559236j, var(E): 0.16320565
-0.0
tensor(14.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 20000/ t/epoch=0.36............. Loss: -0.03909763, mean(E): -19.20339233-0.00010987j, var(E): 0.18266673
-0.0
tensor(14.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 20000/ t/epoch=0.36............. Loss: -0.00968426, mean(E): -19.21760899+0.00287825j, var(E): 0.17005868
-0.0
tensor(14.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 20000/ t/epoch=0.36............. Loss: 0.01344403, mean(E): -19.17271866-0.02409409j, var(E): 0.12512621
-0.0
tensor(14.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 20000/ t/epoch=0.37............. Loss: -0.03519548, mean(E): -19.22484356-0.01465070j, var(E): 0.15733866
-0.0
tensor(14.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 20000/ t/epoch=0.36............. Loss: -0.24767381, mean(E): -19.21697397-0.00228435j, var(E): 0.18175974
-0.0
tensor(14.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 20000/ t/epoch=0.36............. Loss: 0.17367593, mean(E): -19.25242172-0.00228954j, var(E): 0.22201557
-0.0
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 20000/ t/epoch=0.37............. Loss: 0.16346920, mean(E): -19.21910934+0.00129097j, var(E): 0.08704167
-0.0
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 20000/ t/epoch=0.37............. Loss: 0.08018386, mean(E): -19.22629430-0.00200023j, var(E): 0.12024936
-0.0
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 20000/ t/epoch=0.37............. Loss: 0.11206439, mean(E): -19.22672506+0.00245068j, var(E): 0.14302836
-0.0
tensor(14.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 20000/ t/epoch=0.37............. Loss: -0.00244363, mean(E): -19.22052293+0.00527871j, var(E): 0.17207876
-0.0
tensor(14.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 20000/ t/epoch=0.37............. Loss: 0.02079034, mean(E): -19.19009280+0.01297554j, var(E): 0.18028807
-0.0
tensor(14.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 20000/ t/epoch=0.37............. Loss: -0.10551016, mean(E): -19.21544777+0.00590150j, var(E): 0.16730408
-0.0
tensor(14.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 20000/ t/epoch=0.37............. Loss: -0.18868209, mean(E): -19.20177756+0.00142819j, var(E): 0.11781341
-0.0
tensor(14.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 20000/ t/epoch=0.36............. Loss: -0.06265396, mean(E): -19.22147031+0.00473391j, var(E): 0.15939048
-0.0
tensor(14.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 20000/ t/epoch=0.37............. Loss: 0.18050857, mean(E): -19.20681646-0.01140852j, var(E): 0.12129448
-0.0
tensor(14.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 20000/ t/epoch=0.37............. Loss: 0.08254204, mean(E): -19.20906422+0.01009043j, var(E): 0.10830334
-0.0
tensor(14.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 20000/ t/epoch=0.37............. Loss: 0.21887406, mean(E): -19.22166867-0.00848840j, var(E): 0.17907438
-0.0
tensor(14.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 20000/ t/epoch=0.37............. Loss: 0.10457736, mean(E): -19.22861857+0.00731992j, var(E): 0.15975237
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 20000/ t/epoch=0.37............. Loss: -0.00904632, mean(E): -19.23301312+0.00479668j, var(E): 0.10893253
-0.0
tensor(14.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 20000/ t/epoch=0.36............. Loss: 0.12839792, mean(E): -19.20880872-0.00248319j, var(E): 0.20813333
-0.0
tensor(14.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 20000/ t/epoch=0.36............. Loss: -0.07720200, mean(E): -19.15452008-0.00128716j, var(E): 0.22124616
-0.0
tensor(14.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 20000/ t/epoch=0.37............. Loss: 0.12641364, mean(E): -19.21120816+0.02269949j, var(E): 0.15378336
-0.0
tensor(14.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 20000/ t/epoch=0.36............. Loss: 0.16933594, mean(E): -19.23530244-0.00771801j, var(E): 0.21136820
-0.0
tensor(14.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 20000/ t/epoch=0.36............. Loss: 0.21641938, mean(E): -19.19158832-0.00763997j, var(E): 0.22275663
-0.0
tensor(14.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 20000/ t/epoch=0.36............. Loss: -0.14444582, mean(E): -19.17095068-0.00768883j, var(E): 0.20276852
-0.0
tensor(14.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 20000/ t/epoch=0.36............. Loss: 0.11611816, mean(E): -19.21933158+0.00140301j, var(E): 0.12720756
-0.0
tensor(14.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 20000/ t/epoch=0.36............. Loss: 0.11273979, mean(E): -19.20748173+0.01153632j, var(E): 0.11306142
-0.0
tensor(14.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 20000/ t/epoch=0.37............. Loss: -0.35542868, mean(E): -19.17291808-0.00247735j, var(E): 0.14368590
-0.0
tensor(14.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 20000/ t/epoch=0.37............. Loss: 0.16169008, mean(E): -19.21983306+0.01214959j, var(E): 0.23684691
-0.0
tensor(14.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 20000/ t/epoch=0.37............. Loss: 0.22758869, mean(E): -19.25368160-0.01089235j, var(E): 0.20040535
-0.0
tensor(14.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 20000/ t/epoch=0.36............. Loss: -0.28345346, mean(E): -19.18786297-0.01656817j, var(E): 0.29135677
-0.0
tensor(14.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 20000/ t/epoch=0.36............. Loss: 0.18982003, mean(E): -19.24451169-0.00412283j, var(E): 0.17603432
-0.0
tensor(14.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 20000/ t/epoch=0.36............. Loss: 0.22141741, mean(E): -19.23915761-0.00756624j, var(E): 0.17986495
-0.0
tensor(14.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 20000/ t/epoch=0.36............. Loss: -0.05527810, mean(E): -19.22285760+0.01214805j, var(E): 0.19487625
-0.0
tensor(14.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 20000/ t/epoch=0.37............. Loss: -0.17420857, mean(E): -19.18308175-0.00476534j, var(E): 0.16853239
-0.0
tensor(14.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 20000/ t/epoch=0.36............. Loss: 0.13555199, mean(E): -19.21174452-0.00249974j, var(E): 0.22316256
-0.0
tensor(14.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 20000/ t/epoch=0.36............. Loss: 0.04195472, mean(E): -19.16012462+0.02551385j, var(E): 0.14833115
-0.0
tensor(14.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 20000/ t/epoch=0.36............. Loss: 0.07793839, mean(E): -19.20183673+0.00186205j, var(E): 0.13604522
-0.0
tensor(14.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 20000/ t/epoch=0.37............. Loss: -0.01836125, mean(E): -19.18774255-0.00558120j, var(E): 0.13526021
-0.0
tensor(14.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 20000/ t/epoch=0.36............. Loss: 0.25387120, mean(E): -19.19760814+0.00805311j, var(E): 0.11973506
-0.0
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 20000/ t/epoch=0.36............. Loss: 0.03896318, mean(E): -19.19290686-0.01459473j, var(E): 0.20015519
-0.0
tensor(14.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 20000/ t/epoch=0.36............. Loss: 0.08741284, mean(E): -19.19921531-0.00672932j, var(E): 0.14857831
-0.0
tensor(14.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 20000/ t/epoch=0.36............. Loss: 0.00475436, mean(E): -19.19971631+0.00260871j, var(E): 0.18593693
-0.0
tensor(14.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 20000/ t/epoch=0.37............. Loss: 0.14398624, mean(E): -19.20335352+0.00969091j, var(E): 0.13226046
-0.0
tensor(14.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 20000/ t/epoch=0.36............. Loss: -0.05363223, mean(E): -19.16163817-0.01320861j, var(E): 0.20803572
-0.0
tensor(14.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 20000/ t/epoch=0.36............. Loss: 0.18288083, mean(E): -19.21682145+0.01312839j, var(E): 0.17812794
-0.0
tensor(14.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 20000/ t/epoch=0.36............. Loss: 0.02900146, mean(E): -19.20347325+0.01500740j, var(E): 0.21502501
-0.0
tensor(14.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 20000/ t/epoch=0.36............. Loss: -0.09327014, mean(E): -19.23167910-0.00047604j, var(E): 0.09795757
-0.0
tensor(14.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 20000/ t/epoch=0.36............. Loss: 0.00377489, mean(E): -19.22080073-0.00966951j, var(E): 0.21712584
-0.0
tensor(14.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 20000/ t/epoch=0.36............. Loss: -0.10634390, mean(E): -19.22004492+0.00725816j, var(E): 0.15664601
-0.0
tensor(14.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 20000/ t/epoch=0.36............. Loss: -0.06266146, mean(E): -19.20866388-0.00111292j, var(E): 0.10807573
-0.0
tensor(14.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 20000/ t/epoch=0.37............. Loss: 0.07892691, mean(E): -19.22644269+0.00852470j, var(E): 0.08044765
-0.0
tensor(14.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 20000/ t/epoch=0.36............. Loss: -0.08351652, mean(E): -19.19060627+0.00122183j, var(E): 0.16123838
-0.0
tensor(14.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 20000/ t/epoch=0.36............. Loss: -0.03325703, mean(E): -19.18469221+0.00955460j, var(E): 0.16094656
-0.0
tensor(14.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 20000/ t/epoch=0.36............. Loss: -0.03332959, mean(E): -19.21111431+0.00829965j, var(E): 0.14263073
-0.0
tensor(14.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 20000/ t/epoch=0.36............. Loss: -0.06202253, mean(E): -19.21233972+0.00570045j, var(E): 0.20100791
-0.0
tensor(14.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 20000/ t/epoch=0.37............. Loss: -0.11607408, mean(E): -19.20531963+0.00570164j, var(E): 0.10227754
-0.0
tensor(14.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 20000/ t/epoch=0.36............. Loss: -0.05127488, mean(E): -19.19185390-0.01137512j, var(E): 0.13761168
-0.0
tensor(14.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 20000/ t/epoch=0.36............. Loss: -0.08411475, mean(E): -19.21793993+0.01348429j, var(E): 0.15765768
-0.0
tensor(14.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 20000/ t/epoch=0.36............. Loss: -0.20143956, mean(E): -19.15570680-0.00528310j, var(E): 0.17142156
-0.0
tensor(14.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 20000/ t/epoch=0.37............. Loss: 0.08121816, mean(E): -19.22030662-0.00414969j, var(E): 0.11882608
-0.0
tensor(14.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 20000/ t/epoch=0.37............. Loss: 0.16140183, mean(E): -19.20948771-0.00008842j, var(E): 0.14480409
-0.0
tensor(14.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 20000/ t/epoch=0.36............. Loss: -0.11655201, mean(E): -19.20854142+0.00231273j, var(E): 0.16501062
-0.0
tensor(14.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 20000/ t/epoch=0.36............. Loss: 0.11215041, mean(E): -19.20214451-0.00562215j, var(E): 0.13614362
-0.0
tensor(14.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 20000/ t/epoch=0.36............. Loss: 0.07514695, mean(E): -19.18295356+0.00435058j, var(E): 0.13238882
-0.0
tensor(14.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 20000/ t/epoch=0.36............. Loss: -0.29613264, mean(E): -19.15477207+0.00519239j, var(E): 0.17501358
-0.0
tensor(14.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 20000/ t/epoch=0.37............. Loss: -0.20986007, mean(E): -19.22105141-0.00616055j, var(E): 0.18613559
-0.0
tensor(14.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 20000/ t/epoch=0.36............. Loss: -0.25263384, mean(E): -19.17245123+0.00573300j, var(E): 0.15130583
-0.0
tensor(14.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 20000/ t/epoch=0.36............. Loss: -0.01881689, mean(E): -19.21661416+0.00724965j, var(E): 0.16650824
-0.0
tensor(14.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 20000/ t/epoch=0.37............. Loss: 0.12479813, mean(E): -19.22857567-0.00565410j, var(E): 0.12910905
-0.0
tensor(14.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 20000/ t/epoch=0.36............. Loss: -0.19619959, mean(E): -19.19235707-0.00115025j, var(E): 0.11845813
-0.0
tensor(14.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 20000/ t/epoch=0.37............. Loss: -0.08156650, mean(E): -19.21294707+0.00339866j, var(E): 0.13742915
-0.0
tensor(14.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 20000/ t/epoch=0.37............. Loss: -0.06430090, mean(E): -19.20469921-0.00101311j, var(E): 0.15598405
-0.0
tensor(14.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 20000/ t/epoch=0.37............. Loss: -0.14995163, mean(E): -19.18411653+0.00113017j, var(E): 0.12005652
-0.0
tensor(14.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 20000/ t/epoch=0.37............. Loss: -0.28830617, mean(E): -19.18462554+0.00874863j, var(E): 0.18061931
-0.0
tensor(14.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 20000/ t/epoch=0.36............. Loss: -0.08548219, mean(E): -19.14505189+0.00139527j, var(E): 0.17434893
-0.0
tensor(14.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 20000/ t/epoch=0.36............. Loss: 0.04197340, mean(E): -19.20338633-0.01767590j, var(E): 0.14095327
-0.0
tensor(14.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 20000/ t/epoch=0.36............. Loss: 0.09912465, mean(E): -19.18241949+0.00756502j, var(E): 0.14071140
-0.0
tensor(14.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 20000/ t/epoch=0.36............. Loss: 0.01380927, mean(E): -19.28316623+0.01137351j, var(E): 0.10798518
-0.0
tensor(14.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 20000/ t/epoch=0.37............. Loss: -0.07855680, mean(E): -19.16351750-0.00038551j, var(E): 0.13015076
-0.0
tensor(14.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 20000/ t/epoch=0.36............. Loss: -0.08355983, mean(E): -19.23874309-0.00206824j, var(E): 0.18518433
-0.0
tensor(14.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 20000/ t/epoch=0.36............. Loss: 0.13194181, mean(E): -19.14810491-0.00891025j, var(E): 0.14949516
-0.0
tensor(14.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 20000/ t/epoch=0.36............. Loss: 0.04072165, mean(E): -19.22503939-0.00250526j, var(E): 0.12884325
-0.0
tensor(14.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 20000/ t/epoch=0.36............. Loss: 0.21780444, mean(E): -19.20156534+0.00184480j, var(E): 0.13318171
-0.0
tensor(14.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 20000/ t/epoch=0.36............. Loss: 0.09804938, mean(E): -19.24557118-0.00585321j, var(E): 0.18621705
-0.0
tensor(14.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 20000/ t/epoch=0.36............. Loss: -0.26237490, mean(E): -19.18040771+0.00682226j, var(E): 0.14288328
-0.0
tensor(14.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 20000/ t/epoch=0.36............. Loss: 0.08315258, mean(E): -19.19938886-0.01419385j, var(E): 0.16762794
-0.0
tensor(14.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 20000/ t/epoch=0.36............. Loss: -0.06428247, mean(E): -19.18480865+0.00390770j, var(E): 0.10821536
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 20000/ t/epoch=0.36............. Loss: 0.10043262, mean(E): -19.20421953+0.00531399j, var(E): 0.16157071
-0.0
tensor(14.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 20000/ t/epoch=0.36............. Loss: 0.02917339, mean(E): -19.17978738+0.01367741j, var(E): 0.12624963
-0.0
tensor(14.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 20000/ t/epoch=0.36............. Loss: -0.22395522, mean(E): -19.15000375+0.01882464j, var(E): 0.17754139
-0.0
tensor(14.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 20000/ t/epoch=0.36............. Loss: -0.03718356, mean(E): -19.20999534+0.02153793j, var(E): 0.15278132
-0.0
tensor(14.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 20000/ t/epoch=0.36............. Loss: 0.07030142, mean(E): -19.21122325+0.00787184j, var(E): 0.12145083
-0.0
tensor(14.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 20000/ t/epoch=0.36............. Loss: -0.02355249, mean(E): -19.21328778+0.01016676j, var(E): 0.10935296
-0.0
tensor(14.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 20000/ t/epoch=0.36............. Loss: -0.14407547, mean(E): -19.20768795+0.01029216j, var(E): 0.15852857
-0.0
tensor(14.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 20000/ t/epoch=0.37............. Loss: 0.22219094, mean(E): -19.20194230+0.00565669j, var(E): 0.09684565
-0.0
tensor(14.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 20000/ t/epoch=0.36............. Loss: -0.20581399, mean(E): -19.18786829+0.01752324j, var(E): 0.27390657
-0.0
tensor(14.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 20000/ t/epoch=0.36............. Loss: -0.39075675, mean(E): -19.18460401-0.00836838j, var(E): 0.10891777
-0.0
tensor(14.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 20000/ t/epoch=0.36............. Loss: -0.21188137, mean(E): -19.19935723-0.00200147j, var(E): 0.09704228
-0.0
tensor(14.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 20000/ t/epoch=0.36............. Loss: -0.10115616, mean(E): -19.22375867+0.00621562j, var(E): 0.10387797
-0.0
tensor(14.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 20000/ t/epoch=0.37............. Loss: -0.10397824, mean(E): -19.22390420-0.02238475j, var(E): 0.13508869
-0.0
tensor(14.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 20000/ t/epoch=0.36............. Loss: 0.00889493, mean(E): -19.23750274+0.00290538j, var(E): 0.17283108
-0.0
tensor(14.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 20000/ t/epoch=0.36............. Loss: -0.02060499, mean(E): -19.21163494-0.00526656j, var(E): 0.15114260
-0.0
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 20000/ t/epoch=0.36............. Loss: -0.03517226, mean(E): -19.23410529+0.01171475j, var(E): 0.13272026
-0.0
tensor(14.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 20000/ t/epoch=0.36............. Loss: -0.05355791, mean(E): -19.21668945-0.00507528j, var(E): 0.11114240
-0.0
tensor(14.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 20000/ t/epoch=0.36............. Loss: 0.03897549, mean(E): -19.21062216-0.00888598j, var(E): 0.12665514
-0.0
tensor(14.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 20000/ t/epoch=0.37............. Loss: -0.13707400, mean(E): -19.18699518-0.00421845j, var(E): 0.25111923
-0.0
tensor(14.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 20000/ t/epoch=0.36............. Loss: -0.06408385, mean(E): -19.13888685+0.01123645j, var(E): 0.15666503
-0.0
tensor(14.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 20000/ t/epoch=0.37............. Loss: -0.14494108, mean(E): -19.19160463-0.00447906j, var(E): 0.19135873
-0.0
tensor(14.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 20000/ t/epoch=0.36............. Loss: -0.13785224, mean(E): -19.17966789-0.01369250j, var(E): 0.15417879
-0.0
tensor(14.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 20000/ t/epoch=0.36............. Loss: 0.03659462, mean(E): -19.22497293+0.00423882j, var(E): 0.17826888
-0.0
tensor(14.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 20000/ t/epoch=0.36............. Loss: -0.10717880, mean(E): -19.22255583-0.02014588j, var(E): 0.18593746
-0.0
tensor(14.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 20000/ t/epoch=0.36............. Loss: 0.04237105, mean(E): -19.17841355+0.01555932j, var(E): 0.11487392
-0.0
tensor(14.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 20000/ t/epoch=0.37............. Loss: 0.05711173, mean(E): -19.21430766+0.02135638j, var(E): 0.14139565
-0.0
tensor(14.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 20000/ t/epoch=0.36............. Loss: -0.05411361, mean(E): -19.20177447+0.01375832j, var(E): 0.15130938
-0.0
tensor(14.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 20000/ t/epoch=0.36............. Loss: -0.05507500, mean(E): -19.17495916-0.00756775j, var(E): 0.27518264
-0.0
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 20000/ t/epoch=0.36............. Loss: 0.25928750, mean(E): -19.24483838+0.01596837j, var(E): 0.13509443
-0.0
tensor(14.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 20000/ t/epoch=0.36............. Loss: -0.02310438, mean(E): -19.22707283+0.00780415j, var(E): 0.12475193
-0.0
tensor(14.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 20000/ t/epoch=0.36............. Loss: -0.01808937, mean(E): -19.23011082-0.00753768j, var(E): 0.11312640
-0.0
tensor(14.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 20000/ t/epoch=0.36............. Loss: -0.10618500, mean(E): -19.18875688+0.00385311j, var(E): 0.15305855
-0.0
tensor(14.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 20000/ t/epoch=0.36............. Loss: -0.20425427, mean(E): -19.15886393+0.00612511j, var(E): 0.15106765
-0.0
tensor(14.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 20000/ t/epoch=0.37............. Loss: -0.05241102, mean(E): -19.18126560-0.00190939j, var(E): 0.13591373
-0.0
tensor(14.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 20000/ t/epoch=0.36............. Loss: 0.10466118, mean(E): -19.22568027+0.00082051j, var(E): 0.16479424
-0.0
tensor(14.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 20000/ t/epoch=0.36............. Loss: -0.14435897, mean(E): -19.19926193+0.00204102j, var(E): 0.12390579
-0.0
tensor(14.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 20000/ t/epoch=0.37............. Loss: 0.03266081, mean(E): -19.19969226+0.00468395j, var(E): 0.11283825
-0.0
tensor(14.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 20000/ t/epoch=0.37............. Loss: -0.30474160, mean(E): -19.20842121+0.01613691j, var(E): 0.14364503
-0.0
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 20000/ t/epoch=0.37............. Loss: 0.07379387, mean(E): -19.24254124+0.01113283j, var(E): 0.16561600
-0.0
tensor(14.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 20000/ t/epoch=0.36............. Loss: 0.06228078, mean(E): -19.22761251+0.00537711j, var(E): 0.12602969
-0.0
tensor(14.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 20000/ t/epoch=0.36............. Loss: 0.00984343, mean(E): -19.18756332+0.01182381j, var(E): 0.14852115
-0.0
tensor(14.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 20000/ t/epoch=0.36............. Loss: 0.05692242, mean(E): -19.20182426+0.00784964j, var(E): 0.18320833
-0.0
tensor(14.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 20000/ t/epoch=0.37............. Loss: -0.06825580, mean(E): -19.21785817-0.00832074j, var(E): 0.16879258
-0.0
tensor(14.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 20000/ t/epoch=0.36............. Loss: -0.14124515, mean(E): -19.18066599+0.01052352j, var(E): 0.17339937
-0.0
tensor(14.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 20000/ t/epoch=0.36............. Loss: -0.11231557, mean(E): -19.19503885+0.00042951j, var(E): 0.13982598
-0.0
tensor(14.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 20000/ t/epoch=0.37............. Loss: 0.06077711, mean(E): -19.21424109+0.00672624j, var(E): 0.17133713
-0.0
tensor(14.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 20000/ t/epoch=0.36............. Loss: 0.10659344, mean(E): -19.24340292+0.02359443j, var(E): 0.13468971
-0.0
tensor(14.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 20000/ t/epoch=0.36............. Loss: 0.09412767, mean(E): -19.18159380+0.01657466j, var(E): 0.10590640
-0.0
tensor(14.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 20000/ t/epoch=0.36............. Loss: 0.29990816, mean(E): -19.22567680-0.01207861j, var(E): 0.11029272
-0.0
tensor(14.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 20000/ t/epoch=0.37............. Loss: -0.00656397, mean(E): -19.17932954-0.00696406j, var(E): 0.13289004
-0.0
tensor(14.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 20000/ t/epoch=0.36............. Loss: 0.10748428, mean(E): -19.20718977+0.00291468j, var(E): 0.12340978
-0.0
tensor(14.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 20000/ t/epoch=0.36............. Loss: 0.22984537, mean(E): -19.22728851+0.00368651j, var(E): 0.14535966
-0.0
tensor(14.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 20000/ t/epoch=0.36............. Loss: -0.20848269, mean(E): -19.16919782-0.01386033j, var(E): 0.10591751
-0.0
tensor(14.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 20000/ t/epoch=0.36............. Loss: 0.03474216, mean(E): -19.20635680+0.02238621j, var(E): 0.13811509
-0.0
tensor(14.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 20000/ t/epoch=0.36............. Loss: -0.01628228, mean(E): -19.18078280-0.00156520j, var(E): 0.12862774
-0.0
tensor(14.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 20000/ t/epoch=0.36............. Loss: 0.28752173, mean(E): -19.25501585-0.00011985j, var(E): 0.16954161
-0.0
tensor(14.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 20000/ t/epoch=0.37............. Loss: 0.06272361, mean(E): -19.24955791-0.00447184j, var(E): 0.13076366
-0.0
tensor(14.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 20000/ t/epoch=0.36............. Loss: -0.32215077, mean(E): -19.17989665+0.00271702j, var(E): 0.15786119
-0.0
tensor(14.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 20000/ t/epoch=0.37............. Loss: 0.07822064, mean(E): -19.18314421+0.01703009j, var(E): 0.19407740
-0.0
tensor(14.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 20000/ t/epoch=0.36............. Loss: -0.05185277, mean(E): -19.19358262-0.00487764j, var(E): 0.16513113
-0.0
tensor(14.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 20000/ t/epoch=0.36............. Loss: 0.01526321, mean(E): -19.22239080+0.00727887j, var(E): 0.19972150
-0.0
tensor(14.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 20000/ t/epoch=0.37............. Loss: -0.06210093, mean(E): -19.21099086+0.00929435j, var(E): 0.13028600
-0.0
tensor(14.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 20000/ t/epoch=0.36............. Loss: -0.07162706, mean(E): -19.19092463-0.02595984j, var(E): 0.21686407
-0.0
tensor(14.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 20000/ t/epoch=0.36............. Loss: 0.02704828, mean(E): -19.21106298-0.00436721j, var(E): 0.12198233
-0.0
tensor(14.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 20000/ t/epoch=0.36............. Loss: 0.15413938, mean(E): -19.18283714-0.00150610j, var(E): 0.18842970
-0.0
tensor(14.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 20000/ t/epoch=0.37............. Loss: 0.09105211, mean(E): -19.17147807+0.02392619j, var(E): 0.14281458
-0.0
tensor(14.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 20000/ t/epoch=0.36............. Loss: 0.04710652, mean(E): -19.22492348+0.00341674j, var(E): 0.13317417
-0.0
tensor(14.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 20000/ t/epoch=0.37............. Loss: -0.09387717, mean(E): -19.21517943+0.00087279j, var(E): 0.11303200
-0.0
tensor(14.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 20000/ t/epoch=0.36............. Loss: 0.09442273, mean(E): -19.24197384-0.01459862j, var(E): 0.18478805
-0.0
tensor(14.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 20000/ t/epoch=0.36............. Loss: 0.08905371, mean(E): -19.22272900+0.00749366j, var(E): 0.14152389
-0.0
tensor(14.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 20000/ t/epoch=0.36............. Loss: -0.06118081, mean(E): -19.20962791-0.00005761j, var(E): 0.08635487
-0.0
tensor(14.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 20000/ t/epoch=0.36............. Loss: 0.05197189, mean(E): -19.18507613-0.00678300j, var(E): 0.15625668
-0.0
tensor(14.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 20000/ t/epoch=0.37............. Loss: 0.09284333, mean(E): -19.23597512+0.01280335j, var(E): 0.17530605
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 20000/ t/epoch=0.36............. Loss: 0.13643542, mean(E): -19.20529813-0.00939669j, var(E): 0.21698527
-0.0
tensor(14.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 20000/ t/epoch=0.36............. Loss: -0.11122693, mean(E): -19.17825050+0.01303725j, var(E): 0.14392752
-0.0
tensor(14.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 20000/ t/epoch=0.36............. Loss: -0.00435411, mean(E): -19.20096000-0.00546970j, var(E): 0.11364825
-0.0
tensor(14.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 20000/ t/epoch=0.36............. Loss: 0.05254260, mean(E): -19.20614650-0.01320211j, var(E): 0.17836091
-0.0
tensor(14.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 20000/ t/epoch=0.37............. Loss: -0.09588773, mean(E): -19.20064044+0.00043560j, var(E): 0.24340305
-0.0
tensor(14.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 20000/ t/epoch=0.37............. Loss: -0.11942405, mean(E): -19.23436369+0.01866942j, var(E): 0.15767146
-0.0
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 20000/ t/epoch=0.36............. Loss: 0.07391581, mean(E): -19.24772829+0.01798025j, var(E): 0.18656630
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 20000/ t/epoch=0.37............. Loss: 0.09236013, mean(E): -19.21635139+0.00761059j, var(E): 0.20919968
-0.0
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 20000/ t/epoch=0.36............. Loss: 0.37054713, mean(E): -19.26716881+0.01572609j, var(E): 0.14481865
-0.0
tensor(14.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 20000/ t/epoch=0.36............. Loss: 0.09811715, mean(E): -19.23846396+0.00039396j, var(E): 0.12224411
-0.0
tensor(14.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 20000/ t/epoch=0.37............. Loss: -0.05989214, mean(E): -19.17351699-0.00438567j, var(E): 0.17024567
-0.0
tensor(14.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 20000/ t/epoch=0.37............. Loss: -0.02025512, mean(E): -19.21208130+0.00456875j, var(E): 0.17976678
-0.0
tensor(14.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 20000/ t/epoch=0.37............. Loss: -0.12596839, mean(E): -19.20980034-0.00383605j, var(E): 0.12083387
-0.0
tensor(14.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 20000/ t/epoch=0.37............. Loss: -0.20511390, mean(E): -19.17952770+0.00497292j, var(E): 0.14637267
-0.0
tensor(14.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 20000/ t/epoch=0.37............. Loss: 0.16230733, mean(E): -19.20297595+0.00356788j, var(E): 0.13084205
-0.0
tensor(14.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 20000/ t/epoch=0.37............. Loss: 0.15122785, mean(E): -19.21679598+0.00310577j, var(E): 0.12804222
-0.0
tensor(14.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 20000/ t/epoch=0.37............. Loss: 0.02272490, mean(E): -19.18454860-0.02054894j, var(E): 0.18505262
-0.0
tensor(14.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 20000/ t/epoch=0.37............. Loss: -0.01913537, mean(E): -19.19361787-0.00025304j, var(E): 0.14137450
-0.0
tensor(14.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 20000/ t/epoch=0.36............. Loss: 0.02970440, mean(E): -19.19575083+0.00596548j, var(E): 0.11815376
-0.0
tensor(14.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 20000/ t/epoch=0.37............. Loss: -0.14375295, mean(E): -19.21513130+0.00465439j, var(E): 0.14795845
-0.0
tensor(14.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 20000/ t/epoch=0.37............. Loss: -0.00501465, mean(E): -19.22634110-0.00557792j, var(E): 0.13647048
-0.0
tensor(14.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 20000/ t/epoch=0.37............. Loss: -0.09541708, mean(E): -19.19815837+0.00780125j, var(E): 0.16800002
-0.0
tensor(14.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 20000/ t/epoch=0.37............. Loss: -0.18473507, mean(E): -19.19895262-0.00406074j, var(E): 0.10361852
-0.0
tensor(14.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 20000/ t/epoch=0.37............. Loss: 0.11377469, mean(E): -19.24231110+0.01117925j, var(E): 0.09172061
-0.0
tensor(14.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 20000/ t/epoch=0.36............. Loss: -0.11351396, mean(E): -19.19941187+0.00607008j, var(E): 0.16335896
-0.0
tensor(14.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 20000/ t/epoch=0.37............. Loss: 0.03234998, mean(E): -19.22667305-0.00637732j, var(E): 0.10370814
-0.0
tensor(14.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 20000/ t/epoch=0.37............. Loss: -0.15591595, mean(E): -19.22041797+0.01950791j, var(E): 0.25307320
-0.0
tensor(14.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 20000/ t/epoch=0.36............. Loss: -0.19263241, mean(E): -19.20185093-0.00017933j, var(E): 0.12142841
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 20000/ t/epoch=0.37............. Loss: 0.18418142, mean(E): -19.22456726+0.01078109j, var(E): 0.20205906
-0.0
tensor(14.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 20000/ t/epoch=0.36............. Loss: 0.01726085, mean(E): -19.19187007-0.00069642j, var(E): 0.21556026
-0.0
tensor(14.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 20000/ t/epoch=0.36............. Loss: -0.17489499, mean(E): -19.21144390-0.00173704j, var(E): 0.14832501
-0.0
tensor(14.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 20000/ t/epoch=0.36............. Loss: 0.09096588, mean(E): -19.20274594+0.00557159j, var(E): 0.13545628
-0.0
tensor(14.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 20000/ t/epoch=0.37............. Loss: -0.20430996, mean(E): -19.19440524+0.01414988j, var(E): 0.12230727
-0.0
tensor(14.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 20000/ t/epoch=0.36............. Loss: 0.26768116, mean(E): -19.22036971-0.00989550j, var(E): 0.10536739
-0.0
tensor(14.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 20000/ t/epoch=0.36............. Loss: -0.14608890, mean(E): -19.13550064-0.01826994j, var(E): 0.20536558
-0.0
tensor(14.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 20000/ t/epoch=0.37............. Loss: 0.10845293, mean(E): -19.25867730-0.00113534j, var(E): 0.16316953
-0.0
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 20000/ t/epoch=0.37............. Loss: -0.07411267, mean(E): -19.23080548+0.00968217j, var(E): 0.08869957
-0.0
tensor(14.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 20000/ t/epoch=0.36............. Loss: -0.18650258, mean(E): -19.18797821+0.00610561j, var(E): 0.15474043
-0.0
tensor(14.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 20000/ t/epoch=0.37............. Loss: 0.11996113, mean(E): -19.19438880-0.00238095j, var(E): 0.17833741
-0.0
tensor(14.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 20000/ t/epoch=0.37............. Loss: -0.07801560, mean(E): -19.21401943-0.00345547j, var(E): 0.12032399
-0.0
tensor(14.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 20000/ t/epoch=0.37............. Loss: -0.23390149, mean(E): -19.21380424+0.01457196j, var(E): 0.12532092
-0.0
tensor(14.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 20000/ t/epoch=0.37............. Loss: -0.02198065, mean(E): -19.23096461+0.00426599j, var(E): 0.14362573
-0.0
tensor(14.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 20000/ t/epoch=0.37............. Loss: 0.10389006, mean(E): -19.23372963+0.00086119j, var(E): 0.14279057
-0.0
tensor(14.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 20000/ t/epoch=0.36............. Loss: 0.15298073, mean(E): -19.23470380+0.00063386j, var(E): 0.10755519
-0.0
tensor(14.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 20000/ t/epoch=0.36............. Loss: -0.23186286, mean(E): -19.17481019-0.00566927j, var(E): 0.21646311
-0.0
tensor(14.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 20000/ t/epoch=0.37............. Loss: -0.01597355, mean(E): -19.21724813-0.00953890j, var(E): 0.13694762
-0.0
tensor(14.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 20000/ t/epoch=0.37............. Loss: -0.25317021, mean(E): -19.18229130-0.00157112j, var(E): 0.17572142
-0.0
tensor(14.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 20000/ t/epoch=0.37............. Loss: 0.10783634, mean(E): -19.23496079-0.01033956j, var(E): 0.16001374
-0.0
tensor(14.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 20000/ t/epoch=0.37............. Loss: 0.02459724, mean(E): -19.20386876+0.01526810j, var(E): 0.16715665
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 20000/ t/epoch=0.37............. Loss: 0.08101503, mean(E): -19.18902657+0.00013396j, var(E): 0.18038266
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 20000/ t/epoch=0.37............. Loss: 0.04002599, mean(E): -19.22555507+0.00440057j, var(E): 0.19738144
-0.0
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 20000/ t/epoch=0.36............. Loss: 0.09296163, mean(E): -19.19637447+0.00515456j, var(E): 0.12689586
-0.0
tensor(14.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 20000/ t/epoch=0.36............. Loss: -0.16409738, mean(E): -19.18860652+0.00573845j, var(E): 0.12918122
-0.0
tensor(14.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 20000/ t/epoch=0.36............. Loss: -0.12911992, mean(E): -19.19162302-0.02337211j, var(E): 0.12039145
-0.0
tensor(14.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 20000/ t/epoch=0.36............. Loss: 0.04115971, mean(E): -19.17455287-0.00392991j, var(E): 0.12799293
-0.0
tensor(14.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 20000/ t/epoch=0.36............. Loss: -0.02289089, mean(E): -19.20840336+0.00166815j, var(E): 0.20577867
-0.0
tensor(14.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 20000/ t/epoch=0.37............. Loss: -0.03123536, mean(E): -19.19693957-0.00858474j, var(E): 0.08765693
-0.0
tensor(14.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 20000/ t/epoch=0.36............. Loss: -0.08932803, mean(E): -19.22351295+0.00444506j, var(E): 0.23820504
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 20000/ t/epoch=0.37............. Loss: -0.20835140, mean(E): -19.15216017-0.00236357j, var(E): 0.12847136
-0.0
tensor(14.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 20000/ t/epoch=0.37............. Loss: -0.07984145, mean(E): -19.21746379-0.00055967j, var(E): 0.13846199
-0.0
tensor(14.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 20000/ t/epoch=0.36............. Loss: 0.12491684, mean(E): -19.23511673+0.01340256j, var(E): 0.13069155
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 20000/ t/epoch=0.36............. Loss: -0.13238872, mean(E): -19.22169962+0.00388741j, var(E): 0.07679503
-0.0
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 20000/ t/epoch=0.36............. Loss: -0.08116302, mean(E): -19.19941396-0.01007088j, var(E): 0.13670193
-0.0
tensor(14.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 20000/ t/epoch=0.36............. Loss: -0.08770331, mean(E): -19.19884470+0.00145961j, var(E): 0.22348898
-0.0
tensor(14.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 20000/ t/epoch=0.36............. Loss: -0.04576587, mean(E): -19.22621900+0.00535032j, var(E): 0.15474152
-0.0
tensor(14.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 20000/ t/epoch=0.36............. Loss: 0.18858407, mean(E): -19.24254391+0.00624326j, var(E): 0.08846318
-0.0
tensor(14.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 20000/ t/epoch=0.36............. Loss: 0.23477973, mean(E): -19.23603603-0.00427264j, var(E): 0.12402352
-0.0
tensor(14.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 20000/ t/epoch=0.37............. Loss: 0.07290278, mean(E): -19.22175270+0.00200615j, var(E): 0.11788493
-0.0
tensor(14.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 20000/ t/epoch=0.37............. Loss: 0.04587572, mean(E): -19.19557841-0.00289585j, var(E): 0.10061902
-0.0
tensor(14.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 20000/ t/epoch=0.37............. Loss: 0.23592009, mean(E): -19.26227022+0.00956408j, var(E): 0.12186454
-0.0
tensor(14.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 20000/ t/epoch=0.37............. Loss: 0.09245474, mean(E): -19.20802269-0.00783962j, var(E): 0.10756454
-0.0
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 20000/ t/epoch=0.37............. Loss: 0.05235297, mean(E): -19.19611027+0.00264972j, var(E): 0.17304946
-0.0
tensor(14.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 20000/ t/epoch=0.36............. Loss: -0.10075678, mean(E): -19.21055531-0.00320679j, var(E): 0.10552834
-0.0
tensor(14.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 20000/ t/epoch=0.37............. Loss: 0.04713021, mean(E): -19.20063209-0.00278831j, var(E): 0.10391991
-0.0
tensor(14.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 20000/ t/epoch=0.38............. Loss: 0.19074901, mean(E): -19.22896157+0.00088482j, var(E): 0.16084265
-0.0
tensor(14.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 20000/ t/epoch=0.37............. Loss: 0.10846392, mean(E): -19.19533495-0.00293359j, var(E): 0.13025975
-0.0
tensor(14.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 20000/ t/epoch=0.37............. Loss: -0.00111172, mean(E): -19.25107263+0.02169298j, var(E): 0.10573047
-0.0
tensor(14.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 20000/ t/epoch=0.37............. Loss: -0.19942315, mean(E): -19.19373159-0.00463984j, var(E): 0.13830489
-0.0
tensor(14.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 20000/ t/epoch=0.37............. Loss: -0.02943544, mean(E): -19.18456270-0.00599381j, var(E): 0.18096349
-0.0
tensor(14.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 20000/ t/epoch=0.37............. Loss: 0.11575378, mean(E): -19.24885722+0.01900819j, var(E): 0.13362742
-0.0
tensor(14.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 20000/ t/epoch=0.37............. Loss: -0.00207189, mean(E): -19.20393689-0.01080858j, var(E): 0.10158745
-0.0
tensor(14.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 20000/ t/epoch=0.37............. Loss: -0.10589914, mean(E): -19.19993680+0.02191202j, var(E): 0.10639994
-0.0
tensor(14.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 20000/ t/epoch=0.37............. Loss: -0.09847032, mean(E): -19.21291924+0.00212585j, var(E): 0.12034338
-0.0
tensor(14.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 20000/ t/epoch=0.37............. Loss: -0.15650238, mean(E): -19.22997296-0.00078582j, var(E): 0.14242805
-0.0
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 20000/ t/epoch=0.37............. Loss: 0.16983081, mean(E): -19.21597316+0.00399526j, var(E): 0.15159259
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 20000/ t/epoch=0.37............. Loss: -0.09311003, mean(E): -19.21249315-0.00259915j, var(E): 0.08342220
-0.0
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 20000/ t/epoch=0.37............. Loss: -0.43120508, mean(E): -19.16658106+0.00056307j, var(E): 0.25261879
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 20000/ t/epoch=0.37............. Loss: 0.00009171, mean(E): -19.20850501-0.00023802j, var(E): 0.15913635
-0.0
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 20000/ t/epoch=0.37............. Loss: 0.20435597, mean(E): -19.23110306+0.00259479j, var(E): 0.15186266
-0.0
tensor(14.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 20000/ t/epoch=0.37............. Loss: -0.21157869, mean(E): -19.18790588+0.00544966j, var(E): 0.10105486
-0.0
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 20000/ t/epoch=0.37............. Loss: 0.08700281, mean(E): -19.24181481-0.00465216j, var(E): 0.13575568
-0.0
tensor(14.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 20000/ t/epoch=0.38............. Loss: 0.06258410, mean(E): -19.23454891-0.00351620j, var(E): 0.22388552
-0.0
tensor(14.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 20000/ t/epoch=0.37............. Loss: -0.18264586, mean(E): -19.18192469+0.02121169j, var(E): 0.12419395
-0.0
tensor(14.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 20000/ t/epoch=0.37............. Loss: -0.18215887, mean(E): -19.19484114+0.00524992j, var(E): 0.09345157
-0.0
tensor(14.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 20000/ t/epoch=0.37............. Loss: -0.08043442, mean(E): -19.20728198+0.01739446j, var(E): 0.12538514
-0.0
tensor(14.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 20000/ t/epoch=0.37............. Loss: -0.22009105, mean(E): -19.20710889+0.00645078j, var(E): 0.09127848
-0.0
tensor(14.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 20000/ t/epoch=0.37............. Loss: -0.25615638, mean(E): -19.18354291-0.00296020j, var(E): 0.11460457
-0.0
tensor(14.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 20000/ t/epoch=0.37............. Loss: 0.05381313, mean(E): -19.21505745+0.00902796j, var(E): 0.10426200
-0.0
tensor(14.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 20000/ t/epoch=0.37............. Loss: -0.04754944, mean(E): -19.21967030+0.00051553j, var(E): 0.13134399
-0.0
tensor(14.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 20000/ t/epoch=0.37............. Loss: 0.09803434, mean(E): -19.22650573+0.01188439j, var(E): 0.12989637
-0.0
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 20000/ t/epoch=0.37............. Loss: -0.20314690, mean(E): -19.17078365-0.01215920j, var(E): 0.11368634
-0.0
tensor(14.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 20000/ t/epoch=0.37............. Loss: -0.19020008, mean(E): -19.19927012+0.00167830j, var(E): 0.10772718
-0.0
tensor(14.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 20000/ t/epoch=0.37............. Loss: 0.02980245, mean(E): -19.25231143-0.00388005j, var(E): 0.14864256
-0.0
tensor(14.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 20000/ t/epoch=0.37............. Loss: -0.00566065, mean(E): -19.24360531+0.00867493j, var(E): 0.10689865
-0.0
tensor(14.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 20000/ t/epoch=0.37............. Loss: 0.09846545, mean(E): -19.22984854+0.01441081j, var(E): 0.11726981
-0.0
tensor(14.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 20000/ t/epoch=0.37............. Loss: -0.34748605, mean(E): -19.18137864-0.00195427j, var(E): 0.10128015
-0.0
tensor(14.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 20000/ t/epoch=0.37............. Loss: 0.02757773, mean(E): -19.20065774+0.00057607j, var(E): 0.16745274
-0.0
tensor(14.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 20000/ t/epoch=0.37............. Loss: 0.01022850, mean(E): -19.21793748-0.00817102j, var(E): 0.13336536
-0.0
tensor(14.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 20000/ t/epoch=0.37............. Loss: -0.28808186, mean(E): -19.18794385-0.00405836j, var(E): 0.09761888
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 20000/ t/epoch=0.37............. Loss: -0.14549726, mean(E): -19.20235027-0.00184799j, var(E): 0.08853790
-0.0
tensor(14.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 20000/ t/epoch=0.37............. Loss: -0.02990016, mean(E): -19.19270182+0.00481349j, var(E): 0.16199173
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 20000/ t/epoch=0.37............. Loss: -0.04236040, mean(E): -19.21532034+0.00889448j, var(E): 0.19484728
-0.0
tensor(14.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 20000/ t/epoch=0.37............. Loss: 0.19465938, mean(E): -19.23232151+0.00939337j, var(E): 0.09310944
-0.0
tensor(14.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 20000/ t/epoch=0.37............. Loss: 0.17414121, mean(E): -19.23447304+0.00797459j, var(E): 0.09669246
-0.0
tensor(14.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 20000/ t/epoch=0.37............. Loss: -0.18145566, mean(E): -19.18771433-0.00658861j, var(E): 0.11006130
-0.0
tensor(14.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 20000/ t/epoch=0.37............. Loss: 0.04203580, mean(E): -19.20341647+0.00596180j, var(E): 0.11013655
-0.0
tensor(14.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 20000/ t/epoch=0.37............. Loss: -0.08873721, mean(E): -19.21294568-0.00255129j, var(E): 0.12319558
-0.0
tensor(14.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 20000/ t/epoch=0.37............. Loss: 0.02266141, mean(E): -19.21470462-0.00125941j, var(E): 0.11238369
-0.0
tensor(14.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 20000/ t/epoch=0.37............. Loss: -0.04614532, mean(E): -19.20583676-0.00231775j, var(E): 0.13046416
-0.0
tensor(14.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 20000/ t/epoch=0.37............. Loss: -0.25492364, mean(E): -19.15694475+0.00321870j, var(E): 0.16007811
-0.0
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 20000/ t/epoch=0.37............. Loss: -0.06739270, mean(E): -19.21753715+0.00383228j, var(E): 0.17015852
-0.0
tensor(14.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 20000/ t/epoch=0.37............. Loss: -0.11790448, mean(E): -19.20199331+0.00971114j, var(E): 0.19384824
-0.0
tensor(14.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 20000/ t/epoch=0.37............. Loss: 0.15329063, mean(E): -19.23906437-0.02211814j, var(E): 0.21660047
-0.0
tensor(14.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 20000/ t/epoch=0.37............. Loss: -0.08277971, mean(E): -19.19741327-0.01376252j, var(E): 0.11567312
-0.0
tensor(14.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 20000/ t/epoch=0.37............. Loss: 0.02549385, mean(E): -19.22422526+0.00708618j, var(E): 0.16134455
-0.0
tensor(14.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 20000/ t/epoch=0.37............. Loss: -0.11732906, mean(E): -19.20884471-0.00657960j, var(E): 0.12425181
-0.0
tensor(14.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 20000/ t/epoch=0.37............. Loss: 0.10577761, mean(E): -19.23633254+0.00021401j, var(E): 0.16648085
-0.0
tensor(14.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 20000/ t/epoch=0.37............. Loss: 0.19596800, mean(E): -19.20678221+0.01185001j, var(E): 0.12750159
-0.0
tensor(14.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 20000/ t/epoch=0.36............. Loss: 0.19607281, mean(E): -19.22889634+0.01357466j, var(E): 0.11055613
-0.0
tensor(14.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 20000/ t/epoch=0.37............. Loss: 0.21688064, mean(E): -19.22631432+0.01729657j, var(E): 0.13091648
-0.0
tensor(14.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 20000/ t/epoch=0.37............. Loss: 0.08737355, mean(E): -19.22615571+0.00540451j, var(E): 0.10260566
-0.0
tensor(14.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 20000/ t/epoch=0.37............. Loss: -0.29302941, mean(E): -19.21356478+0.00187492j, var(E): 0.10894297
-0.0
tensor(14.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 20000/ t/epoch=0.37............. Loss: -0.09318808, mean(E): -19.19320164-0.00859873j, var(E): 0.08640814
-0.0
tensor(14.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 20000/ t/epoch=0.37............. Loss: -0.05445512, mean(E): -19.22805939-0.00922351j, var(E): 0.11957790
-0.0
tensor(14.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10010/ 20000/ t/epoch=0.37............. Loss: -0.14037529, mean(E): -19.20472577+0.00741452j, var(E): 0.16753454
-0.0
tensor(14.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10020/ 20000/ t/epoch=0.37............. Loss: 0.04956885, mean(E): -19.18713889+0.00143750j, var(E): 0.13207723
-0.0
tensor(14.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10030/ 20000/ t/epoch=0.37............. Loss: 0.07773973, mean(E): -19.21218119+0.00537635j, var(E): 0.11944577
-0.0
tensor(14.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10040/ 20000/ t/epoch=0.37............. Loss: -0.13852948, mean(E): -19.21611046-0.00393742j, var(E): 0.14534280
-0.0
tensor(14.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10050/ 20000/ t/epoch=0.37............. Loss: -0.09636975, mean(E): -19.18792269+0.01337771j, var(E): 0.12862443
-0.0
tensor(14.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10060/ 20000/ t/epoch=0.37............. Loss: -0.43909138, mean(E): -19.20805208+0.00256057j, var(E): 0.09058489
-0.0
tensor(14.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10070/ 20000/ t/epoch=0.37............. Loss: -0.13835130, mean(E): -19.22921412-0.00333721j, var(E): 0.11675627
-0.0
tensor(14.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10080/ 20000/ t/epoch=0.37............. Loss: -0.15371797, mean(E): -19.18253111-0.00649087j, var(E): 0.12564606
-0.0
tensor(14.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10090/ 20000/ t/epoch=0.37............. Loss: -0.16992970, mean(E): -19.19667761-0.01778865j, var(E): 0.11222452
-0.0
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10100/ 20000/ t/epoch=0.37............. Loss: -0.06622713, mean(E): -19.19173536+0.00699896j, var(E): 0.12037528
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10110/ 20000/ t/epoch=0.37............. Loss: 0.27401748, mean(E): -19.26260348+0.00277011j, var(E): 0.15689587
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10120/ 20000/ t/epoch=0.37............. Loss: -0.11684365, mean(E): -19.22367805+0.00819623j, var(E): 0.14142365
-0.0
tensor(14.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10130/ 20000/ t/epoch=0.37............. Loss: 0.09552625, mean(E): -19.21158331+0.01387806j, var(E): 0.12721189
-0.0
tensor(14.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10140/ 20000/ t/epoch=0.37............. Loss: -0.08779079, mean(E): -19.16870904-0.00792747j, var(E): 0.12657644
-0.0
tensor(14.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10150/ 20000/ t/epoch=0.37............. Loss: 0.02599683, mean(E): -19.19922423+0.00723649j, var(E): 0.07329750
-0.0
tensor(14.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10160/ 20000/ t/epoch=0.37............. Loss: -0.16294703, mean(E): -19.22122173+0.00115928j, var(E): 0.13228932
-0.0
tensor(14.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10170/ 20000/ t/epoch=0.37............. Loss: -0.03874910, mean(E): -19.20306030+0.00366771j, var(E): 0.16125824
-0.0
tensor(14.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10180/ 20000/ t/epoch=0.37............. Loss: -0.31369987, mean(E): -19.18704813-0.00764632j, var(E): 0.09962853
-0.0
tensor(14.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10190/ 20000/ t/epoch=0.37............. Loss: -0.02703688, mean(E): -19.16447027+0.00112398j, var(E): 0.11481597
-0.0
tensor(14.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10200/ 20000/ t/epoch=0.37............. Loss: 0.11025521, mean(E): -19.20588007-0.00347625j, var(E): 0.10642573
-0.0
tensor(14.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10210/ 20000/ t/epoch=0.37............. Loss: 0.05379662, mean(E): -19.21643377+0.00427729j, var(E): 0.12736123
-0.0
tensor(14.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10220/ 20000/ t/epoch=0.37............. Loss: 0.25890122, mean(E): -19.25858486+0.01446329j, var(E): 0.17618449
-0.0
tensor(14.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10230/ 20000/ t/epoch=0.37............. Loss: 0.02996757, mean(E): -19.22136269+0.00460190j, var(E): 0.13034733
-0.0
tensor(14.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10240/ 20000/ t/epoch=0.37............. Loss: -0.02773997, mean(E): -19.23551553-0.02255230j, var(E): 0.09293687
-0.0
tensor(14.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10250/ 20000/ t/epoch=0.37............. Loss: -0.07046712, mean(E): -19.22657999+0.00160381j, var(E): 0.09772266
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10260/ 20000/ t/epoch=0.37............. Loss: -0.03824946, mean(E): -19.24513908-0.00182810j, var(E): 0.10037703
-0.0
tensor(14.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10270/ 20000/ t/epoch=0.37............. Loss: -0.23875747, mean(E): -19.19982027+0.00357563j, var(E): 0.13451953
-0.0
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10280/ 20000/ t/epoch=0.37............. Loss: -0.08448158, mean(E): -19.21944111-0.02309130j, var(E): 0.11419479
-0.0
tensor(14.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10290/ 20000/ t/epoch=0.37............. Loss: -0.01377962, mean(E): -19.25046473+0.00101953j, var(E): 0.14943567
-0.0
tensor(14.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10300/ 20000/ t/epoch=0.37............. Loss: -0.18150549, mean(E): -19.19653769-0.02172375j, var(E): 0.11317427
-0.0
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10310/ 20000/ t/epoch=0.37............. Loss: -0.02708015, mean(E): -19.20933210-0.01394685j, var(E): 0.12610799
-0.0
tensor(14.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10320/ 20000/ t/epoch=0.37............. Loss: 0.20439484, mean(E): -19.27175004+0.01120092j, var(E): 0.13442497
-0.0
tensor(14.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10330/ 20000/ t/epoch=0.37............. Loss: -0.10296874, mean(E): -19.16923035-0.00230833j, var(E): 0.21389355
-0.0
tensor(14.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10340/ 20000/ t/epoch=0.37............. Loss: 0.09380580, mean(E): -19.21242252-0.00947168j, var(E): 0.11222296
-0.0
tensor(14.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10350/ 20000/ t/epoch=0.37............. Loss: 0.02690496, mean(E): -19.21068974+0.00165125j, var(E): 0.12935949
-0.0
tensor(14.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10360/ 20000/ t/epoch=0.37............. Loss: 0.08329105, mean(E): -19.27027922+0.00634143j, var(E): 0.12636078
-0.0
tensor(14.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10370/ 20000/ t/epoch=0.37............. Loss: 0.15723953, mean(E): -19.20586328+0.01354061j, var(E): 0.11538429
-0.0
tensor(14.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10380/ 20000/ t/epoch=0.37............. Loss: -0.06238403, mean(E): -19.20056578+0.00569291j, var(E): 0.08982816
-0.0
tensor(14.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10390/ 20000/ t/epoch=0.37............. Loss: -0.06230229, mean(E): -19.21337179+0.01286210j, var(E): 0.06675708
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10400/ 20000/ t/epoch=0.37............. Loss: -0.15492412, mean(E): -19.20522528+0.00201647j, var(E): 0.13743545
-0.0
tensor(14.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10410/ 20000/ t/epoch=0.37............. Loss: 0.12406249, mean(E): -19.23103182-0.00705384j, var(E): 0.07836637
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10420/ 20000/ t/epoch=0.37............. Loss: -0.03809516, mean(E): -19.23720129-0.00385119j, var(E): 0.12426325
-0.0
tensor(14.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10430/ 20000/ t/epoch=0.37............. Loss: -0.27435984, mean(E): -19.20303807+0.00796552j, var(E): 0.11221472
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10440/ 20000/ t/epoch=0.37............. Loss: -0.02157559, mean(E): -19.24588285-0.00124625j, var(E): 0.10741415
-0.0
tensor(14.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10450/ 20000/ t/epoch=0.37............. Loss: -0.11607227, mean(E): -19.17541704+0.01120841j, var(E): 0.13102268
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10460/ 20000/ t/epoch=0.37............. Loss: 0.05290604, mean(E): -19.20200707+0.00318322j, var(E): 0.23730524
-0.0
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10470/ 20000/ t/epoch=0.37............. Loss: -0.09594364, mean(E): -19.16132404-0.00056516j, var(E): 0.14523484
-0.0
tensor(14.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10480/ 20000/ t/epoch=0.38............. Loss: -0.03056645, mean(E): -19.21492259+0.01483905j, var(E): 0.09734107
-0.0
tensor(14.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10490/ 20000/ t/epoch=0.37............. Loss: 0.04585931, mean(E): -19.22189498-0.00271683j, var(E): 0.10548991
-0.0
tensor(14.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10500/ 20000/ t/epoch=0.37............. Loss: -0.22455539, mean(E): -19.22518892-0.01049103j, var(E): 0.13917288
-0.0
tensor(14.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10510/ 20000/ t/epoch=0.37............. Loss: -0.20157847, mean(E): -19.17322297-0.00324317j, var(E): 0.11929542
-0.0
tensor(14.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10520/ 20000/ t/epoch=0.37............. Loss: -0.06538400, mean(E): -19.19290198-0.00545944j, var(E): 0.13480333
-0.0
tensor(14.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10530/ 20000/ t/epoch=0.37............. Loss: -0.06962930, mean(E): -19.18830299+0.01073287j, var(E): 0.10332804
-0.0
tensor(14.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10540/ 20000/ t/epoch=0.37............. Loss: 0.01025369, mean(E): -19.19097344-0.00131715j, var(E): 0.16950625
-0.0
tensor(14.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10550/ 20000/ t/epoch=0.37............. Loss: 0.06724283, mean(E): -19.18405228-0.00749009j, var(E): 0.14111859
-0.0
tensor(14.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10560/ 20000/ t/epoch=0.37............. Loss: 0.00572815, mean(E): -19.23847227+0.00889089j, var(E): 0.13007081
-0.0
tensor(14.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10570/ 20000/ t/epoch=0.37............. Loss: 0.31894003, mean(E): -19.24847381+0.00688905j, var(E): 0.11176249
-0.0
tensor(14.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10580/ 20000/ t/epoch=0.37............. Loss: -0.00759917, mean(E): -19.21075934+0.00101089j, var(E): 0.10262719
-0.0
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10590/ 20000/ t/epoch=0.37............. Loss: 0.00917865, mean(E): -19.22553432+0.01062481j, var(E): 0.09812195
-0.0
tensor(14.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10600/ 20000/ t/epoch=0.37............. Loss: -0.02549951, mean(E): -19.20066189+0.01522280j, var(E): 0.15930084
-0.0
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10610/ 20000/ t/epoch=0.37............. Loss: 0.04756909, mean(E): -19.16865391-0.00274897j, var(E): 0.13210908
-0.0
tensor(14.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10620/ 20000/ t/epoch=0.37............. Loss: -0.12532985, mean(E): -19.16775524+0.00648002j, var(E): 0.16051808
-0.0
tensor(14.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10630/ 20000/ t/epoch=0.37............. Loss: 0.11689977, mean(E): -19.22715801-0.00657000j, var(E): 0.12917832
-0.0
tensor(14.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10640/ 20000/ t/epoch=0.37............. Loss: 0.02334545, mean(E): -19.23983144-0.00666887j, var(E): 0.18330669
-0.0
tensor(14.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10650/ 20000/ t/epoch=0.37............. Loss: 0.12071499, mean(E): -19.21727695-0.01033147j, var(E): 0.12983958
-0.0
tensor(14.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10660/ 20000/ t/epoch=0.37............. Loss: 0.04776565, mean(E): -19.19113296+0.00112724j, var(E): 0.13083294
-0.0
tensor(14.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10670/ 20000/ t/epoch=0.37............. Loss: -0.11349773, mean(E): -19.15997700-0.02031126j, var(E): 0.18900970
-0.0
tensor(14.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10680/ 20000/ t/epoch=0.37............. Loss: 0.21714697, mean(E): -19.24676691-0.01345593j, var(E): 0.14243334
-0.0
tensor(14.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10690/ 20000/ t/epoch=0.37............. Loss: 0.00929324, mean(E): -19.21260825+0.01290514j, var(E): 0.12344865
-0.0
tensor(14.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10700/ 20000/ t/epoch=0.37............. Loss: 0.24968469, mean(E): -19.21875278-0.01405253j, var(E): 0.12582191
-0.0
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10710/ 20000/ t/epoch=0.37............. Loss: -0.07238192, mean(E): -19.17288636-0.00932711j, var(E): 0.14795311
-0.0
tensor(14.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10720/ 20000/ t/epoch=0.37............. Loss: 0.08505478, mean(E): -19.24982074+0.01238818j, var(E): 0.14895134
-0.0
tensor(14.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10730/ 20000/ t/epoch=0.37............. Loss: -0.21906882, mean(E): -19.14711479-0.00962233j, var(E): 0.13819166
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10740/ 20000/ t/epoch=0.37............. Loss: 0.17215445, mean(E): -19.23308758-0.00473398j, var(E): 0.11606043
-0.0
tensor(14.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10750/ 20000/ t/epoch=0.37............. Loss: 0.04922115, mean(E): -19.23007021+0.01030591j, var(E): 0.15631221
-0.0
tensor(14.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10760/ 20000/ t/epoch=0.36............. Loss: -0.14957826, mean(E): -19.17345202-0.02312396j, var(E): 0.18684106
-0.0
tensor(14.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10770/ 20000/ t/epoch=0.37............. Loss: -0.08174582, mean(E): -19.18970830+0.00464633j, var(E): 0.07636401
-0.0
tensor(14.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10780/ 20000/ t/epoch=0.37............. Loss: 0.05991621, mean(E): -19.25135821-0.00914360j, var(E): 0.10024065
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10790/ 20000/ t/epoch=0.37............. Loss: 0.11997803, mean(E): -19.21702166+0.00421837j, var(E): 0.10089499
-0.0
tensor(14.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10800/ 20000/ t/epoch=0.37............. Loss: 0.10052567, mean(E): -19.22101486+0.00448098j, var(E): 0.11283742
-0.0
tensor(14.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10810/ 20000/ t/epoch=0.37............. Loss: -0.15963697, mean(E): -19.19491410+0.01118368j, var(E): 0.09450750
-0.0
tensor(14.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10820/ 20000/ t/epoch=0.37............. Loss: -0.16319181, mean(E): -19.18171984-0.00219039j, var(E): 0.10724977
-0.0
tensor(14.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10830/ 20000/ t/epoch=0.37............. Loss: -0.06061550, mean(E): -19.21738269+0.00993013j, var(E): 0.08462059
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10840/ 20000/ t/epoch=0.37............. Loss: -0.16990772, mean(E): -19.20549077-0.00118920j, var(E): 0.14983210
-0.0
tensor(14.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10850/ 20000/ t/epoch=0.37............. Loss: -0.26892467, mean(E): -19.18706519+0.00808507j, var(E): 0.23631496
-0.0
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10860/ 20000/ t/epoch=0.37............. Loss: -0.01273528, mean(E): -19.20348913+0.01998346j, var(E): 0.12607652
-0.0
tensor(14.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10870/ 20000/ t/epoch=0.37............. Loss: -0.13581793, mean(E): -19.23379503+0.00936968j, var(E): 0.10564808
-0.0
tensor(14.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10880/ 20000/ t/epoch=0.37............. Loss: 0.02089647, mean(E): -19.21448230-0.00475442j, var(E): 0.11164880
-0.0
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10890/ 20000/ t/epoch=0.37............. Loss: -0.22426628, mean(E): -19.18016158-0.01156109j, var(E): 0.22173116
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10900/ 20000/ t/epoch=0.37............. Loss: -0.22227592, mean(E): -19.21388508+0.00234769j, var(E): 0.17888187
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10910/ 20000/ t/epoch=0.37............. Loss: -0.19287155, mean(E): -19.21694667-0.01406842j, var(E): 0.11056032
-0.0
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10920/ 20000/ t/epoch=0.37............. Loss: 0.21033635, mean(E): -19.20555320-0.00708556j, var(E): 0.12045406
-0.0
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10930/ 20000/ t/epoch=0.37............. Loss: 0.05080303, mean(E): -19.25668210-0.01048927j, var(E): 0.09082571
-0.0
tensor(14.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10940/ 20000/ t/epoch=0.37............. Loss: -0.05646277, mean(E): -19.20025095-0.00523788j, var(E): 0.14819694
-0.0
tensor(14.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10950/ 20000/ t/epoch=0.37............. Loss: -0.27130531, mean(E): -19.19025412+0.00540318j, var(E): 0.15837254
-0.0
tensor(14.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10960/ 20000/ t/epoch=0.37............. Loss: -0.10664533, mean(E): -19.19568336-0.00569498j, var(E): 0.15036795
-0.0
tensor(14.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10970/ 20000/ t/epoch=0.37............. Loss: 0.32061159, mean(E): -19.26110080+0.01483419j, var(E): 0.14395254
-0.0
tensor(14.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10980/ 20000/ t/epoch=0.37............. Loss: 0.10388923, mean(E): -19.20937241+0.00894975j, var(E): 0.10993160
-0.0
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10990/ 20000/ t/epoch=0.37............. Loss: -0.11511019, mean(E): -19.16773793-0.01157636j, var(E): 0.13452173
-0.0
tensor(14.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11000/ 20000/ t/epoch=0.37............. Loss: -0.10973347, mean(E): -19.23966558-0.00420838j, var(E): 0.13847166
-0.0
tensor(14.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11010/ 20000/ t/epoch=0.36............. Loss: -0.20482882, mean(E): -19.19047769-0.00523037j, var(E): 0.16675916
-0.0
tensor(14.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11020/ 20000/ t/epoch=0.37............. Loss: -0.17712220, mean(E): -19.20239770-0.00086473j, var(E): 0.10363858
-0.0
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11030/ 20000/ t/epoch=0.37............. Loss: -0.16363286, mean(E): -19.19011188-0.01406898j, var(E): 0.11158634
-0.0
tensor(14.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11040/ 20000/ t/epoch=0.37............. Loss: -0.27695082, mean(E): -19.18337244+0.01436573j, var(E): 0.11144330
-0.0
tensor(14.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11050/ 20000/ t/epoch=0.37............. Loss: 0.12552635, mean(E): -19.19177882+0.01650801j, var(E): 0.11881184
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11060/ 20000/ t/epoch=0.37............. Loss: 0.05365233, mean(E): -19.20183522+0.00588035j, var(E): 0.13103292
-0.0
tensor(14.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11070/ 20000/ t/epoch=0.37............. Loss: 0.11291503, mean(E): -19.19546418+0.02183306j, var(E): 0.21269688
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11080/ 20000/ t/epoch=0.37............. Loss: 0.08436353, mean(E): -19.19962027+0.01818145j, var(E): 0.11214998
-0.0
tensor(14.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11090/ 20000/ t/epoch=0.37............. Loss: 0.07692937, mean(E): -19.23825177+0.00620259j, var(E): 0.09525836
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11100/ 20000/ t/epoch=0.37............. Loss: -0.25377239, mean(E): -19.17162929-0.00820362j, var(E): 0.18728248
-0.0
tensor(14.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11110/ 20000/ t/epoch=0.37............. Loss: -0.13002788, mean(E): -19.19870784+0.01432812j, var(E): 0.17270912
-0.0
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11120/ 20000/ t/epoch=0.37............. Loss: 0.07249614, mean(E): -19.22995186-0.00021769j, var(E): 0.13216134
-0.0
tensor(14.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11130/ 20000/ t/epoch=0.37............. Loss: 0.16444003, mean(E): -19.18958238-0.01354815j, var(E): 0.12504696
-0.0
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11140/ 20000/ t/epoch=0.37............. Loss: 0.16183267, mean(E): -19.23382139+0.01037417j, var(E): 0.12412257
-0.0
tensor(14.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11150/ 20000/ t/epoch=0.36............. Loss: 0.07635250, mean(E): -19.22428217+0.00874722j, var(E): 0.15143134
-0.0
tensor(14.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11160/ 20000/ t/epoch=0.37............. Loss: 0.15948465, mean(E): -19.22873015+0.00628426j, var(E): 0.08938123
-0.0
tensor(14.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11170/ 20000/ t/epoch=0.37............. Loss: -0.20459860, mean(E): -19.16920998+0.00947350j, var(E): 0.14354718
-0.0
tensor(14.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11180/ 20000/ t/epoch=0.37............. Loss: -0.21803862, mean(E): -19.21193305+0.01037948j, var(E): 0.11341371
-0.0
tensor(14.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11190/ 20000/ t/epoch=0.37............. Loss: -0.14009597, mean(E): -19.20252877-0.00245439j, var(E): 0.19890518
-0.0
tensor(14.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11200/ 20000/ t/epoch=0.37............. Loss: -0.07300574, mean(E): -19.24244741+0.00788761j, var(E): 0.10399378
-0.0
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11210/ 20000/ t/epoch=0.37............. Loss: -0.03708587, mean(E): -19.23452265-0.00856886j, var(E): 0.15214495
-0.0
tensor(14.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11220/ 20000/ t/epoch=0.37............. Loss: -0.16517390, mean(E): -19.22063938+0.00802976j, var(E): 0.08231199
-0.0
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11230/ 20000/ t/epoch=0.37............. Loss: 0.08516824, mean(E): -19.20596758+0.01082852j, var(E): 0.11054463
-0.0
tensor(14.7808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11240/ 20000/ t/epoch=0.37............. Loss: -0.08129524, mean(E): -19.22457220+0.00953447j, var(E): 0.08818051
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11250/ 20000/ t/epoch=0.37............. Loss: -0.02392504, mean(E): -19.22362895+0.00167923j, var(E): 0.12065283
-0.0
tensor(14.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11260/ 20000/ t/epoch=0.37............. Loss: -0.02685835, mean(E): -19.20152417+0.00359989j, var(E): 0.10096164
-0.0
tensor(14.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11270/ 20000/ t/epoch=0.37............. Loss: 0.23977548, mean(E): -19.24682210+0.01117527j, var(E): 0.15392691
-0.0
tensor(14.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11280/ 20000/ t/epoch=0.38............. Loss: 0.15508062, mean(E): -19.22731343+0.00501005j, var(E): 0.10842111
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11290/ 20000/ t/epoch=0.37............. Loss: 0.02085051, mean(E): -19.23059001-0.00675020j, var(E): 0.12120420
-0.0
tensor(14.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11300/ 20000/ t/epoch=0.37............. Loss: 0.04881636, mean(E): -19.22468187+0.00152201j, var(E): 0.17978859
-0.0
tensor(14.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11310/ 20000/ t/epoch=0.37............. Loss: 0.21248412, mean(E): -19.23945014-0.00710418j, var(E): 0.09577409
-0.0
tensor(14.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11320/ 20000/ t/epoch=0.37............. Loss: 0.31888676, mean(E): -19.26460187+0.00235390j, var(E): 0.18008324
-0.0
tensor(14.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11330/ 20000/ t/epoch=0.37............. Loss: 0.13929930, mean(E): -19.21613168-0.01720530j, var(E): 0.13395863
-0.0
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11340/ 20000/ t/epoch=0.37............. Loss: -0.24480855, mean(E): -19.24390787+0.01681080j, var(E): 0.11821259
-0.0
tensor(14.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11350/ 20000/ t/epoch=0.37............. Loss: -0.12781020, mean(E): -19.21864611+0.00982789j, var(E): 0.18070110
-0.0
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11360/ 20000/ t/epoch=0.37............. Loss: 0.13910096, mean(E): -19.25149195-0.00034376j, var(E): 0.17825635
-0.0
tensor(14.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11370/ 20000/ t/epoch=0.37............. Loss: 0.17611787, mean(E): -19.22721146-0.02005770j, var(E): 0.14421932
-0.0
tensor(14.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11380/ 20000/ t/epoch=0.37............. Loss: -0.05778369, mean(E): -19.22391765+0.00489212j, var(E): 0.17227519
-0.0
tensor(14.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11390/ 20000/ t/epoch=0.37............. Loss: 0.06719953, mean(E): -19.21759963+0.00454158j, var(E): 0.09370517
-0.0
tensor(14.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11400/ 20000/ t/epoch=0.37............. Loss: -0.04766031, mean(E): -19.18563721-0.01036978j, var(E): 0.14993532
-0.0
tensor(14.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11410/ 20000/ t/epoch=0.37............. Loss: -0.04645551, mean(E): -19.21751283+0.00279193j, var(E): 0.11297903
-0.0
tensor(14.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11420/ 20000/ t/epoch=0.37............. Loss: -0.17755910, mean(E): -19.21587514+0.01087833j, var(E): 0.15112756
-0.0
tensor(14.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11430/ 20000/ t/epoch=0.37............. Loss: 0.01279956, mean(E): -19.18999286-0.00138557j, var(E): 0.15284352
-0.0
tensor(14.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11440/ 20000/ t/epoch=0.37............. Loss: -0.00828174, mean(E): -19.23133833+0.00335728j, var(E): 0.11102749
-0.0
tensor(14.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11450/ 20000/ t/epoch=0.37............. Loss: -0.09002693, mean(E): -19.25068571-0.01480419j, var(E): 0.08355187
-0.0
tensor(14.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11460/ 20000/ t/epoch=0.37............. Loss: -0.11048651, mean(E): -19.15384138-0.00210087j, var(E): 0.09921502
-0.0
tensor(14.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11470/ 20000/ t/epoch=0.37............. Loss: -0.12833768, mean(E): -19.23721019+0.00251148j, var(E): 0.13863337
-0.0
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11480/ 20000/ t/epoch=0.37............. Loss: 0.06334926, mean(E): -19.22561430-0.00069618j, var(E): 0.11609630
-0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11490/ 20000/ t/epoch=0.37............. Loss: 0.06009665, mean(E): -19.26077671-0.00096198j, var(E): 0.12204293
-0.0
tensor(14.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11500/ 20000/ t/epoch=0.37............. Loss: -0.14144839, mean(E): -19.18576527-0.00456304j, var(E): 0.12706944
-0.0
tensor(14.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11510/ 20000/ t/epoch=0.38............. Loss: -0.10419910, mean(E): -19.19121479-0.00603904j, var(E): 0.06855951
-0.0
tensor(14.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11520/ 20000/ t/epoch=0.37............. Loss: -0.04282031, mean(E): -19.20694173-0.00965413j, var(E): 0.13497690
-0.0
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11530/ 20000/ t/epoch=0.37............. Loss: -0.19332627, mean(E): -19.18948858-0.00758536j, var(E): 0.13532740
-0.0
tensor(14.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11540/ 20000/ t/epoch=0.37............. Loss: -0.09117228, mean(E): -19.21958742-0.00314346j, var(E): 0.07142036
-0.0
tensor(14.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11550/ 20000/ t/epoch=0.37............. Loss: -0.04589794, mean(E): -19.19067788+0.00577534j, var(E): 0.17146834
-0.0
tensor(14.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11560/ 20000/ t/epoch=0.37............. Loss: -0.03942605, mean(E): -19.22767422-0.00203773j, var(E): 0.15869701
-0.0
tensor(14.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11570/ 20000/ t/epoch=0.37............. Loss: -0.01599458, mean(E): -19.19989899+0.00259553j, var(E): 0.19435423
-0.0
tensor(14.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11580/ 20000/ t/epoch=0.37............. Loss: -0.16234728, mean(E): -19.18662845+0.00894503j, var(E): 0.10480043
-0.0
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11590/ 20000/ t/epoch=0.37............. Loss: -0.02860648, mean(E): -19.21572273-0.00158360j, var(E): 0.11834845
-0.0
tensor(14.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11600/ 20000/ t/epoch=0.37............. Loss: -0.31627515, mean(E): -19.17767570+0.00061150j, var(E): 0.15955937
-0.0
tensor(14.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11610/ 20000/ t/epoch=0.37............. Loss: 0.08486808, mean(E): -19.22591090+0.00067960j, var(E): 0.09877878
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11620/ 20000/ t/epoch=0.37............. Loss: -0.34161542, mean(E): -19.16853141+0.00781571j, var(E): 0.10634336
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11630/ 20000/ t/epoch=0.37............. Loss: -0.06744315, mean(E): -19.19308067+0.00454867j, var(E): 0.11988410
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11640/ 20000/ t/epoch=0.37............. Loss: 0.22461997, mean(E): -19.26549193-0.00226558j, var(E): 0.14713568
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11650/ 20000/ t/epoch=0.37............. Loss: -0.11212959, mean(E): -19.17879829-0.00580801j, var(E): 0.12136709
-0.0
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11660/ 20000/ t/epoch=0.37............. Loss: 0.13949492, mean(E): -19.21687247-0.00338921j, var(E): 0.12171368
-0.0
tensor(14.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11670/ 20000/ t/epoch=0.37............. Loss: 0.10073625, mean(E): -19.20667182-0.01214508j, var(E): 0.10332044
-0.0
tensor(14.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11680/ 20000/ t/epoch=0.37............. Loss: 0.10682058, mean(E): -19.21643100-0.01541569j, var(E): 0.11305814
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11690/ 20000/ t/epoch=0.37............. Loss: -0.10844317, mean(E): -19.16234424+0.01386447j, var(E): 0.16208655
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11700/ 20000/ t/epoch=0.37............. Loss: -0.23875249, mean(E): -19.20808493+0.00024597j, var(E): 0.08976619
-0.0
tensor(14.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11710/ 20000/ t/epoch=0.37............. Loss: 0.06802735, mean(E): -19.21190564+0.00444101j, var(E): 0.15513956
-0.0
tensor(14.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11720/ 20000/ t/epoch=0.37............. Loss: 0.04973654, mean(E): -19.22615519+0.00601945j, var(E): 0.07842496
-0.0
tensor(14.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11730/ 20000/ t/epoch=0.37............. Loss: 0.07160029, mean(E): -19.21650335+0.00143562j, var(E): 0.06909873
-0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11740/ 20000/ t/epoch=0.37............. Loss: -0.00888160, mean(E): -19.20496818+0.01481282j, var(E): 0.13924136
-0.0
tensor(14.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11750/ 20000/ t/epoch=0.37............. Loss: -0.01604250, mean(E): -19.21753443-0.01676325j, var(E): 0.12899205
-0.0
tensor(14.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11760/ 20000/ t/epoch=0.37............. Loss: -0.17862863, mean(E): -19.18586764+0.00673676j, var(E): 0.17443624
-0.0
tensor(14.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11770/ 20000/ t/epoch=0.37............. Loss: 0.32788612, mean(E): -19.25218611-0.00899515j, var(E): 0.10411211
-0.0
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11780/ 20000/ t/epoch=0.37............. Loss: 0.24240193, mean(E): -19.22233453+0.00600007j, var(E): 0.10013289
-0.0
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11790/ 20000/ t/epoch=0.37............. Loss: -0.00962046, mean(E): -19.21018341+0.00561500j, var(E): 0.07704787
-0.0
tensor(14.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11800/ 20000/ t/epoch=0.37............. Loss: 0.06730834, mean(E): -19.21540098-0.00418503j, var(E): 0.10388144
-0.0
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11810/ 20000/ t/epoch=0.37............. Loss: -0.21558511, mean(E): -19.17629385+0.00212033j, var(E): 0.09680082
-0.0
tensor(14.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11820/ 20000/ t/epoch=0.37............. Loss: 0.05938586, mean(E): -19.21450182+0.00248381j, var(E): 0.13968215
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11830/ 20000/ t/epoch=0.37............. Loss: 0.02119954, mean(E): -19.24368011+0.01188150j, var(E): 0.13049311
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11840/ 20000/ t/epoch=0.37............. Loss: -0.26006212, mean(E): -19.20491543-0.00106275j, var(E): 0.09895631
-0.0
tensor(14.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11850/ 20000/ t/epoch=0.37............. Loss: -0.03772696, mean(E): -19.21746676+0.00183754j, var(E): 0.15354923
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11860/ 20000/ t/epoch=0.37............. Loss: 0.12366010, mean(E): -19.23002451-0.00516129j, var(E): 0.09129788
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11870/ 20000/ t/epoch=0.37............. Loss: 0.21084103, mean(E): -19.25182893-0.01995829j, var(E): 0.16669804
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11880/ 20000/ t/epoch=0.37............. Loss: 0.23654775, mean(E): -19.23694289+0.01391670j, var(E): 0.11154793
-0.0
tensor(14.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11890/ 20000/ t/epoch=0.37............. Loss: -0.07126137, mean(E): -19.21984332-0.00067133j, var(E): 0.19305790
-0.0
tensor(14.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11900/ 20000/ t/epoch=0.37............. Loss: -0.01248651, mean(E): -19.22130249+0.00505518j, var(E): 0.11436142
-0.0
tensor(14.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11910/ 20000/ t/epoch=0.37............. Loss: -0.09434887, mean(E): -19.22357916+0.00046635j, var(E): 0.10499008
-0.0
tensor(14.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11920/ 20000/ t/epoch=0.37............. Loss: -0.33472197, mean(E): -19.22623280-0.00059178j, var(E): 0.10103444
-0.0
tensor(14.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11930/ 20000/ t/epoch=0.37............. Loss: -0.02391425, mean(E): -19.17095171-0.00769691j, var(E): 0.09729342
-0.0
tensor(14.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11940/ 20000/ t/epoch=0.37............. Loss: -0.07395667, mean(E): -19.20647757-0.00997079j, var(E): 0.09927057
-0.0
tensor(14.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11950/ 20000/ t/epoch=0.37............. Loss: -0.23064634, mean(E): -19.14912790-0.00394918j, var(E): 0.11172703
-0.0
tensor(14.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11960/ 20000/ t/epoch=0.37............. Loss: -0.01302178, mean(E): -19.22921871-0.01329580j, var(E): 0.15439190
-0.0
tensor(14.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11970/ 20000/ t/epoch=0.37............. Loss: 0.03173544, mean(E): -19.26752325+0.00082256j, var(E): 0.09513528
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11980/ 20000/ t/epoch=0.37............. Loss: 0.10756461, mean(E): -19.21388159-0.00887061j, var(E): 0.13636750
-0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11990/ 20000/ t/epoch=0.37............. Loss: -0.04025580, mean(E): -19.23389246+0.00307398j, var(E): 0.07002291
-0.0
tensor(14.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12000/ 20000/ t/epoch=0.37............. Loss: -0.29731445, mean(E): -19.20290651+0.00052107j, var(E): 0.13438128
-0.0
tensor(14.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12010/ 20000/ t/epoch=0.37............. Loss: -0.30715877, mean(E): -19.19465316-0.00892780j, var(E): 0.11234261
-0.0
tensor(14.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12020/ 20000/ t/epoch=0.37............. Loss: -0.00229478, mean(E): -19.20647554+0.00221621j, var(E): 0.11487024
-0.0
tensor(14.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12030/ 20000/ t/epoch=0.37............. Loss: -0.05319123, mean(E): -19.22842580+0.01144073j, var(E): 0.11855053
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12040/ 20000/ t/epoch=0.37............. Loss: -0.07850400, mean(E): -19.21579156+0.01227632j, var(E): 0.09947494
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12050/ 20000/ t/epoch=0.37............. Loss: 0.01522028, mean(E): -19.22743271-0.00197867j, var(E): 0.16631387
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12060/ 20000/ t/epoch=0.37............. Loss: 0.01896224, mean(E): -19.18082646-0.00565532j, var(E): 0.10232673
-0.0
tensor(14.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12070/ 20000/ t/epoch=0.37............. Loss: -0.33463071, mean(E): -19.21353088-0.00516158j, var(E): 0.13323948
-0.0
tensor(14.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12080/ 20000/ t/epoch=0.37............. Loss: -0.04407437, mean(E): -19.22688647-0.00689709j, var(E): 0.10360207
-0.0
tensor(14.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12090/ 20000/ t/epoch=0.37............. Loss: -0.14798815, mean(E): -19.17244567-0.00493188j, var(E): 0.19431253
-0.0
tensor(14.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12100/ 20000/ t/epoch=0.37............. Loss: -0.09484293, mean(E): -19.22200751+0.01077170j, var(E): 0.14942991
-0.0
tensor(14.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12110/ 20000/ t/epoch=0.37............. Loss: 0.10740180, mean(E): -19.22999862-0.00148836j, var(E): 0.12224095
-0.0
tensor(14.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12120/ 20000/ t/epoch=0.37............. Loss: 0.22805265, mean(E): -19.25605505-0.00161768j, var(E): 0.13108931
-0.0
tensor(14.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12130/ 20000/ t/epoch=0.36............. Loss: 0.18690641, mean(E): -19.25384760-0.02005813j, var(E): 0.08753031
-0.0
tensor(14.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12140/ 20000/ t/epoch=0.37............. Loss: 0.03487934, mean(E): -19.21405651+0.00073880j, var(E): 0.06747441
-0.0
tensor(14.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12150/ 20000/ t/epoch=0.37............. Loss: -0.02608880, mean(E): -19.21911335+0.00502935j, var(E): 0.08354527
-0.0
tensor(14.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12160/ 20000/ t/epoch=0.37............. Loss: -0.11363992, mean(E): -19.18620397-0.00020271j, var(E): 0.15284665
-0.0
tensor(14.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12170/ 20000/ t/epoch=0.37............. Loss: -0.20276567, mean(E): -19.20493692-0.00193107j, var(E): 0.11574062
-0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12180/ 20000/ t/epoch=0.37............. Loss: -0.03113338, mean(E): -19.23108343+0.00071287j, var(E): 0.16483186
-0.0
tensor(14.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12190/ 20000/ t/epoch=0.37............. Loss: -0.03539487, mean(E): -19.18529197-0.00733526j, var(E): 0.18257840
-0.0
tensor(14.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12200/ 20000/ t/epoch=0.37............. Loss: -0.19862861, mean(E): -19.19923337-0.00221787j, var(E): 0.09663041
-0.0
tensor(14.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12210/ 20000/ t/epoch=0.37............. Loss: -0.16862393, mean(E): -19.18178270-0.01925367j, var(E): 0.14392892
-0.0
tensor(14.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12220/ 20000/ t/epoch=0.37............. Loss: 0.09725173, mean(E): -19.23396083+0.00533446j, var(E): 0.08867635
-0.0
tensor(14.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12230/ 20000/ t/epoch=0.37............. Loss: -0.02541508, mean(E): -19.21397188+0.00508270j, var(E): 0.12040187
-0.0
tensor(14.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12240/ 20000/ t/epoch=0.37............. Loss: 0.01502428, mean(E): -19.24130493-0.00710072j, var(E): 0.20643428
-0.0
tensor(14.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12250/ 20000/ t/epoch=0.37............. Loss: -0.02143263, mean(E): -19.20567240-0.00464909j, var(E): 0.13184005
-0.0
tensor(14.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12260/ 20000/ t/epoch=0.37............. Loss: 0.14792118, mean(E): -19.25933119-0.00274197j, var(E): 0.15016278
-0.0
tensor(14.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12270/ 20000/ t/epoch=0.37............. Loss: 0.04922015, mean(E): -19.20577262+0.00751399j, var(E): 0.10457564
-0.0
tensor(14.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12280/ 20000/ t/epoch=0.37............. Loss: -0.13046655, mean(E): -19.19872533-0.00095833j, var(E): 0.13207584
-0.0
tensor(14.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12290/ 20000/ t/epoch=0.37............. Loss: 0.11157743, mean(E): -19.20819644-0.00035686j, var(E): 0.10272516
-0.0
tensor(14.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12300/ 20000/ t/epoch=0.37............. Loss: -0.05477309, mean(E): -19.19636410+0.00506722j, var(E): 0.10384774
-0.0
tensor(14.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12310/ 20000/ t/epoch=0.37............. Loss: 0.02558036, mean(E): -19.22835951-0.00089756j, var(E): 0.11076673
-0.0
tensor(14.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12320/ 20000/ t/epoch=0.37............. Loss: 0.00144713, mean(E): -19.18830134-0.00962086j, var(E): 0.09577670
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12330/ 20000/ t/epoch=0.37............. Loss: 0.05107879, mean(E): -19.23452037+0.00200954j, var(E): 0.07680853
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12340/ 20000/ t/epoch=0.37............. Loss: -0.10636725, mean(E): -19.22644040-0.00141317j, var(E): 0.12381613
-0.0
tensor(14.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12350/ 20000/ t/epoch=0.37............. Loss: 0.05365255, mean(E): -19.19768300+0.00521637j, var(E): 0.09205408
-0.0
tensor(14.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12360/ 20000/ t/epoch=0.37............. Loss: 0.03166303, mean(E): -19.23972025+0.00976687j, var(E): 0.09491414
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12370/ 20000/ t/epoch=0.37............. Loss: 0.07073826, mean(E): -19.25675132+0.00042430j, var(E): 0.14005785
-0.0
tensor(14.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12380/ 20000/ t/epoch=0.37............. Loss: -0.13912819, mean(E): -19.19925138-0.00759124j, var(E): 0.09172187
-0.0
tensor(14.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12390/ 20000/ t/epoch=0.37............. Loss: -0.07447693, mean(E): -19.22799970+0.00673532j, var(E): 0.11228434
-0.0
tensor(14.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12400/ 20000/ t/epoch=0.37............. Loss: -0.02754230, mean(E): -19.21679673-0.01168883j, var(E): 0.15067593
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12410/ 20000/ t/epoch=0.37............. Loss: -0.06528594, mean(E): -19.19703612-0.00736961j, var(E): 0.13821085
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12420/ 20000/ t/epoch=0.37............. Loss: -0.12651601, mean(E): -19.18485085-0.00835316j, var(E): 0.12150429
-0.0
tensor(14.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12430/ 20000/ t/epoch=0.37............. Loss: -0.09722096, mean(E): -19.20801128+0.00395512j, var(E): 0.09597994
-0.0
tensor(14.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12440/ 20000/ t/epoch=0.37............. Loss: -0.23728529, mean(E): -19.17809942+0.00160888j, var(E): 0.10470415
-0.0
tensor(14.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12450/ 20000/ t/epoch=0.37............. Loss: 0.13767871, mean(E): -19.22117348-0.00965895j, var(E): 0.10584187
-0.0
tensor(14.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12460/ 20000/ t/epoch=0.37............. Loss: 0.16380066, mean(E): -19.23013690+0.00186342j, var(E): 0.09018938
-0.0
tensor(14.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12470/ 20000/ t/epoch=0.37............. Loss: -0.00880679, mean(E): -19.21532829-0.00156070j, var(E): 0.12787516
-0.0
tensor(14.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12480/ 20000/ t/epoch=0.37............. Loss: -0.05049987, mean(E): -19.21846260-0.00211058j, var(E): 0.12306856
-0.0
tensor(14.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12490/ 20000/ t/epoch=0.37............. Loss: -0.13824992, mean(E): -19.20360748+0.00491246j, var(E): 0.10264087
-0.0
tensor(14.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12500/ 20000/ t/epoch=0.37............. Loss: -0.08609854, mean(E): -19.18427750+0.00694924j, var(E): 0.12885791
-0.0
tensor(14.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12510/ 20000/ t/epoch=0.37............. Loss: 0.09223731, mean(E): -19.21834019+0.00110421j, var(E): 0.12254431
-0.0
tensor(14.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12520/ 20000/ t/epoch=0.37............. Loss: -0.00797429, mean(E): -19.23669188+0.00081660j, var(E): 0.09130624
-0.0
tensor(14.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12530/ 20000/ t/epoch=0.37............. Loss: 0.04722224, mean(E): -19.23103075+0.01177657j, var(E): 0.11830109
-0.0
tensor(14.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12540/ 20000/ t/epoch=0.37............. Loss: -0.25000308, mean(E): -19.21382694+0.01274128j, var(E): 0.09587334
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12550/ 20000/ t/epoch=0.37............. Loss: -0.04059256, mean(E): -19.22115981-0.00465422j, var(E): 0.11378121
-0.0
tensor(14.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12560/ 20000/ t/epoch=0.37............. Loss: -0.17896677, mean(E): -19.18486641+0.01613872j, var(E): 0.11486451
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12570/ 20000/ t/epoch=0.37............. Loss: -0.00431393, mean(E): -19.20325216+0.00146927j, var(E): 0.10610533
-0.0
tensor(14.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12580/ 20000/ t/epoch=0.37............. Loss: 0.08480577, mean(E): -19.22620424-0.01095136j, var(E): 0.15858636
-0.0
tensor(14.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12590/ 20000/ t/epoch=0.37............. Loss: 0.03371032, mean(E): -19.19722957-0.00448417j, var(E): 0.09404245
-0.0
tensor(14.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12600/ 20000/ t/epoch=0.37............. Loss: -0.12058782, mean(E): -19.18469925+0.00000708j, var(E): 0.08967255
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12610/ 20000/ t/epoch=0.37............. Loss: 0.10914334, mean(E): -19.21354330+0.00264680j, var(E): 0.10490347
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12620/ 20000/ t/epoch=0.37............. Loss: -0.23317029, mean(E): -19.20626667+0.00092320j, var(E): 0.13589808
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12630/ 20000/ t/epoch=0.37............. Loss: -0.13792814, mean(E): -19.22485493-0.00297878j, var(E): 0.15306369
-0.0
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12640/ 20000/ t/epoch=0.37............. Loss: 0.03490097, mean(E): -19.24406959+0.02456923j, var(E): 0.06747718
-0.0
tensor(14.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12650/ 20000/ t/epoch=0.37............. Loss: 0.01511435, mean(E): -19.17529861-0.00129544j, var(E): 0.12849373
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12660/ 20000/ t/epoch=0.37............. Loss: 0.15865714, mean(E): -19.24772528-0.00793096j, var(E): 0.10042998
-0.0
tensor(14.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12670/ 20000/ t/epoch=0.37............. Loss: -0.11430888, mean(E): -19.22262476-0.00386681j, var(E): 0.11261957
-0.0
tensor(14.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12680/ 20000/ t/epoch=0.37............. Loss: -0.30617770, mean(E): -19.21296122-0.00416154j, var(E): 0.10956479
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12690/ 20000/ t/epoch=0.37............. Loss: -0.14203622, mean(E): -19.19019392-0.00324446j, var(E): 0.09242858
-0.0
tensor(14.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12700/ 20000/ t/epoch=0.37............. Loss: 0.01827706, mean(E): -19.20297838-0.00701275j, var(E): 0.12808910
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12710/ 20000/ t/epoch=0.37............. Loss: -0.18483597, mean(E): -19.19250586+0.00135780j, var(E): 0.09504063
-0.0
tensor(14.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12720/ 20000/ t/epoch=0.37............. Loss: -0.27444411, mean(E): -19.19297483-0.00371205j, var(E): 0.14606481
-0.0
tensor(14.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12730/ 20000/ t/epoch=0.37............. Loss: -0.15628921, mean(E): -19.21025786-0.00519850j, var(E): 0.13766040
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12740/ 20000/ t/epoch=0.37............. Loss: -0.11144393, mean(E): -19.20464031+0.01904074j, var(E): 0.12858099
-0.0
tensor(14.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12750/ 20000/ t/epoch=0.37............. Loss: 0.05166412, mean(E): -19.19556897+0.00849442j, var(E): 0.10034829
-0.0
tensor(14.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12760/ 20000/ t/epoch=0.37............. Loss: -0.00556966, mean(E): -19.19331901-0.01204331j, var(E): 0.10558401
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12770/ 20000/ t/epoch=0.37............. Loss: 0.08638192, mean(E): -19.25282439-0.01332415j, var(E): 0.09160179
-0.0
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12780/ 20000/ t/epoch=0.37............. Loss: 0.05899783, mean(E): -19.19404186-0.00293727j, var(E): 0.13543647
-0.0
tensor(14.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12790/ 20000/ t/epoch=0.37............. Loss: 0.18366535, mean(E): -19.26036453-0.00445478j, var(E): 0.20655194
-0.0
tensor(14.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12800/ 20000/ t/epoch=0.37............. Loss: -0.01408631, mean(E): -19.22314221-0.00344091j, var(E): 0.11854455
-0.0
tensor(14.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12810/ 20000/ t/epoch=0.37............. Loss: -0.14286949, mean(E): -19.22269243-0.01132936j, var(E): 0.09825324
-0.0
tensor(14.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12820/ 20000/ t/epoch=0.37............. Loss: -0.02208098, mean(E): -19.20054590+0.00234708j, var(E): 0.10097003
-0.0
tensor(14.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12830/ 20000/ t/epoch=0.37............. Loss: -0.09438296, mean(E): -19.23009372+0.00084089j, var(E): 0.17535303
-0.0
tensor(14.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12840/ 20000/ t/epoch=0.37............. Loss: 0.10701818, mean(E): -19.21159229+0.01563543j, var(E): 0.14945612
-0.0
tensor(14.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12850/ 20000/ t/epoch=0.37............. Loss: 0.08712861, mean(E): -19.23344012+0.00923781j, var(E): 0.08992847
-0.0
tensor(14.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12860/ 20000/ t/epoch=0.37............. Loss: -0.13683693, mean(E): -19.20988405-0.00136153j, var(E): 0.16780786
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12870/ 20000/ t/epoch=0.37............. Loss: -0.28335534, mean(E): -19.21081198-0.01376900j, var(E): 0.10031239
-0.0
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12880/ 20000/ t/epoch=0.37............. Loss: 0.05459789, mean(E): -19.22824806+0.00339607j, var(E): 0.13814654
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12890/ 20000/ t/epoch=0.37............. Loss: 0.13876498, mean(E): -19.20120658+0.00580992j, var(E): 0.14990324
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12900/ 20000/ t/epoch=0.37............. Loss: -0.03777035, mean(E): -19.21722227+0.01145691j, var(E): 0.14291551
-0.0
tensor(14.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12910/ 20000/ t/epoch=0.37............. Loss: 0.16406101, mean(E): -19.26157261-0.00909838j, var(E): 0.13170519
-0.0
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12920/ 20000/ t/epoch=0.37............. Loss: -0.14150408, mean(E): -19.18854053-0.00618070j, var(E): 0.12406105
-0.0
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12930/ 20000/ t/epoch=0.37............. Loss: -0.18352787, mean(E): -19.18551493+0.00023643j, var(E): 0.12630147
-0.0
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12940/ 20000/ t/epoch=0.37............. Loss: 0.23618308, mean(E): -19.24663306-0.00680903j, var(E): 0.08862406
-0.0
tensor(14.8552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12950/ 20000/ t/epoch=0.37............. Loss: -0.17018031, mean(E): -19.18411029-0.00286512j, var(E): 0.08413471
-0.0
tensor(14.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12960/ 20000/ t/epoch=0.37............. Loss: -0.11532089, mean(E): -19.24722668+0.00528208j, var(E): 0.08769219
-0.0
tensor(14.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12970/ 20000/ t/epoch=0.37............. Loss: 0.07578279, mean(E): -19.25457175+0.00117808j, var(E): 0.13261080
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12980/ 20000/ t/epoch=0.37............. Loss: -0.00002305, mean(E): -19.22097286+0.00431839j, var(E): 0.09522568
-0.0
tensor(14.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12990/ 20000/ t/epoch=0.37............. Loss: 0.06040331, mean(E): -19.23592999-0.00909824j, var(E): 0.10499652
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13000/ 20000/ t/epoch=0.37............. Loss: -0.20930526, mean(E): -19.19447894+0.00216931j, var(E): 0.11779110
-0.0
tensor(14.8574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13010/ 20000/ t/epoch=0.37............. Loss: -0.36023872, mean(E): -19.19919654+0.00643439j, var(E): 0.19882914
-0.0
tensor(14.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13020/ 20000/ t/epoch=0.37............. Loss: 0.01064338, mean(E): -19.22185610+0.00383383j, var(E): 0.08216460
-0.0
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13030/ 20000/ t/epoch=0.37............. Loss: 0.06158880, mean(E): -19.22709633+0.00533961j, var(E): 0.11327582
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13040/ 20000/ t/epoch=0.37............. Loss: -0.22705520, mean(E): -19.18396121+0.00544226j, var(E): 0.10581337
-0.0
tensor(14.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13050/ 20000/ t/epoch=0.37............. Loss: -0.00936953, mean(E): -19.22225297-0.00151185j, var(E): 0.11911478
-0.0
tensor(14.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13060/ 20000/ t/epoch=0.37............. Loss: -0.00809299, mean(E): -19.23184541-0.00818011j, var(E): 0.09140729
-0.0
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13070/ 20000/ t/epoch=0.37............. Loss: -0.03319546, mean(E): -19.19699293-0.01205469j, var(E): 0.15225313
-0.0
tensor(14.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13080/ 20000/ t/epoch=0.37............. Loss: -0.07118288, mean(E): -19.20552216+0.00223044j, var(E): 0.13554825
-0.0
tensor(14.8605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13090/ 20000/ t/epoch=0.37............. Loss: -0.25758294, mean(E): -19.16319874-0.00011614j, var(E): 0.10286736
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13100/ 20000/ t/epoch=0.37............. Loss: 0.12702767, mean(E): -19.23193499+0.00196864j, var(E): 0.07318953
-0.0
tensor(14.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13110/ 20000/ t/epoch=0.37............. Loss: -0.04907358, mean(E): -19.19819592-0.00600584j, var(E): 0.11929577
-0.0
tensor(14.8618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13120/ 20000/ t/epoch=0.37............. Loss: 0.00825928, mean(E): -19.23365666-0.00134022j, var(E): 0.11851698
-0.0
tensor(14.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13130/ 20000/ t/epoch=0.37............. Loss: -0.16010094, mean(E): -19.19343299-0.00534435j, var(E): 0.13975967
-0.0
tensor(14.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13140/ 20000/ t/epoch=0.37............. Loss: 0.09495336, mean(E): -19.19717720-0.01032822j, var(E): 0.10854515
-0.0
tensor(14.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13150/ 20000/ t/epoch=0.37............. Loss: 0.11089350, mean(E): -19.21200792-0.00007380j, var(E): 0.10506174
-0.0
tensor(14.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13160/ 20000/ t/epoch=0.37............. Loss: -0.07685582, mean(E): -19.21827088+0.00497745j, var(E): 0.11225184
-0.0
tensor(14.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13170/ 20000/ t/epoch=0.37............. Loss: 0.10837215, mean(E): -19.25148610+0.00078332j, var(E): 0.10464172
-0.0
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13180/ 20000/ t/epoch=0.37............. Loss: 0.21450470, mean(E): -19.21387990+0.00739223j, var(E): 0.11016454
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13190/ 20000/ t/epoch=0.37............. Loss: 0.23301461, mean(E): -19.21979653+0.01105948j, var(E): 0.09837827
-0.0
tensor(14.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13200/ 20000/ t/epoch=0.37............. Loss: -0.08936841, mean(E): -19.20616735-0.00529637j, var(E): 0.08450809
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13210/ 20000/ t/epoch=0.37............. Loss: -0.03543058, mean(E): -19.20475918+0.01333629j, var(E): 0.07405596
-0.0
tensor(14.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13220/ 20000/ t/epoch=0.37............. Loss: -0.06142844, mean(E): -19.23042531-0.01117117j, var(E): 0.12679690
-0.0
tensor(14.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13230/ 20000/ t/epoch=0.37............. Loss: 0.00681873, mean(E): -19.21953383-0.00114570j, var(E): 0.08420678
-0.0
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13240/ 20000/ t/epoch=0.37............. Loss: 0.00878385, mean(E): -19.18873362-0.01452631j, var(E): 0.17914799
-0.0
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13250/ 20000/ t/epoch=0.37............. Loss: -0.21223789, mean(E): -19.21302191+0.01056129j, var(E): 0.11507341
-0.0
tensor(14.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13260/ 20000/ t/epoch=0.37............. Loss: -0.18378758, mean(E): -19.20342134+0.00775244j, var(E): 0.07753247
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13270/ 20000/ t/epoch=0.37............. Loss: -0.11967603, mean(E): -19.17686878-0.00015002j, var(E): 0.11289484
-0.0
tensor(14.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13280/ 20000/ t/epoch=0.37............. Loss: 0.06595048, mean(E): -19.21590656+0.00356114j, var(E): 0.11211843
-0.0
tensor(14.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13290/ 20000/ t/epoch=0.37............. Loss: -0.07840584, mean(E): -19.19191144-0.01410194j, var(E): 0.09725498
-0.0
tensor(14.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13300/ 20000/ t/epoch=0.37............. Loss: 0.03839270, mean(E): -19.26469874+0.01621286j, var(E): 0.08093452
-0.0
tensor(14.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13310/ 20000/ t/epoch=0.37............. Loss: 0.00807841, mean(E): -19.20648573+0.01063015j, var(E): 0.07498747
-0.0
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13320/ 20000/ t/epoch=0.37............. Loss: -0.25201174, mean(E): -19.19113778-0.00498285j, var(E): 0.14369284
-0.0
tensor(14.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13330/ 20000/ t/epoch=0.37............. Loss: 0.23478337, mean(E): -19.27235949-0.00916245j, var(E): 0.10505926
-0.0
tensor(14.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13340/ 20000/ t/epoch=0.37............. Loss: 0.21210520, mean(E): -19.24536138-0.00845614j, var(E): 0.12475333
-0.0
tensor(14.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13350/ 20000/ t/epoch=0.37............. Loss: -0.01565408, mean(E): -19.22324852-0.00916468j, var(E): 0.11920611
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13360/ 20000/ t/epoch=0.37............. Loss: -0.15249885, mean(E): -19.18896502+0.00226752j, var(E): 0.10110739
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13370/ 20000/ t/epoch=0.37............. Loss: 0.23851252, mean(E): -19.21283295+0.00579865j, var(E): 0.08213165
-0.0
tensor(14.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13380/ 20000/ t/epoch=0.37............. Loss: 0.04430790, mean(E): -19.22024116+0.00123695j, var(E): 0.10762162
-0.0
tensor(14.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13390/ 20000/ t/epoch=0.37............. Loss: 0.07490568, mean(E): -19.24222940-0.01018184j, var(E): 0.09436702
-0.0
tensor(14.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13400/ 20000/ t/epoch=0.37............. Loss: 0.00898298, mean(E): -19.21155617+0.00878839j, var(E): 0.11393583
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13410/ 20000/ t/epoch=0.37............. Loss: 0.00489025, mean(E): -19.24103827-0.00929227j, var(E): 0.12812553
-0.0
tensor(14.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13420/ 20000/ t/epoch=0.37............. Loss: 0.03198944, mean(E): -19.19848424+0.00291881j, var(E): 0.07364347
-0.0
tensor(14.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13430/ 20000/ t/epoch=0.37............. Loss: 0.11776941, mean(E): -19.23269516-0.00566548j, var(E): 0.07328128
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13440/ 20000/ t/epoch=0.37............. Loss: 0.02356925, mean(E): -19.20869263+0.00751584j, var(E): 0.09610125
-0.0
tensor(14.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13450/ 20000/ t/epoch=0.37............. Loss: 0.12922410, mean(E): -19.24169696+0.00672658j, var(E): 0.11210117
-0.0
tensor(14.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13460/ 20000/ t/epoch=0.37............. Loss: -0.00807259, mean(E): -19.22400456+0.00619036j, var(E): 0.15169942
-0.0
tensor(14.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13470/ 20000/ t/epoch=0.37............. Loss: -0.17544058, mean(E): -19.20135809+0.00916762j, var(E): 0.09625219
-0.0
tensor(14.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13480/ 20000/ t/epoch=0.37............. Loss: -0.01918625, mean(E): -19.23220094-0.00549753j, var(E): 0.12159501
-0.0
tensor(14.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13490/ 20000/ t/epoch=0.37............. Loss: 0.09290963, mean(E): -19.23092956-0.02030799j, var(E): 0.11908983
-0.0
tensor(14.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13500/ 20000/ t/epoch=0.37............. Loss: -0.20265839, mean(E): -19.18589790+0.00697405j, var(E): 0.10407445
-0.0
tensor(14.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13510/ 20000/ t/epoch=0.37............. Loss: -0.10060803, mean(E): -19.23247999+0.00323916j, var(E): 0.12161393
-0.0
tensor(14.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13520/ 20000/ t/epoch=0.36............. Loss: -0.34218265, mean(E): -19.18490118+0.01648686j, var(E): 0.13588357
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13530/ 20000/ t/epoch=0.37............. Loss: -0.16443334, mean(E): -19.18987949-0.00224912j, var(E): 0.08761291
-0.0
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13540/ 20000/ t/epoch=0.37............. Loss: 0.14994495, mean(E): -19.23789397+0.01207188j, var(E): 0.11336770
-0.0
tensor(14.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13550/ 20000/ t/epoch=0.37............. Loss: 0.20920231, mean(E): -19.22197678+0.00208282j, var(E): 0.10231021
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13560/ 20000/ t/epoch=0.37............. Loss: -0.20900567, mean(E): -19.17982274-0.01520796j, var(E): 0.10470621
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13570/ 20000/ t/epoch=0.37............. Loss: -0.06204129, mean(E): -19.21745815+0.00634988j, var(E): 0.21616373
-0.0
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13580/ 20000/ t/epoch=0.37............. Loss: -0.28256045, mean(E): -19.18394587-0.00823346j, var(E): 0.17279582
-0.0
tensor(14.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13590/ 20000/ t/epoch=0.37............. Loss: 0.26405447, mean(E): -19.24349133+0.01105790j, var(E): 0.08490144
-0.0
tensor(14.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13600/ 20000/ t/epoch=0.37............. Loss: -0.03190217, mean(E): -19.20121781+0.00414135j, var(E): 0.15501004
-0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13610/ 20000/ t/epoch=0.37............. Loss: -0.08099572, mean(E): -19.24633977+0.00780396j, var(E): 0.10212008
-0.0
tensor(14.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13620/ 20000/ t/epoch=0.37............. Loss: 0.23952325, mean(E): -19.24736960+0.00153884j, var(E): 0.09424845
-0.0
tensor(14.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13630/ 20000/ t/epoch=0.37............. Loss: 0.01155686, mean(E): -19.20910958-0.00167800j, var(E): 0.08446420
-0.0
tensor(14.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13640/ 20000/ t/epoch=0.37............. Loss: -0.03720051, mean(E): -19.19860950-0.00435341j, var(E): 0.13873951
-0.0
tensor(14.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13650/ 20000/ t/epoch=0.37............. Loss: -0.04966285, mean(E): -19.21454760-0.00441034j, var(E): 0.13556060
-0.0
tensor(14.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13660/ 20000/ t/epoch=0.37............. Loss: 0.10326194, mean(E): -19.20425707+0.00859546j, var(E): 0.13362115
-0.0
tensor(14.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13670/ 20000/ t/epoch=0.37............. Loss: -0.24806380, mean(E): -19.19505848-0.01140616j, var(E): 0.14238302
-0.0
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13680/ 20000/ t/epoch=0.37............. Loss: -0.04017095, mean(E): -19.21406160+0.00334793j, var(E): 0.07186531
-0.0
tensor(14.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13690/ 20000/ t/epoch=0.37............. Loss: 0.17017535, mean(E): -19.24356221+0.00725893j, var(E): 0.10631260
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13700/ 20000/ t/epoch=0.37............. Loss: -0.02486311, mean(E): -19.18350554+0.00435558j, var(E): 0.07600672
-0.0
tensor(14.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13710/ 20000/ t/epoch=0.37............. Loss: -0.01490588, mean(E): -19.19028127+0.00417215j, var(E): 0.07564890
-0.0
tensor(14.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13720/ 20000/ t/epoch=0.37............. Loss: -0.12213604, mean(E): -19.18944359+0.01571918j, var(E): 0.17053702
-0.0
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13730/ 20000/ t/epoch=0.37............. Loss: -0.01080593, mean(E): -19.21252898+0.00040682j, var(E): 0.10135440
-0.0
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13740/ 20000/ t/epoch=0.37............. Loss: -0.01300825, mean(E): -19.21160438-0.00404428j, var(E): 0.09861580
-0.0
tensor(14.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13750/ 20000/ t/epoch=0.36............. Loss: 0.03282897, mean(E): -19.21964240-0.00041469j, var(E): 0.13334994
-0.0
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13760/ 20000/ t/epoch=0.37............. Loss: 0.04775172, mean(E): -19.23871800-0.00072451j, var(E): 0.08050510
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13770/ 20000/ t/epoch=0.37............. Loss: -0.03421251, mean(E): -19.17571247-0.00378894j, var(E): 0.11562059
-0.0
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13780/ 20000/ t/epoch=0.37............. Loss: -0.09629337, mean(E): -19.18662342+0.00906814j, var(E): 0.10925709
-0.0
tensor(14.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13790/ 20000/ t/epoch=0.37............. Loss: -0.15035757, mean(E): -19.14654349-0.00421159j, var(E): 0.11453284
-0.0
tensor(14.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13800/ 20000/ t/epoch=0.37............. Loss: -0.00665440, mean(E): -19.23541146+0.00542457j, var(E): 0.12974038
-0.0
tensor(14.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13810/ 20000/ t/epoch=0.37............. Loss: 0.17016819, mean(E): -19.17657745+0.00316752j, var(E): 0.15014059
-0.0
tensor(14.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13820/ 20000/ t/epoch=0.37............. Loss: 0.05327626, mean(E): -19.21910167+0.00944288j, var(E): 0.18217010
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13830/ 20000/ t/epoch=0.37............. Loss: -0.14886057, mean(E): -19.21020306-0.00933687j, var(E): 0.09588029
-0.0
tensor(14.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13840/ 20000/ t/epoch=0.37............. Loss: -0.24541871, mean(E): -19.17160623+0.00282045j, var(E): 0.13290022
-0.0
tensor(14.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13850/ 20000/ t/epoch=0.37............. Loss: 0.24537831, mean(E): -19.23373829+0.00064419j, var(E): 0.10587707
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13860/ 20000/ t/epoch=0.37............. Loss: -0.14555510, mean(E): -19.19039128-0.00049655j, var(E): 0.09454692
-0.0
tensor(14.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13870/ 20000/ t/epoch=0.37............. Loss: 0.06357232, mean(E): -19.20900856-0.00010165j, var(E): 0.13635836
-0.0
tensor(14.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13880/ 20000/ t/epoch=0.36............. Loss: -0.01573740, mean(E): -19.20217830+0.00769416j, var(E): 0.08758932
-0.0
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13890/ 20000/ t/epoch=0.37............. Loss: -0.15131206, mean(E): -19.21575113-0.00600454j, var(E): 0.07632977
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13900/ 20000/ t/epoch=0.37............. Loss: 0.03590193, mean(E): -19.20624318+0.00040724j, var(E): 0.09693177
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13910/ 20000/ t/epoch=0.37............. Loss: -0.09913895, mean(E): -19.22605192+0.00159669j, var(E): 0.08155483
-0.0
tensor(14.8927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13920/ 20000/ t/epoch=0.37............. Loss: -0.01774540, mean(E): -19.23463612-0.00224901j, var(E): 0.10560121
-0.0
tensor(14.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13930/ 20000/ t/epoch=0.37............. Loss: 0.19106484, mean(E): -19.21880279+0.01260994j, var(E): 0.07919857
-0.0
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13940/ 20000/ t/epoch=0.37............. Loss: 0.13842164, mean(E): -19.22701481-0.00111068j, var(E): 0.07263719
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13950/ 20000/ t/epoch=0.37............. Loss: -0.02213830, mean(E): -19.24943547+0.00066661j, var(E): 0.10962506
-0.0
tensor(14.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13960/ 20000/ t/epoch=0.37............. Loss: -0.20375469, mean(E): -19.19376952-0.01544709j, var(E): 0.10048776
-0.0
tensor(14.8941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13970/ 20000/ t/epoch=0.37............. Loss: -0.05450486, mean(E): -19.21143654+0.00060471j, var(E): 0.10682090
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13980/ 20000/ t/epoch=0.37............. Loss: -0.13716821, mean(E): -19.14690898-0.00685366j, var(E): 0.14103586
-0.0
tensor(14.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13990/ 20000/ t/epoch=0.37............. Loss: -0.03350598, mean(E): -19.22318552+0.00351082j, var(E): 0.11525369
-0.0
tensor(14.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14000/ 20000/ t/epoch=0.37............. Loss: 0.06322535, mean(E): -19.21590128-0.00520197j, var(E): 0.08649371
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14010/ 20000/ t/epoch=0.37............. Loss: 0.04428237, mean(E): -19.23097348+0.00443362j, var(E): 0.14123465
-0.0
tensor(14.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14020/ 20000/ t/epoch=0.37............. Loss: 0.17093774, mean(E): -19.29083402+0.00458179j, var(E): 0.21768187
-0.0
tensor(14.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14030/ 20000/ t/epoch=0.37............. Loss: 0.04614291, mean(E): -19.22380751+0.00378237j, var(E): 0.11921619
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14040/ 20000/ t/epoch=0.37............. Loss: -0.14937155, mean(E): -19.20166742+0.01762722j, var(E): 0.10864006
-0.0
tensor(14.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14050/ 20000/ t/epoch=0.37............. Loss: -0.07028198, mean(E): -19.17340764+0.01124752j, var(E): 0.15347305
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14060/ 20000/ t/epoch=0.37............. Loss: -0.18236418, mean(E): -19.19025209+0.01570375j, var(E): 0.09509869
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14070/ 20000/ t/epoch=0.37............. Loss: 0.01286486, mean(E): -19.20979487+0.00038450j, var(E): 0.11652062
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14080/ 20000/ t/epoch=0.37............. Loss: -0.19604241, mean(E): -19.15445664-0.00942577j, var(E): 0.15771420
-0.0
tensor(14.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14090/ 20000/ t/epoch=0.37............. Loss: -0.19664005, mean(E): -19.22218745-0.00600410j, var(E): 0.15296331
-0.0
tensor(14.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14100/ 20000/ t/epoch=0.37............. Loss: -0.30448012, mean(E): -19.19712280+0.00197192j, var(E): 0.12126235
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14110/ 20000/ t/epoch=0.37............. Loss: -0.07499009, mean(E): -19.23635422-0.00297635j, var(E): 0.11304447
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14120/ 20000/ t/epoch=0.37............. Loss: -0.17482017, mean(E): -19.20584654-0.00615637j, var(E): 0.08121502
-0.0
tensor(14.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14130/ 20000/ t/epoch=0.37............. Loss: 0.11272395, mean(E): -19.19463495+0.00481881j, var(E): 0.11470802
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14140/ 20000/ t/epoch=0.37............. Loss: 0.03880988, mean(E): -19.22151156+0.01079489j, var(E): 0.07843605
-0.0
tensor(14.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14150/ 20000/ t/epoch=0.37............. Loss: 0.02770515, mean(E): -19.19721993-0.01766430j, var(E): 0.11621117
-0.0
tensor(14.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14160/ 20000/ t/epoch=0.37............. Loss: -0.07611666, mean(E): -19.18701944+0.00041973j, var(E): 0.07227596
-0.0
tensor(14.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14170/ 20000/ t/epoch=0.37............. Loss: -0.17080180, mean(E): -19.17908769+0.00240994j, var(E): 0.12146459
-0.0
tensor(14.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14180/ 20000/ t/epoch=0.37............. Loss: -0.15015751, mean(E): -19.18611846-0.01704345j, var(E): 0.09771093
-0.0
tensor(14.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14190/ 20000/ t/epoch=0.37............. Loss: -0.15947433, mean(E): -19.22683194+0.00181266j, var(E): 0.10079433
-0.0
tensor(14.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14200/ 20000/ t/epoch=0.37............. Loss: 0.07914999, mean(E): -19.22176907-0.00509633j, var(E): 0.09866187
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14210/ 20000/ t/epoch=0.37............. Loss: -0.04848293, mean(E): -19.19403100+0.01294952j, var(E): 0.08840037
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14220/ 20000/ t/epoch=0.37............. Loss: 0.07951639, mean(E): -19.22997401-0.00392480j, var(E): 0.17575124
-0.0
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14230/ 20000/ t/epoch=0.37............. Loss: -0.13540856, mean(E): -19.18020390-0.00457319j, var(E): 0.10485057
-0.0
tensor(14.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14240/ 20000/ t/epoch=0.37............. Loss: -0.06288235, mean(E): -19.20087337-0.00392740j, var(E): 0.11469658
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14250/ 20000/ t/epoch=0.37............. Loss: 0.11098543, mean(E): -19.24406984-0.01087182j, var(E): 0.09706655
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14260/ 20000/ t/epoch=0.37............. Loss: 0.06564845, mean(E): -19.19298417+0.00726496j, var(E): 0.11318722
-0.0
tensor(14.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14270/ 20000/ t/epoch=0.37............. Loss: 0.13897603, mean(E): -19.26300139-0.00653836j, var(E): 0.13422530
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14280/ 20000/ t/epoch=0.37............. Loss: -0.16744159, mean(E): -19.21218580+0.01508979j, var(E): 0.14694842
-0.0
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14290/ 20000/ t/epoch=0.37............. Loss: -0.10797393, mean(E): -19.21388711-0.00739537j, var(E): 0.08051075
-0.0
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14300/ 20000/ t/epoch=0.37............. Loss: 0.01513238, mean(E): -19.19086623-0.00471095j, var(E): 0.14380817
-0.0
tensor(14.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14310/ 20000/ t/epoch=0.37............. Loss: 0.13056617, mean(E): -19.23434794-0.00379749j, var(E): 0.07681536
-0.0
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14320/ 20000/ t/epoch=0.37............. Loss: -0.06510023, mean(E): -19.21999294+0.00556868j, var(E): 0.07663595
-0.0
tensor(14.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14330/ 20000/ t/epoch=0.37............. Loss: 0.00944443, mean(E): -19.21078071-0.00075710j, var(E): 0.10955565
-0.0
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14340/ 20000/ t/epoch=0.37............. Loss: 0.07070159, mean(E): -19.20974494-0.00816451j, var(E): 0.12333921
-0.0
tensor(14.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14350/ 20000/ t/epoch=0.37............. Loss: 0.16669794, mean(E): -19.21536795+0.00914671j, var(E): 0.07878049
-0.0
tensor(14.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14360/ 20000/ t/epoch=0.37............. Loss: -0.22254719, mean(E): -19.15865941-0.01396099j, var(E): 0.14912649
-0.0
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14370/ 20000/ t/epoch=0.37............. Loss: -0.15144719, mean(E): -19.19723453+0.01470608j, var(E): 0.08931657
-0.0
tensor(14.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14380/ 20000/ t/epoch=0.37............. Loss: -0.25659134, mean(E): -19.23949898-0.01516429j, var(E): 0.08500280
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14390/ 20000/ t/epoch=0.37............. Loss: -0.27251320, mean(E): -19.16695757-0.01755456j, var(E): 0.16252059
-0.0
tensor(14.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14400/ 20000/ t/epoch=0.37............. Loss: 0.08051417, mean(E): -19.20625900-0.00040828j, var(E): 0.15506566
-0.0
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14410/ 20000/ t/epoch=0.37............. Loss: -0.14278318, mean(E): -19.21226516-0.00467305j, var(E): 0.08440031
-0.0
tensor(14.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14420/ 20000/ t/epoch=0.37............. Loss: 0.02917339, mean(E): -19.23013800+0.00464804j, var(E): 0.13773618
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14430/ 20000/ t/epoch=0.37............. Loss: -0.06636401, mean(E): -19.25256513+0.00078696j, var(E): 0.07558234
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14440/ 20000/ t/epoch=0.37............. Loss: -0.14683263, mean(E): -19.19473047-0.00556022j, var(E): 0.12476927
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14450/ 20000/ t/epoch=0.37............. Loss: 0.03034149, mean(E): -19.16924504+0.00311103j, var(E): 0.13234936
-0.0
tensor(14.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14460/ 20000/ t/epoch=0.37............. Loss: -0.07666805, mean(E): -19.25095715-0.00350377j, var(E): 0.17784690
-0.0
tensor(14.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14470/ 20000/ t/epoch=0.37............. Loss: -0.21542057, mean(E): -19.18097783-0.01292752j, var(E): 0.07282061
-0.0
tensor(14.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14480/ 20000/ t/epoch=0.37............. Loss: 0.01714638, mean(E): -19.23353197+0.00043788j, var(E): 0.08444289
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14490/ 20000/ t/epoch=0.37............. Loss: -0.04109590, mean(E): -19.18538104-0.00555462j, var(E): 0.06822390
-0.0
tensor(14.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14500/ 20000/ t/epoch=0.37............. Loss: -0.11827756, mean(E): -19.21213441+0.00353816j, var(E): 0.07471329
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14510/ 20000/ t/epoch=0.37............. Loss: -0.00694776, mean(E): -19.23605927+0.00211863j, var(E): 0.10131595
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14520/ 20000/ t/epoch=0.37............. Loss: -0.21240077, mean(E): -19.16441076-0.00511239j, var(E): 0.09027389
-0.0
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14530/ 20000/ t/epoch=0.37............. Loss: 0.06797129, mean(E): -19.22564933-0.01045264j, var(E): 0.11497079
-0.0
tensor(14.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14540/ 20000/ t/epoch=0.37............. Loss: 0.07234297, mean(E): -19.20590956+0.00202888j, var(E): 0.10528327
-0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14550/ 20000/ t/epoch=0.37............. Loss: -0.17368557, mean(E): -19.17657375+0.00175225j, var(E): 0.08951977
-0.0
tensor(14.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14560/ 20000/ t/epoch=0.37............. Loss: 0.08257068, mean(E): -19.20469787-0.01692419j, var(E): 0.11539231
-0.0
tensor(14.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14570/ 20000/ t/epoch=0.37............. Loss: 0.24443774, mean(E): -19.21955890+0.00349327j, var(E): 0.13903185
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14580/ 20000/ t/epoch=0.37............. Loss: 0.11326453, mean(E): -19.23630121+0.01611620j, var(E): 0.10390921
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14590/ 20000/ t/epoch=0.37............. Loss: -0.02245686, mean(E): -19.23831809-0.00225503j, var(E): 0.09617106
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14600/ 20000/ t/epoch=0.37............. Loss: 0.01991291, mean(E): -19.22585343-0.02136920j, var(E): 0.14376141
-0.0
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14610/ 20000/ t/epoch=0.37............. Loss: 0.00482690, mean(E): -19.19473964+0.01316394j, var(E): 0.09203469
-0.0
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14620/ 20000/ t/epoch=0.37............. Loss: 0.08815678, mean(E): -19.21935057-0.00007799j, var(E): 0.13736186
-0.0
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14630/ 20000/ t/epoch=0.37............. Loss: -0.00682663, mean(E): -19.23458947-0.00114464j, var(E): 0.12573051
-0.0
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14640/ 20000/ t/epoch=0.37............. Loss: 0.07596439, mean(E): -19.20268202+0.01031918j, var(E): 0.10405221
-0.0
tensor(14.9187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14650/ 20000/ t/epoch=0.37............. Loss: 0.12510194, mean(E): -19.23730775-0.01047645j, var(E): 0.06071672
-0.0
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14660/ 20000/ t/epoch=0.37............. Loss: -0.05831281, mean(E): -19.20957241+0.01007158j, var(E): 0.23544250
-0.0
tensor(14.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14670/ 20000/ t/epoch=0.37............. Loss: -0.12346942, mean(E): -19.21526547-0.00250157j, var(E): 0.06643153
-0.0
tensor(14.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14680/ 20000/ t/epoch=0.37............. Loss: 0.04834045, mean(E): -19.23065681-0.00609579j, var(E): 0.15741960
-0.0
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14690/ 20000/ t/epoch=0.37............. Loss: 0.05795467, mean(E): -19.22725436+0.00863505j, var(E): 0.18324670
-0.0
tensor(14.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14700/ 20000/ t/epoch=0.37............. Loss: -0.17717200, mean(E): -19.18863693+0.01295059j, var(E): 0.07719908
-0.0
tensor(14.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14710/ 20000/ t/epoch=0.37............. Loss: 0.05895230, mean(E): -19.22839961-0.00701439j, var(E): 0.14587856
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14720/ 20000/ t/epoch=0.37............. Loss: 0.08557741, mean(E): -19.23293952-0.01040284j, var(E): 0.12047178
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14730/ 20000/ t/epoch=0.37............. Loss: -0.12717601, mean(E): -19.18001010+0.00872790j, var(E): 0.09847522
-0.0
tensor(14.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14740/ 20000/ t/epoch=0.37............. Loss: -0.41865972, mean(E): -19.20083259-0.00326712j, var(E): 0.13337332
-0.0
tensor(14.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14750/ 20000/ t/epoch=0.37............. Loss: -0.08926336, mean(E): -19.20244909-0.00807187j, var(E): 0.10755768
-0.0
tensor(14.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14760/ 20000/ t/epoch=0.37............. Loss: -0.14094212, mean(E): -19.21047887+0.00715305j, var(E): 0.10874696
-0.0
tensor(14.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14770/ 20000/ t/epoch=0.37............. Loss: -0.10474952, mean(E): -19.16390809-0.00939423j, var(E): 0.09102976
-0.0
tensor(14.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14780/ 20000/ t/epoch=0.37............. Loss: 0.17222549, mean(E): -19.22211153-0.00711033j, var(E): 0.11391633
-0.0
tensor(14.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14790/ 20000/ t/epoch=0.37............. Loss: 0.03053315, mean(E): -19.21070242-0.00916645j, var(E): 0.09916169
-0.0
tensor(14.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14800/ 20000/ t/epoch=0.37............. Loss: -0.03638393, mean(E): -19.24101810-0.00222952j, var(E): 0.06976995
-0.0
tensor(14.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14810/ 20000/ t/epoch=0.37............. Loss: -0.12977195, mean(E): -19.19146239+0.00971888j, var(E): 0.09960311
-0.0
tensor(14.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14820/ 20000/ t/epoch=0.37............. Loss: -0.26829060, mean(E): -19.19513042-0.01736216j, var(E): 0.15379919
-0.0
tensor(14.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14830/ 20000/ t/epoch=0.37............. Loss: -0.09557762, mean(E): -19.20521391-0.01158597j, var(E): 0.12791045
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14840/ 20000/ t/epoch=0.37............. Loss: -0.13581915, mean(E): -19.20676245-0.01089993j, var(E): 0.10608101
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14850/ 20000/ t/epoch=0.37............. Loss: -0.07774815, mean(E): -19.18546602-0.00603216j, var(E): 0.09129442
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14860/ 20000/ t/epoch=0.37............. Loss: -0.11111724, mean(E): -19.18307411+0.00727023j, var(E): 0.06469127
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14870/ 20000/ t/epoch=0.37............. Loss: 0.28364495, mean(E): -19.21164967+0.00168471j, var(E): 0.15782318
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14880/ 20000/ t/epoch=0.37............. Loss: -0.06042103, mean(E): -19.21670319-0.00349953j, var(E): 0.13127422
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14890/ 20000/ t/epoch=0.37............. Loss: 0.12048965, mean(E): -19.26660535-0.00647312j, var(E): 0.11417065
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14900/ 20000/ t/epoch=0.37............. Loss: 0.00580253, mean(E): -19.23615116+0.01002002j, var(E): 0.08995005
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14910/ 20000/ t/epoch=0.37............. Loss: -0.15456161, mean(E): -19.19686319+0.00645804j, var(E): 0.07599426
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14920/ 20000/ t/epoch=0.37............. Loss: 0.14921894, mean(E): -19.24087418+0.00364620j, var(E): 0.15890865
-0.0
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14930/ 20000/ t/epoch=0.37............. Loss: -0.07540669, mean(E): -19.18400585-0.00673832j, var(E): 0.09242949
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14940/ 20000/ t/epoch=0.37............. Loss: 0.11604808, mean(E): -19.22147114-0.01113541j, var(E): 0.12004315
-0.0
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14950/ 20000/ t/epoch=0.37............. Loss: -0.04018279, mean(E): -19.23913996-0.01481157j, var(E): 0.11265611
-0.0
tensor(14.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14960/ 20000/ t/epoch=0.37............. Loss: -0.12042472, mean(E): -19.20210956-0.00351533j, var(E): 0.12483429
-0.0
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14970/ 20000/ t/epoch=0.37............. Loss: 0.05671705, mean(E): -19.22998401+0.00504026j, var(E): 0.11669896
-0.0
tensor(14.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14980/ 20000/ t/epoch=0.37............. Loss: -0.08377086, mean(E): -19.23721187-0.00171156j, var(E): 0.15943475
-0.0
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14990/ 20000/ t/epoch=0.37............. Loss: 0.10644839, mean(E): -19.22457315+0.00165966j, var(E): 0.12464909
-0.0
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15000/ 20000/ t/epoch=0.37............. Loss: 0.03523300, mean(E): -19.24053422-0.00917983j, var(E): 0.07451451
-0.0
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15010/ 20000/ t/epoch=0.37............. Loss: 0.04272390, mean(E): -19.20673152+0.00620180j, var(E): 0.07018188
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15020/ 20000/ t/epoch=0.37............. Loss: -0.18626981, mean(E): -19.20159785-0.01139565j, var(E): 0.09670858
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15030/ 20000/ t/epoch=0.37............. Loss: 0.14087404, mean(E): -19.21779338-0.00619024j, var(E): 0.10244985
-0.0
tensor(14.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15040/ 20000/ t/epoch=0.37............. Loss: -0.03339764, mean(E): -19.21084234+0.01083728j, var(E): 0.06871217
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15050/ 20000/ t/epoch=0.37............. Loss: 0.03547589, mean(E): -19.23752502-0.00100279j, var(E): 0.09478548
-0.0
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15060/ 20000/ t/epoch=0.37............. Loss: 0.12135385, mean(E): -19.22530201-0.00085847j, var(E): 0.16160264
-0.0
tensor(14.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15070/ 20000/ t/epoch=0.37............. Loss: 0.14187471, mean(E): -19.25223194-0.00521684j, var(E): 0.08140970
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15080/ 20000/ t/epoch=0.37............. Loss: -0.05272981, mean(E): -19.19990995+0.01806942j, var(E): 0.10002908
-0.0
tensor(14.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15090/ 20000/ t/epoch=0.37............. Loss: 0.07577050, mean(E): -19.22924222+0.00675106j, var(E): 0.09563933
-0.0
tensor(14.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15100/ 20000/ t/epoch=0.37............. Loss: 0.10278813, mean(E): -19.21897042-0.00123996j, var(E): 0.12431805
-0.0
tensor(14.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15110/ 20000/ t/epoch=0.37............. Loss: -0.03158048, mean(E): -19.20567345-0.00194335j, var(E): 0.10128625
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15120/ 20000/ t/epoch=0.37............. Loss: 0.04397031, mean(E): -19.22719346-0.00865837j, var(E): 0.11120034
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15130/ 20000/ t/epoch=0.37............. Loss: 0.11110532, mean(E): -19.20890759-0.00168361j, var(E): 0.07524857
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15140/ 20000/ t/epoch=0.37............. Loss: -0.19199787, mean(E): -19.19586526-0.00463866j, var(E): 0.13432336
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15150/ 20000/ t/epoch=0.37............. Loss: -0.15712301, mean(E): -19.21175302+0.00667998j, var(E): 0.13639871
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15160/ 20000/ t/epoch=0.37............. Loss: -0.28699944, mean(E): -19.17861654-0.00023262j, var(E): 0.12250623
-0.0
tensor(14.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15170/ 20000/ t/epoch=0.37............. Loss: -0.03161950, mean(E): -19.21541962+0.00013670j, var(E): 0.11564953
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15180/ 20000/ t/epoch=0.37............. Loss: 0.02564746, mean(E): -19.22343838+0.01266388j, var(E): 0.06621474
-0.0
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15190/ 20000/ t/epoch=0.37............. Loss: -0.14293178, mean(E): -19.18868077+0.00463851j, var(E): 0.09714727
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15200/ 20000/ t/epoch=0.37............. Loss: 0.05037914, mean(E): -19.22444323-0.00586596j, var(E): 0.08961651
-0.0
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15210/ 20000/ t/epoch=0.37............. Loss: 0.15014290, mean(E): -19.24682790-0.00268275j, var(E): 0.12265798
-0.0
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15220/ 20000/ t/epoch=0.37............. Loss: 0.08801640, mean(E): -19.20989004+0.00171778j, var(E): 0.09586620
-0.0
tensor(14.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15230/ 20000/ t/epoch=0.37............. Loss: -0.13057416, mean(E): -19.20617107-0.00298235j, var(E): 0.10656992
-0.0
tensor(14.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15240/ 20000/ t/epoch=0.37............. Loss: 0.11431840, mean(E): -19.19029207+0.00852554j, var(E): 0.08188315
-0.0
tensor(14.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15250/ 20000/ t/epoch=0.37............. Loss: 0.08857811, mean(E): -19.23704632+0.00505557j, var(E): 0.12121888
-0.0
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15260/ 20000/ t/epoch=0.37............. Loss: -0.10526520, mean(E): -19.21174004-0.00948477j, var(E): 0.09048801
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15270/ 20000/ t/epoch=0.37............. Loss: -0.13598362, mean(E): -19.18912750-0.00365162j, var(E): 0.12304039
-0.0
tensor(14.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15280/ 20000/ t/epoch=0.37............. Loss: 0.12056523, mean(E): -19.23012394-0.00461111j, var(E): 0.07139732
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15290/ 20000/ t/epoch=0.37............. Loss: -0.04836362, mean(E): -19.20945079+0.00726966j, var(E): 0.09950791
-0.0
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15300/ 20000/ t/epoch=0.37............. Loss: -0.19076462, mean(E): -19.18703933+0.01385829j, var(E): 0.08505491
-0.0
tensor(14.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15310/ 20000/ t/epoch=0.37............. Loss: 0.16519433, mean(E): -19.25596930-0.00792473j, var(E): 0.09776888
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15320/ 20000/ t/epoch=0.37............. Loss: -0.04699022, mean(E): -19.21538881+0.00166833j, var(E): 0.12694507
-0.0
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15330/ 20000/ t/epoch=0.37............. Loss: -0.00416446, mean(E): -19.21682874+0.00370853j, var(E): 0.09387091
-0.0
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15340/ 20000/ t/epoch=0.37............. Loss: 0.17643969, mean(E): -19.25578686-0.00278009j, var(E): 0.17958975
-0.0
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15350/ 20000/ t/epoch=0.37............. Loss: -0.10778691, mean(E): -19.21486262+0.00203879j, var(E): 0.09315571
-0.0
tensor(14.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15360/ 20000/ t/epoch=0.37............. Loss: -0.08540344, mean(E): -19.23559630+0.00860939j, var(E): 0.08921651
-0.0
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15370/ 20000/ t/epoch=0.38............. Loss: 0.05317270, mean(E): -19.24285708+0.01313488j, var(E): 0.07659734
-0.0
tensor(14.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15380/ 20000/ t/epoch=0.37............. Loss: 0.19111622, mean(E): -19.22889428+0.00992539j, var(E): 0.08522697
-0.0
tensor(14.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15390/ 20000/ t/epoch=0.37............. Loss: -0.01489101, mean(E): -19.19562864-0.01333053j, var(E): 0.06939925
-0.0
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15400/ 20000/ t/epoch=0.37............. Loss: 0.25382050, mean(E): -19.22049290+0.01321865j, var(E): 0.14137539
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15410/ 20000/ t/epoch=0.37............. Loss: -0.05453047, mean(E): -19.21588499+0.00216573j, var(E): 0.08393052
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15420/ 20000/ t/epoch=0.37............. Loss: 0.18270218, mean(E): -19.22280548-0.01363460j, var(E): 0.09568714
-0.0
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15430/ 20000/ t/epoch=0.37............. Loss: -0.15120061, mean(E): -19.19104874-0.00226703j, var(E): 0.10846149
-0.0
tensor(14.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15440/ 20000/ t/epoch=0.37............. Loss: -0.17158875, mean(E): -19.21029067-0.02034825j, var(E): 0.06991402
-0.0
tensor(14.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15450/ 20000/ t/epoch=0.37............. Loss: -0.07108936, mean(E): -19.21853422-0.00047936j, var(E): 0.08604366
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15460/ 20000/ t/epoch=0.37............. Loss: -0.10601902, mean(E): -19.22628546-0.00936336j, var(E): 0.13207127
-0.0
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15470/ 20000/ t/epoch=0.37............. Loss: 0.18476066, mean(E): -19.21830180-0.00021368j, var(E): 0.06991405
-0.0
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15480/ 20000/ t/epoch=0.37............. Loss: 0.24071772, mean(E): -19.24402949+0.00133993j, var(E): 0.13425372
-0.0
tensor(14.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15490/ 20000/ t/epoch=0.37............. Loss: 0.11646071, mean(E): -19.23844081-0.00182648j, var(E): 0.09119513
-0.0
tensor(14.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15500/ 20000/ t/epoch=0.37............. Loss: -0.19887528, mean(E): -19.18098558+0.00135656j, var(E): 0.12878505
-0.0
tensor(14.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15510/ 20000/ t/epoch=0.37............. Loss: 0.15154851, mean(E): -19.24002728+0.00093021j, var(E): 0.07675320
-0.0
tensor(14.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15520/ 20000/ t/epoch=0.37............. Loss: -0.05213146, mean(E): -19.22232633+0.00587021j, var(E): 0.09124812
-0.0
tensor(14.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15530/ 20000/ t/epoch=0.37............. Loss: -0.13366056, mean(E): -19.20254371-0.00402476j, var(E): 0.08387189
-0.0
tensor(14.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15540/ 20000/ t/epoch=0.37............. Loss: 0.29195440, mean(E): -19.25580469-0.00435907j, var(E): 0.06757301
-0.0
tensor(14.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15550/ 20000/ t/epoch=0.37............. Loss: -0.05151437, mean(E): -19.20142136-0.02467144j, var(E): 0.10418539
-0.0
tensor(14.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15560/ 20000/ t/epoch=0.37............. Loss: -0.04210258, mean(E): -19.24922125-0.01473439j, var(E): 0.13309929
-0.0
tensor(14.9484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15570/ 20000/ t/epoch=0.37............. Loss: 0.06365710, mean(E): -19.19862744+0.00877351j, var(E): 0.07898043
-0.0
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15580/ 20000/ t/epoch=0.37............. Loss: -0.18442742, mean(E): -19.16883440-0.01261931j, var(E): 0.12359992
-0.0
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15590/ 20000/ t/epoch=0.37............. Loss: 0.02777403, mean(E): -19.22971332+0.00247108j, var(E): 0.10716575
-0.0
tensor(14.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15600/ 20000/ t/epoch=0.37............. Loss: -0.14100664, mean(E): -19.18395020+0.00144212j, var(E): 0.08176680
-0.0
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15610/ 20000/ t/epoch=0.37............. Loss: 0.02791171, mean(E): -19.21587298+0.00038874j, var(E): 0.08929579
-0.0
tensor(14.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15620/ 20000/ t/epoch=0.37............. Loss: -0.02800933, mean(E): -19.19424235-0.00325036j, var(E): 0.07008602
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15630/ 20000/ t/epoch=0.37............. Loss: 0.02877357, mean(E): -19.23396006-0.00234975j, var(E): 0.13941940
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15640/ 20000/ t/epoch=0.37............. Loss: -0.20915612, mean(E): -19.18750504+0.00388506j, var(E): 0.07209019
-0.0
tensor(14.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15650/ 20000/ t/epoch=0.37............. Loss: -0.00991643, mean(E): -19.20435979+0.00407684j, var(E): 0.11122096
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15660/ 20000/ t/epoch=0.37............. Loss: -0.20540154, mean(E): -19.21238761+0.00983242j, var(E): 0.08637107
-0.0
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15670/ 20000/ t/epoch=0.37............. Loss: 0.16475180, mean(E): -19.24143198+0.00007687j, var(E): 0.09446566
-0.0
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15680/ 20000/ t/epoch=0.37............. Loss: 0.04558544, mean(E): -19.22659236-0.00129229j, var(E): 0.14959712
-0.0
tensor(14.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15690/ 20000/ t/epoch=0.37............. Loss: 0.01854127, mean(E): -19.23056782+0.00559118j, var(E): 0.09060034
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15700/ 20000/ t/epoch=0.37............. Loss: 0.13013126, mean(E): -19.26283684+0.00424994j, var(E): 0.10261805
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15710/ 20000/ t/epoch=0.37............. Loss: -0.00795128, mean(E): -19.19393872+0.02251400j, var(E): 0.10461170
-0.0
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15720/ 20000/ t/epoch=0.37............. Loss: -0.13405454, mean(E): -19.20390871-0.00988316j, var(E): 0.12819007
-0.0
tensor(14.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15730/ 20000/ t/epoch=0.37............. Loss: -0.07807116, mean(E): -19.20692701-0.00141852j, var(E): 0.08294737
-0.0
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15740/ 20000/ t/epoch=0.37............. Loss: -0.03064627, mean(E): -19.20981720+0.00037527j, var(E): 0.06642370
-0.0
tensor(14.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15750/ 20000/ t/epoch=0.37............. Loss: 0.07338581, mean(E): -19.22317004+0.00573677j, var(E): 0.10821642
-0.0
tensor(14.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15760/ 20000/ t/epoch=0.37............. Loss: 0.12014860, mean(E): -19.24155162-0.00604340j, var(E): 0.08050157
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15770/ 20000/ t/epoch=0.37............. Loss: -0.03766646, mean(E): -19.20007690+0.00653386j, var(E): 0.08344449
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15780/ 20000/ t/epoch=0.37............. Loss: 0.14860977, mean(E): -19.23031628-0.01072785j, var(E): 0.09029553
-0.0
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15790/ 20000/ t/epoch=0.37............. Loss: -0.08791264, mean(E): -19.19595140-0.00384351j, var(E): 0.16217237
-0.0
tensor(14.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15800/ 20000/ t/epoch=0.37............. Loss: 0.13560287, mean(E): -19.19854864-0.00457947j, var(E): 0.09240600
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15810/ 20000/ t/epoch=0.37............. Loss: -0.11900928, mean(E): -19.19453107+0.00508915j, var(E): 0.11048133
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15820/ 20000/ t/epoch=0.37............. Loss: -0.32918157, mean(E): -19.19700985+0.01334912j, var(E): 0.16799514
-0.0
tensor(14.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15830/ 20000/ t/epoch=0.37............. Loss: -0.16219754, mean(E): -19.20339015+0.00056300j, var(E): 0.09850896
-0.0
tensor(14.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15840/ 20000/ t/epoch=0.37............. Loss: 0.05068110, mean(E): -19.20998098+0.01532009j, var(E): 0.10419533
-0.0
tensor(14.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15850/ 20000/ t/epoch=0.37............. Loss: 0.10388783, mean(E): -19.20650266+0.00095109j, var(E): 0.09826131
-0.0
tensor(14.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15860/ 20000/ t/epoch=0.37............. Loss: 0.10078181, mean(E): -19.22210419-0.00496619j, var(E): 0.11699879
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15870/ 20000/ t/epoch=0.37............. Loss: -0.13928391, mean(E): -19.18358455-0.00414647j, var(E): 0.09368194
-0.0
tensor(14.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15880/ 20000/ t/epoch=0.38............. Loss: -0.13016732, mean(E): -19.22992649-0.00380796j, var(E): 0.07076651
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15890/ 20000/ t/epoch=0.37............. Loss: -0.13830193, mean(E): -19.23560052-0.00325094j, var(E): 0.08633031
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15900/ 20000/ t/epoch=0.37............. Loss: 0.01726800, mean(E): -19.21250765+0.01022686j, var(E): 0.11917445
-0.0
tensor(14.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15910/ 20000/ t/epoch=0.37............. Loss: -0.11148054, mean(E): -19.20761437+0.00660331j, var(E): 0.10039101
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15920/ 20000/ t/epoch=0.37............. Loss: -0.14140044, mean(E): -19.21436474+0.00619282j, var(E): 0.06686142
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15930/ 20000/ t/epoch=0.37............. Loss: 0.14555175, mean(E): -19.22517120+0.00306501j, var(E): 0.10386027
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15940/ 20000/ t/epoch=0.37............. Loss: -0.14034587, mean(E): -19.21040532+0.00574335j, var(E): 0.06430464
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15950/ 20000/ t/epoch=0.37............. Loss: 0.07853834, mean(E): -19.20306334-0.00536934j, var(E): 0.15013365
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15960/ 20000/ t/epoch=0.37............. Loss: 0.01547585, mean(E): -19.19560791+0.00425810j, var(E): 0.05867626
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15970/ 20000/ t/epoch=0.37............. Loss: -0.00876156, mean(E): -19.21944484+0.00318124j, var(E): 0.06628561
-0.0
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15980/ 20000/ t/epoch=0.37............. Loss: -0.09051378, mean(E): -19.19630016+0.00286078j, var(E): 0.16264254
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15990/ 20000/ t/epoch=0.37............. Loss: -0.01706931, mean(E): -19.23545682-0.00558973j, var(E): 0.06484887
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16000/ 20000/ t/epoch=0.37............. Loss: 0.04938153, mean(E): -19.22414764+0.01069477j, var(E): 0.10443539
-0.0
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16010/ 20000/ t/epoch=0.37............. Loss: 0.18269521, mean(E): -19.22663331+0.00124473j, var(E): 0.08393567
-0.0
tensor(14.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16020/ 20000/ t/epoch=0.37............. Loss: 0.07725670, mean(E): -19.24513136+0.00950723j, var(E): 0.07837443
-0.0
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16030/ 20000/ t/epoch=0.37............. Loss: 0.15008634, mean(E): -19.23913941+0.00050074j, var(E): 0.07730266
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16040/ 20000/ t/epoch=0.37............. Loss: 0.08146577, mean(E): -19.19042238+0.00250184j, var(E): 0.11072571
-0.0
tensor(14.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16050/ 20000/ t/epoch=0.37............. Loss: 0.01306024, mean(E): -19.20867198+0.00156420j, var(E): 0.07378519
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16060/ 20000/ t/epoch=0.37............. Loss: -0.25194454, mean(E): -19.21029967-0.01207772j, var(E): 0.09060020
-0.0
tensor(14.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16070/ 20000/ t/epoch=0.37............. Loss: 0.01960994, mean(E): -19.22055305+0.01291361j, var(E): 0.07373507
-0.0
tensor(14.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16080/ 20000/ t/epoch=0.37............. Loss: -0.06921258, mean(E): -19.17955565-0.00702696j, var(E): 0.10672611
-0.0
tensor(14.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16090/ 20000/ t/epoch=0.37............. Loss: 0.14094827, mean(E): -19.24332067-0.00104296j, var(E): 0.10419403
-0.0
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16100/ 20000/ t/epoch=0.37............. Loss: -0.21296883, mean(E): -19.17945912+0.00689158j, var(E): 0.07544519
-0.0
tensor(14.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16110/ 20000/ t/epoch=0.37............. Loss: 0.14792691, mean(E): -19.23439204+0.00176092j, var(E): 0.10619202
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16120/ 20000/ t/epoch=0.37............. Loss: 0.00736606, mean(E): -19.23076601-0.00375680j, var(E): 0.06168698
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16130/ 20000/ t/epoch=0.37............. Loss: 0.15174519, mean(E): -19.22082390-0.00113751j, var(E): 0.21530900
-0.0
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16140/ 20000/ t/epoch=0.37............. Loss: 0.02468885, mean(E): -19.20749790-0.00922501j, var(E): 0.07024908
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16150/ 20000/ t/epoch=0.37............. Loss: 0.02214666, mean(E): -19.20751852-0.00782039j, var(E): 0.10438834
-0.0
tensor(14.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16160/ 20000/ t/epoch=0.37............. Loss: -0.03920839, mean(E): -19.20237222+0.01359987j, var(E): 0.10961432
-0.0
tensor(14.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16170/ 20000/ t/epoch=0.37............. Loss: -0.15976023, mean(E): -19.21279793-0.00658526j, var(E): 0.13318386
-0.0
tensor(14.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16180/ 20000/ t/epoch=0.37............. Loss: 0.03682875, mean(E): -19.18168424+0.01542771j, var(E): 0.07016566
-0.0
tensor(14.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16190/ 20000/ t/epoch=0.37............. Loss: 0.11406036, mean(E): -19.25234796+0.00092392j, var(E): 0.10217843
-0.0
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16200/ 20000/ t/epoch=0.37............. Loss: -0.09938871, mean(E): -19.22006590+0.00960769j, var(E): 0.09306832
-0.0
tensor(14.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16210/ 20000/ t/epoch=0.37............. Loss: 0.03926233, mean(E): -19.20987052-0.00044237j, var(E): 0.09059906
-0.0
tensor(14.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16220/ 20000/ t/epoch=0.37............. Loss: -0.20386650, mean(E): -19.18303933-0.00388388j, var(E): 0.13518157
-0.0
tensor(14.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16230/ 20000/ t/epoch=0.37............. Loss: 0.11270794, mean(E): -19.20767966-0.01520726j, var(E): 0.07839994
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16240/ 20000/ t/epoch=0.37............. Loss: 0.13024536, mean(E): -19.24092425+0.00357936j, var(E): 0.07477157
-0.0
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16250/ 20000/ t/epoch=0.37............. Loss: 0.02617286, mean(E): -19.18908348+0.00230628j, var(E): 0.05886177
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16260/ 20000/ t/epoch=0.37............. Loss: 0.27556379, mean(E): -19.24027752-0.00864043j, var(E): 0.11894032
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16270/ 20000/ t/epoch=0.37............. Loss: -0.17967579, mean(E): -19.20993682-0.00676707j, var(E): 0.15732663
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16280/ 20000/ t/epoch=0.37............. Loss: 0.00566526, mean(E): -19.21135344+0.00571046j, var(E): 0.10735888
-0.0
tensor(14.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16290/ 20000/ t/epoch=0.37............. Loss: 0.06193816, mean(E): -19.21017873+0.00971619j, var(E): 0.12566528
-0.0
tensor(14.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16300/ 20000/ t/epoch=0.37............. Loss: -0.02872870, mean(E): -19.21600418+0.00240733j, var(E): 0.10217470
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16310/ 20000/ t/epoch=0.37............. Loss: -0.05548952, mean(E): -19.19061418-0.00053455j, var(E): 0.09643164
-0.0
tensor(14.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16320/ 20000/ t/epoch=0.37............. Loss: 0.00188476, mean(E): -19.25555164+0.01170977j, var(E): 0.09729156
-0.0
tensor(14.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16330/ 20000/ t/epoch=0.37............. Loss: 0.17971953, mean(E): -19.27725708+0.00874580j, var(E): 0.08812583
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16340/ 20000/ t/epoch=0.37............. Loss: 0.07773950, mean(E): -19.18467500+0.00138449j, var(E): 0.18369590
-0.0
tensor(14.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16350/ 20000/ t/epoch=0.37............. Loss: 0.07101343, mean(E): -19.20163329-0.02022855j, var(E): 0.13562368
-0.0
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16360/ 20000/ t/epoch=0.38............. Loss: -0.22555909, mean(E): -19.18864642-0.00009175j, var(E): 0.08354182
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16370/ 20000/ t/epoch=0.37............. Loss: 0.02787785, mean(E): -19.20767573+0.00293202j, var(E): 0.13998519
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16380/ 20000/ t/epoch=0.37............. Loss: 0.20424534, mean(E): -19.23898642+0.00448174j, var(E): 0.10709217
-0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16390/ 20000/ t/epoch=0.37............. Loss: 0.17983201, mean(E): -19.25013609+0.01154567j, var(E): 0.06512612
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16400/ 20000/ t/epoch=0.37............. Loss: 0.17057991, mean(E): -19.22723256+0.00343832j, var(E): 0.11104796
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16410/ 20000/ t/epoch=0.37............. Loss: 0.05982424, mean(E): -19.18884498+0.00523326j, var(E): 0.10215162
-0.0
tensor(14.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16420/ 20000/ t/epoch=0.37............. Loss: 0.09091896, mean(E): -19.23055037+0.01775364j, var(E): 0.13410456
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16430/ 20000/ t/epoch=0.37............. Loss: 0.02055090, mean(E): -19.21452221+0.00212008j, var(E): 0.08104661
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16440/ 20000/ t/epoch=0.37............. Loss: 0.04308191, mean(E): -19.24118489+0.00720304j, var(E): 0.07633073
-0.0
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16450/ 20000/ t/epoch=0.37............. Loss: -0.17007296, mean(E): -19.20999599-0.00181623j, var(E): 0.08188804
-0.0
tensor(14.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16460/ 20000/ t/epoch=0.37............. Loss: 0.07275586, mean(E): -19.21537270-0.00635886j, var(E): 0.09905875
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16470/ 20000/ t/epoch=0.37............. Loss: -0.19004811, mean(E): -19.20885753-0.00547325j, var(E): 0.11426728
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16480/ 20000/ t/epoch=0.37............. Loss: 0.09921523, mean(E): -19.25858257+0.00168397j, var(E): 0.11404763
-0.0
tensor(14.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16490/ 20000/ t/epoch=0.37............. Loss: -0.14978466, mean(E): -19.22363274+0.00672925j, var(E): 0.07056887
-0.0
tensor(14.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16500/ 20000/ t/epoch=0.37............. Loss: -0.03461488, mean(E): -19.21928099-0.00654004j, var(E): 0.10190976
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16510/ 20000/ t/epoch=0.37............. Loss: 0.16036435, mean(E): -19.24879107-0.00026581j, var(E): 0.07932333
-0.0
tensor(14.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16520/ 20000/ t/epoch=0.37............. Loss: 0.25262240, mean(E): -19.28310275-0.00963280j, var(E): 0.14071808
-0.0
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16530/ 20000/ t/epoch=0.37............. Loss: -0.06163904, mean(E): -19.21363092-0.01612982j, var(E): 0.11342720
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16540/ 20000/ t/epoch=0.37............. Loss: -0.07934352, mean(E): -19.20429001-0.00373064j, var(E): 0.07751532
-0.0
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16550/ 20000/ t/epoch=0.37............. Loss: 0.17119964, mean(E): -19.22351521-0.01463923j, var(E): 0.07592002
-0.0
tensor(14.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16560/ 20000/ t/epoch=0.37............. Loss: 0.05840892, mean(E): -19.23469493-0.01032073j, var(E): 0.15559051
-0.0
tensor(14.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16570/ 20000/ t/epoch=0.37............. Loss: -0.03381564, mean(E): -19.25682676+0.00600361j, var(E): 0.07339103
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16580/ 20000/ t/epoch=0.37............. Loss: 0.00579794, mean(E): -19.22129006+0.00339480j, var(E): 0.06486840
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16590/ 20000/ t/epoch=0.37............. Loss: 0.09943843, mean(E): -19.21659380-0.00247390j, var(E): 0.08289758
-0.0
tensor(14.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16600/ 20000/ t/epoch=0.37............. Loss: 0.09225779, mean(E): -19.22464115-0.00048716j, var(E): 0.12335172
-0.0
tensor(14.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16610/ 20000/ t/epoch=0.37............. Loss: 0.07696036, mean(E): -19.21765793+0.00035057j, var(E): 0.08064143
-0.0
tensor(14.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16620/ 20000/ t/epoch=0.37............. Loss: -0.03151820, mean(E): -19.20126181-0.00000878j, var(E): 0.09587123
-0.0
tensor(14.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16630/ 20000/ t/epoch=0.37............. Loss: 0.05939628, mean(E): -19.20812173-0.00356286j, var(E): 0.06698111
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16640/ 20000/ t/epoch=0.37............. Loss: -0.16400699, mean(E): -19.22614048+0.00029725j, var(E): 0.07293166
-0.0
tensor(14.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16650/ 20000/ t/epoch=0.37............. Loss: -0.03913574, mean(E): -19.22408548-0.00006939j, var(E): 0.07464595
-0.0
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16660/ 20000/ t/epoch=0.37............. Loss: 0.15015686, mean(E): -19.22052647+0.01502174j, var(E): 0.08497865
-0.0
tensor(14.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16670/ 20000/ t/epoch=0.37............. Loss: 0.05916010, mean(E): -19.23421407-0.00485821j, var(E): 0.09307716
-0.0
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16680/ 20000/ t/epoch=0.37............. Loss: 0.00338917, mean(E): -19.24122566+0.00271725j, var(E): 0.10104058
-0.0
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16690/ 20000/ t/epoch=0.37............. Loss: -0.02509515, mean(E): -19.19921766+0.00199729j, var(E): 0.09969265
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16700/ 20000/ t/epoch=0.37............. Loss: 0.23045565, mean(E): -19.22012963+0.00946396j, var(E): 0.11526275
-0.0
tensor(14.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16710/ 20000/ t/epoch=0.37............. Loss: 0.09532344, mean(E): -19.19907624-0.00747215j, var(E): 0.12833966
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16720/ 20000/ t/epoch=0.37............. Loss: -0.01806726, mean(E): -19.19530568+0.00066318j, var(E): 0.13571405
-0.0
tensor(14.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16730/ 20000/ t/epoch=0.37............. Loss: 0.04826293, mean(E): -19.22822325+0.00127962j, var(E): 0.08708819
-0.0
tensor(14.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16740/ 20000/ t/epoch=0.37............. Loss: 0.02073332, mean(E): -19.24062317+0.00417013j, var(E): 0.06601359
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16750/ 20000/ t/epoch=0.37............. Loss: -0.01391280, mean(E): -19.21856087+0.00310370j, var(E): 0.08910508
-0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16760/ 20000/ t/epoch=0.37............. Loss: 0.18372196, mean(E): -19.25624056-0.00483896j, var(E): 0.10627840
-0.0
tensor(14.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16770/ 20000/ t/epoch=0.37............. Loss: -0.09927253, mean(E): -19.21752391+0.01150466j, var(E): 0.10861771
-0.0
tensor(14.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16780/ 20000/ t/epoch=0.37............. Loss: -0.00372782, mean(E): -19.23930570+0.00228635j, var(E): 0.09998477
-0.0
tensor(14.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16790/ 20000/ t/epoch=0.38............. Loss: 0.01221183, mean(E): -19.19023051+0.00530295j, var(E): 0.06856224
-0.0
tensor(14.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16800/ 20000/ t/epoch=0.37............. Loss: 0.37354542, mean(E): -19.24958775+0.00489394j, var(E): 0.09537058
-0.0
tensor(14.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16810/ 20000/ t/epoch=0.37............. Loss: -0.01284745, mean(E): -19.20206988+0.01030254j, var(E): 0.09054004
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16820/ 20000/ t/epoch=0.37............. Loss: -0.04607096, mean(E): -19.20954097-0.00771195j, var(E): 0.08921337
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16830/ 20000/ t/epoch=0.38............. Loss: -0.06874588, mean(E): -19.20227880+0.00955439j, var(E): 0.09892273
-0.0
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16840/ 20000/ t/epoch=0.37............. Loss: 0.10012106, mean(E): -19.20146394+0.00310830j, var(E): 0.08812367
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16850/ 20000/ t/epoch=0.37............. Loss: -0.06319528, mean(E): -19.19180493+0.00728782j, var(E): 0.07797945
-0.0
tensor(14.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16860/ 20000/ t/epoch=0.37............. Loss: 0.29111185, mean(E): -19.22882315-0.01057316j, var(E): 0.11305646
-0.0
tensor(14.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16870/ 20000/ t/epoch=0.38............. Loss: -0.17011901, mean(E): -19.18390554+0.00579409j, var(E): 0.16226837
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16880/ 20000/ t/epoch=0.37............. Loss: 0.08826455, mean(E): -19.21707858-0.01684897j, var(E): 0.07294744
-0.0
tensor(14.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16890/ 20000/ t/epoch=0.37............. Loss: -0.08563327, mean(E): -19.21904911-0.00629462j, var(E): 0.06968551
-0.0
tensor(14.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16900/ 20000/ t/epoch=0.37............. Loss: -0.03822987, mean(E): -19.25211768-0.00000759j, var(E): 0.10005868
-0.0
tensor(14.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16910/ 20000/ t/epoch=0.37............. Loss: -0.08403108, mean(E): -19.20919154-0.00998525j, var(E): 0.06333188
-0.0
tensor(14.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16920/ 20000/ t/epoch=0.37............. Loss: 0.05604549, mean(E): -19.21143879-0.00002932j, var(E): 0.06516809
-0.0
tensor(14.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16930/ 20000/ t/epoch=0.37............. Loss: 0.00150339, mean(E): -19.21003457-0.00326933j, var(E): 0.12013006
-0.0
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16940/ 20000/ t/epoch=0.37............. Loss: -0.06431831, mean(E): -19.22502031-0.00505855j, var(E): 0.07790499
-0.0
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16950/ 20000/ t/epoch=0.37............. Loss: -0.30479922, mean(E): -19.19787893-0.00514376j, var(E): 0.11774866
-0.0
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16960/ 20000/ t/epoch=0.37............. Loss: -0.29778534, mean(E): -19.20072082-0.01161652j, var(E): 0.12399575
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16970/ 20000/ t/epoch=0.37............. Loss: 0.06100258, mean(E): -19.20879271-0.00580424j, var(E): 0.08568450
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16980/ 20000/ t/epoch=0.37............. Loss: 0.05380806, mean(E): -19.23805911-0.00092225j, var(E): 0.08647392
-0.0
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16990/ 20000/ t/epoch=0.37............. Loss: 0.10918924, mean(E): -19.23816443+0.00610515j, var(E): 0.09060134
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17000/ 20000/ t/epoch=0.37............. Loss: 0.18835916, mean(E): -19.22742142+0.00039546j, var(E): 0.08496577
-0.0
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17010/ 20000/ t/epoch=0.37............. Loss: -0.05690179, mean(E): -19.21906940-0.00061184j, var(E): 0.09628380
-0.0
tensor(14.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17020/ 20000/ t/epoch=0.37............. Loss: -0.03148765, mean(E): -19.20845139-0.00266487j, var(E): 0.11794263
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17030/ 20000/ t/epoch=0.37............. Loss: 0.05218805, mean(E): -19.22121366+0.01263800j, var(E): 0.09257598
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17040/ 20000/ t/epoch=0.37............. Loss: -0.00710692, mean(E): -19.20691655-0.00701731j, var(E): 0.09218863
-0.0
tensor(14.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17050/ 20000/ t/epoch=0.37............. Loss: 0.15993138, mean(E): -19.21422014+0.00178747j, var(E): 0.06735437
-0.0
tensor(14.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17060/ 20000/ t/epoch=0.37............. Loss: -0.09236054, mean(E): -19.20154176-0.01146918j, var(E): 0.05770529
-0.0
tensor(14.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17070/ 20000/ t/epoch=0.37............. Loss: 0.06631193, mean(E): -19.22578002-0.00054443j, var(E): 0.11834225
-0.0
tensor(14.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17080/ 20000/ t/epoch=0.37............. Loss: -0.12115263, mean(E): -19.20390087+0.00487021j, var(E): 0.09164054
-0.0
tensor(14.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17090/ 20000/ t/epoch=0.37............. Loss: 0.27602938, mean(E): -19.24397850-0.00731062j, var(E): 0.08693102
-0.0
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17100/ 20000/ t/epoch=0.37............. Loss: -0.01597463, mean(E): -19.22249354-0.00391528j, var(E): 0.16286106
-0.0
tensor(14.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17110/ 20000/ t/epoch=0.37............. Loss: 0.18445705, mean(E): -19.26155603-0.00083969j, var(E): 0.11072160
-0.0
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17120/ 20000/ t/epoch=0.37............. Loss: -0.00758928, mean(E): -19.22743909+0.01077110j, var(E): 0.15881443
-0.0
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17130/ 20000/ t/epoch=0.37............. Loss: -0.10882344, mean(E): -19.21332101-0.00627002j, var(E): 0.06460744
-0.0
tensor(14.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17140/ 20000/ t/epoch=0.37............. Loss: 0.24272876, mean(E): -19.21485452+0.01184435j, var(E): 0.07040555
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17150/ 20000/ t/epoch=0.37............. Loss: 0.06969651, mean(E): -19.23555718-0.01213658j, var(E): 0.19884064
-0.0
tensor(14.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17160/ 20000/ t/epoch=0.37............. Loss: 0.05449136, mean(E): -19.21329557+0.00264405j, var(E): 0.06973668
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17170/ 20000/ t/epoch=0.37............. Loss: -0.04601558, mean(E): -19.19666228-0.01647489j, var(E): 0.07631551
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17180/ 20000/ t/epoch=0.37............. Loss: -0.08725550, mean(E): -19.17663915-0.00409447j, var(E): 0.10233573
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17190/ 20000/ t/epoch=0.37............. Loss: -0.03858457, mean(E): -19.21012895+0.00633846j, var(E): 0.08036407
-0.0
tensor(14.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17200/ 20000/ t/epoch=0.37............. Loss: -0.22350949, mean(E): -19.18667809-0.00308722j, var(E): 0.06896191
-0.0
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17210/ 20000/ t/epoch=0.37............. Loss: -0.02411000, mean(E): -19.22121172+0.01188309j, var(E): 0.08492490
-0.0
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17220/ 20000/ t/epoch=0.37............. Loss: -0.06236878, mean(E): -19.22141844+0.00732881j, var(E): 0.08482969
-0.0
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17230/ 20000/ t/epoch=0.37............. Loss: -0.23969604, mean(E): -19.18945680+0.00710964j, var(E): 0.09580072
-0.0
tensor(14.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17240/ 20000/ t/epoch=0.37............. Loss: 0.06568936, mean(E): -19.20330630-0.00018734j, var(E): 0.09250711
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17250/ 20000/ t/epoch=0.37............. Loss: 0.00850870, mean(E): -19.21770391-0.00925102j, var(E): 0.06067730
-0.0
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17260/ 20000/ t/epoch=0.37............. Loss: -0.06657020, mean(E): -19.21261146-0.00438634j, var(E): 0.09361506
-0.0
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17270/ 20000/ t/epoch=0.37............. Loss: 0.20017932, mean(E): -19.22979140-0.00748506j, var(E): 0.12036040
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17280/ 20000/ t/epoch=0.37............. Loss: -0.07470334, mean(E): -19.19770071+0.00173499j, var(E): 0.09094457
-0.0
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(14.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17290/ 20000/ t/epoch=0.37............. Loss: -0.06601356, mean(E): -19.19729156+0.00311806j, var(E): 0.07272517
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17300/ 20000/ t/epoch=0.37............. Loss: -0.00800956, mean(E): -19.22120785-0.00403610j, var(E): 0.07317428
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17310/ 20000/ t/epoch=0.37............. Loss: 0.14317153, mean(E): -19.23935225-0.00842952j, var(E): 0.10554485
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17320/ 20000/ t/epoch=0.37............. Loss: -0.10746770, mean(E): -19.20865948-0.01292702j, var(E): 0.05729886
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17330/ 20000/ t/epoch=0.37............. Loss: -0.02247150, mean(E): -19.21441831-0.00124056j, var(E): 0.09494410
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17340/ 20000/ t/epoch=0.37............. Loss: 0.17517537, mean(E): -19.23491837+0.00127801j, var(E): 0.09051648
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17350/ 20000/ t/epoch=0.37............. Loss: 0.06502245, mean(E): -19.19027390+0.00891380j, var(E): 0.13114487
-0.0
tensor(15.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17360/ 20000/ t/epoch=0.37............. Loss: 0.08501419, mean(E): -19.23614799+0.00243377j, var(E): 0.08935399
-0.0
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17370/ 20000/ t/epoch=0.37............. Loss: 0.09363032, mean(E): -19.25353029-0.01258497j, var(E): 0.06491469
-0.0
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17380/ 20000/ t/epoch=0.37............. Loss: -0.17104625, mean(E): -19.22298802-0.01081967j, var(E): 0.08794790
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17390/ 20000/ t/epoch=0.38............. Loss: -0.13015346, mean(E): -19.20684839-0.00594546j, var(E): 0.07262003
-0.0
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17400/ 20000/ t/epoch=0.37............. Loss: -0.07817025, mean(E): -19.21778927-0.00377173j, var(E): 0.09577179
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17410/ 20000/ t/epoch=0.38............. Loss: -0.10436024, mean(E): -19.21534116-0.00267158j, var(E): 0.10712167
-0.0
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17420/ 20000/ t/epoch=0.37............. Loss: -0.01975252, mean(E): -19.24438641+0.00094498j, var(E): 0.12028915
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17430/ 20000/ t/epoch=0.37............. Loss: 0.05387134, mean(E): -19.20880902-0.00185692j, var(E): 0.10863936
-0.0
tensor(15.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17440/ 20000/ t/epoch=0.37............. Loss: 0.05153788, mean(E): -19.24359096-0.00432105j, var(E): 0.10086095
-0.0
tensor(15.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17450/ 20000/ t/epoch=0.37............. Loss: 0.04623080, mean(E): -19.23231388+0.01243910j, var(E): 0.07766327
-0.0
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17460/ 20000/ t/epoch=0.37............. Loss: -0.05901033, mean(E): -19.21702663-0.00014254j, var(E): 0.07326822
-0.0
tensor(15.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17470/ 20000/ t/epoch=0.37............. Loss: 0.04348052, mean(E): -19.21522454-0.00006274j, var(E): 0.11742874
-0.0
tensor(15.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17480/ 20000/ t/epoch=0.37............. Loss: 0.01434357, mean(E): -19.23607158+0.00321374j, var(E): 0.10231072
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17490/ 20000/ t/epoch=0.37............. Loss: -0.00674442, mean(E): -19.23291011+0.00850830j, var(E): 0.07397087
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17500/ 20000/ t/epoch=0.38............. Loss: 0.08736591, mean(E): -19.24324495-0.00336182j, var(E): 0.08225883
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17510/ 20000/ t/epoch=0.37............. Loss: 0.01184148, mean(E): -19.21226036+0.00922167j, var(E): 0.07317221
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17520/ 20000/ t/epoch=0.37............. Loss: 0.05512618, mean(E): -19.20774357-0.00497864j, var(E): 0.06673253
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17530/ 20000/ t/epoch=0.37............. Loss: 0.12435741, mean(E): -19.21403895+0.00014912j, var(E): 0.08867441
-0.0
tensor(15.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17540/ 20000/ t/epoch=0.37............. Loss: -0.13957006, mean(E): -19.17787527+0.01257249j, var(E): 0.10076850
-0.0
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17550/ 20000/ t/epoch=0.37............. Loss: -0.04645399, mean(E): -19.20574188+0.00200724j, var(E): 0.10293100
-0.0
tensor(15.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17560/ 20000/ t/epoch=0.37............. Loss: -0.22343414, mean(E): -19.18083869+0.00002085j, var(E): 0.11530035
-0.0
tensor(15.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17570/ 20000/ t/epoch=0.37............. Loss: -0.06715653, mean(E): -19.18950759+0.00052284j, var(E): 0.07909723
-0.0
tensor(15.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17580/ 20000/ t/epoch=0.37............. Loss: -0.21044187, mean(E): -19.20950130-0.00568635j, var(E): 0.08248518
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17590/ 20000/ t/epoch=0.37............. Loss: 0.08346421, mean(E): -19.25160726-0.00134382j, var(E): 0.07672644
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17600/ 20000/ t/epoch=0.37............. Loss: 0.10360781, mean(E): -19.22780520-0.01024379j, var(E): 0.06038724
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17610/ 20000/ t/epoch=0.37............. Loss: -0.18659950, mean(E): -19.21915223-0.01204909j, var(E): 0.11977949
-0.0
tensor(15.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17620/ 20000/ t/epoch=0.37............. Loss: -0.05954946, mean(E): -19.22338003-0.00316072j, var(E): 0.12035765
-0.0
tensor(15.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17630/ 20000/ t/epoch=0.37............. Loss: 0.08113460, mean(E): -19.20209595-0.00812875j, var(E): 0.08012118
-0.0
tensor(15.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17640/ 20000/ t/epoch=0.37............. Loss: 0.15488482, mean(E): -19.20629562-0.00539932j, var(E): 0.09400362
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17650/ 20000/ t/epoch=0.37............. Loss: 0.00000267, mean(E): -19.22431429-0.00669612j, var(E): 0.05853486
-0.0
tensor(15.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17660/ 20000/ t/epoch=0.37............. Loss: -0.08266050, mean(E): -19.22105830-0.00065489j, var(E): 0.10632946
-0.0
tensor(15.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17670/ 20000/ t/epoch=0.37............. Loss: -0.12679878, mean(E): -19.17767231-0.00213631j, var(E): 0.08767981
-0.0
tensor(15.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17680/ 20000/ t/epoch=0.38............. Loss: -0.02799031, mean(E): -19.22215269+0.00145619j, var(E): 0.05857971
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17690/ 20000/ t/epoch=0.37............. Loss: -0.30113812, mean(E): -19.16515124+0.00751744j, var(E): 0.19764193
-0.0
tensor(15.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17700/ 20000/ t/epoch=0.37............. Loss: -0.09919593, mean(E): -19.21143298+0.00502903j, var(E): 0.09239754
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17710/ 20000/ t/epoch=0.37............. Loss: 0.16893736, mean(E): -19.25955844+0.00495462j, var(E): 0.16075436
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17720/ 20000/ t/epoch=0.37............. Loss: 0.01290393, mean(E): -19.23401230-0.00388373j, var(E): 0.08108241
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17730/ 20000/ t/epoch=0.37............. Loss: 0.05580726, mean(E): -19.24300082-0.00370668j, var(E): 0.07717431
-0.0
tensor(15.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17740/ 20000/ t/epoch=0.37............. Loss: -0.10031360, mean(E): -19.19312611-0.00630084j, var(E): 0.07047627
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17750/ 20000/ t/epoch=0.37............. Loss: -0.10961021, mean(E): -19.17351387-0.01436542j, var(E): 0.08131553
-0.0
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17760/ 20000/ t/epoch=0.37............. Loss: -0.10502660, mean(E): -19.20583745-0.00412526j, var(E): 0.07243352
-0.0
tensor(15.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17770/ 20000/ t/epoch=0.37............. Loss: 0.01208889, mean(E): -19.20283784+0.01635534j, var(E): 0.10485849
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17780/ 20000/ t/epoch=0.37............. Loss: 0.14647298, mean(E): -19.22139604-0.00283296j, var(E): 0.09092194
-0.0
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17790/ 20000/ t/epoch=0.37............. Loss: -0.01643019, mean(E): -19.23689875+0.00035188j, var(E): 0.06368031
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17800/ 20000/ t/epoch=0.37............. Loss: -0.08156903, mean(E): -19.22537611-0.00289663j, var(E): 0.06474565
-0.0
tensor(15.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17810/ 20000/ t/epoch=0.37............. Loss: 0.05032792, mean(E): -19.21266225-0.01101395j, var(E): 0.06550527
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17820/ 20000/ t/epoch=0.37............. Loss: -0.25532065, mean(E): -19.17882689+0.00361244j, var(E): 0.09383992
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17830/ 20000/ t/epoch=0.37............. Loss: 0.01459086, mean(E): -19.21490503+0.00743509j, var(E): 0.08109249
-0.0
tensor(15.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17840/ 20000/ t/epoch=0.37............. Loss: 0.01998120, mean(E): -19.20326468+0.00435660j, var(E): 0.12081967
-0.0
tensor(15.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17850/ 20000/ t/epoch=0.37............. Loss: -0.14375273, mean(E): -19.19532210-0.00540240j, var(E): 0.11020391
-0.0
tensor(15.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17860/ 20000/ t/epoch=0.37............. Loss: -0.04918788, mean(E): -19.18165819-0.00130839j, var(E): 0.10242358
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17870/ 20000/ t/epoch=0.37............. Loss: 0.07014000, mean(E): -19.22973487-0.00812902j, var(E): 0.08397709
-0.0
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17880/ 20000/ t/epoch=0.37............. Loss: 0.03242500, mean(E): -19.23270884+0.00180055j, var(E): 0.13817796
-0.0
tensor(15.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17890/ 20000/ t/epoch=0.37............. Loss: 0.00956562, mean(E): -19.21720371+0.00635435j, var(E): 0.04421231
-0.0
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17900/ 20000/ t/epoch=0.37............. Loss: 0.12940991, mean(E): -19.24017036-0.01212780j, var(E): 0.10194154
-0.0
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17910/ 20000/ t/epoch=0.37............. Loss: -0.07558648, mean(E): -19.21372290+0.00452629j, var(E): 0.10514303
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17920/ 20000/ t/epoch=0.37............. Loss: 0.01956282, mean(E): -19.21693902+0.00353788j, var(E): 0.11762325
-0.0
tensor(15.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17930/ 20000/ t/epoch=0.37............. Loss: -0.02832185, mean(E): -19.18972042-0.00012825j, var(E): 0.11562491
-0.0
tensor(15.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17940/ 20000/ t/epoch=0.38............. Loss: 0.12137796, mean(E): -19.21794927-0.00355009j, var(E): 0.11413874
-0.0
tensor(15.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17950/ 20000/ t/epoch=0.37............. Loss: -0.07359357, mean(E): -19.23174637+0.01544261j, var(E): 0.07643711
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17960/ 20000/ t/epoch=0.37............. Loss: 0.00445426, mean(E): -19.24705386+0.00793087j, var(E): 0.10393092
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17970/ 20000/ t/epoch=0.37............. Loss: 0.17502439, mean(E): -19.26984925-0.00270581j, var(E): 0.09115322
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17980/ 20000/ t/epoch=0.37............. Loss: -0.08970340, mean(E): -19.22505629-0.01763890j, var(E): 0.12625436
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17990/ 20000/ t/epoch=0.37............. Loss: 0.12552109, mean(E): -19.24329603-0.00102600j, var(E): 0.13537540
-0.0
tensor(15.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18000/ 20000/ t/epoch=0.37............. Loss: 0.23813313, mean(E): -19.24762970-0.00443867j, var(E): 0.12902378
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18010/ 20000/ t/epoch=0.37............. Loss: 0.34719053, mean(E): -19.22333182-0.00724040j, var(E): 0.10046962
-0.0
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18020/ 20000/ t/epoch=0.37............. Loss: 0.04285905, mean(E): -19.23233602-0.00722232j, var(E): 0.07406558
-0.0
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18030/ 20000/ t/epoch=0.37............. Loss: 0.31219264, mean(E): -19.25064817-0.00302963j, var(E): 0.12822412
-0.0
tensor(15.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18040/ 20000/ t/epoch=0.37............. Loss: -0.12303864, mean(E): -19.20068282+0.00548982j, var(E): 0.07253117
-0.0
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18050/ 20000/ t/epoch=0.37............. Loss: 0.15306828, mean(E): -19.22993075+0.00244807j, var(E): 0.13290663
-0.0
tensor(15.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18060/ 20000/ t/epoch=0.37............. Loss: 0.00983063, mean(E): -19.21000359-0.00030582j, var(E): 0.09550897
-0.0
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18070/ 20000/ t/epoch=0.37............. Loss: 0.04148549, mean(E): -19.22877236+0.00948866j, var(E): 0.08426071
-0.0
tensor(15.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18080/ 20000/ t/epoch=0.37............. Loss: 0.03687464, mean(E): -19.22494615+0.01124776j, var(E): 0.08380188
-0.0
tensor(15.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18090/ 20000/ t/epoch=0.37............. Loss: 0.10508377, mean(E): -19.22854429+0.01202684j, var(E): 0.07392810
-0.0
tensor(15.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18100/ 20000/ t/epoch=0.38............. Loss: 0.08860409, mean(E): -19.22679737-0.00010102j, var(E): 0.11600270
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18110/ 20000/ t/epoch=0.37............. Loss: 0.08063792, mean(E): -19.23528647-0.00793145j, var(E): 0.07674131
-0.0
tensor(15.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18120/ 20000/ t/epoch=0.37............. Loss: -0.00318732, mean(E): -19.21696182-0.00214245j, var(E): 0.06551720
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18130/ 20000/ t/epoch=0.37............. Loss: -0.04779273, mean(E): -19.23259610-0.00269278j, var(E): 0.12344182
-0.0
tensor(15.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18140/ 20000/ t/epoch=0.37............. Loss: 0.05065054, mean(E): -19.26826908-0.00354858j, var(E): 0.09809368
-0.0
tensor(15.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18150/ 20000/ t/epoch=0.37............. Loss: 0.08748294, mean(E): -19.25884556-0.01346155j, var(E): 0.13600366
-0.0
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18160/ 20000/ t/epoch=0.37............. Loss: -0.06555515, mean(E): -19.20939420+0.00210631j, var(E): 0.10468033
-0.0
tensor(15.0224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18170/ 20000/ t/epoch=0.37............. Loss: -0.01551757, mean(E): -19.24593013-0.00370419j, var(E): 0.08230043
-0.0
tensor(15.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18180/ 20000/ t/epoch=0.37............. Loss: -0.11477870, mean(E): -19.19876064-0.00953900j, var(E): 0.11503014
-0.0
tensor(15.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18190/ 20000/ t/epoch=0.37............. Loss: 0.23192739, mean(E): -19.24945198+0.00064552j, var(E): 0.08853611
-0.0
tensor(15.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18200/ 20000/ t/epoch=0.38............. Loss: -0.04634804, mean(E): -19.19880258+0.00365344j, var(E): 0.12306596
-0.0
tensor(15.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18210/ 20000/ t/epoch=0.37............. Loss: -0.24948142, mean(E): -19.16736621-0.00241684j, var(E): 0.18378299
-0.0
tensor(15.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18220/ 20000/ t/epoch=0.37............. Loss: 0.13521880, mean(E): -19.23339886-0.00757491j, var(E): 0.08059510
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18230/ 20000/ t/epoch=0.38............. Loss: -0.02486466, mean(E): -19.21066127-0.00115127j, var(E): 0.07654062
-0.0
tensor(15.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18240/ 20000/ t/epoch=0.37............. Loss: 0.07206959, mean(E): -19.21257814-0.00983683j, var(E): 0.10208529
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18250/ 20000/ t/epoch=0.37............. Loss: -0.21385833, mean(E): -19.17508737+0.00246959j, var(E): 0.14587847
-0.0
tensor(15.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18260/ 20000/ t/epoch=0.37............. Loss: -0.03705478, mean(E): -19.23024036-0.01479327j, var(E): 0.06049810
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18270/ 20000/ t/epoch=0.37............. Loss: -0.04155244, mean(E): -19.21262578-0.00276298j, var(E): 0.06940457
-0.0
tensor(15.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18280/ 20000/ t/epoch=0.37............. Loss: 0.01053834, mean(E): -19.22245050-0.00621517j, var(E): 0.15188173
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18290/ 20000/ t/epoch=0.38............. Loss: -0.02202279, mean(E): -19.22401925+0.01127111j, var(E): 0.13466734
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18300/ 20000/ t/epoch=0.37............. Loss: -0.13129238, mean(E): -19.18806018+0.00128739j, var(E): 0.08130010
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18310/ 20000/ t/epoch=0.37............. Loss: 0.00155615, mean(E): -19.23425341+0.00429965j, var(E): 0.07589886
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18320/ 20000/ t/epoch=0.37............. Loss: 0.02604417, mean(E): -19.23506486+0.01264765j, var(E): 0.10883238
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18330/ 20000/ t/epoch=0.37............. Loss: -0.02168974, mean(E): -19.21786215-0.00451803j, var(E): 0.07537770
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18340/ 20000/ t/epoch=0.38............. Loss: -0.00417195, mean(E): -19.22104083-0.00219960j, var(E): 0.08153125
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18350/ 20000/ t/epoch=0.37............. Loss: -0.23030029, mean(E): -19.22615364-0.00065138j, var(E): 0.09130853
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18360/ 20000/ t/epoch=0.37............. Loss: 0.10435100, mean(E): -19.23818145-0.01176074j, var(E): 0.08276908
-0.0
tensor(15.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18370/ 20000/ t/epoch=0.38............. Loss: 0.21329228, mean(E): -19.20965868+0.00546503j, var(E): 0.08616872
-0.0
tensor(15.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18380/ 20000/ t/epoch=0.37............. Loss: 0.09596774, mean(E): -19.21133972+0.00934367j, var(E): 0.12126653
-0.0
tensor(15.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18390/ 20000/ t/epoch=0.37............. Loss: -0.09473846, mean(E): -19.21398258+0.00030906j, var(E): 0.07659321
-0.0
tensor(15.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18400/ 20000/ t/epoch=0.38............. Loss: -0.11907669, mean(E): -19.22275306+0.00699712j, var(E): 0.08327386
-0.0
tensor(15.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18410/ 20000/ t/epoch=0.37............. Loss: 0.01479107, mean(E): -19.23311293+0.00405308j, var(E): 0.07904313
-0.0
tensor(15.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18420/ 20000/ t/epoch=0.37............. Loss: 0.00941913, mean(E): -19.19743506+0.00328771j, var(E): 0.11920816
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18430/ 20000/ t/epoch=0.37............. Loss: -0.06577027, mean(E): -19.23978448+0.00250934j, var(E): 0.08664743
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18440/ 20000/ t/epoch=0.37............. Loss: -0.06210583, mean(E): -19.22067768-0.00492035j, var(E): 0.07421138
-0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18450/ 20000/ t/epoch=0.37............. Loss: -0.05088627, mean(E): -19.23097648+0.00920352j, var(E): 0.11534387
-0.0
tensor(15.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18460/ 20000/ t/epoch=0.37............. Loss: 0.05711244, mean(E): -19.20514457-0.00168345j, var(E): 0.06916920
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18470/ 20000/ t/epoch=0.37............. Loss: 0.01063086, mean(E): -19.20375002+0.01206708j, var(E): 0.06450262
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18480/ 20000/ t/epoch=0.37............. Loss: -0.04953214, mean(E): -19.23045013-0.00015061j, var(E): 0.05253677
-0.0
tensor(15.0287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18490/ 20000/ t/epoch=0.37............. Loss: -0.06520374, mean(E): -19.20000935+0.00705831j, var(E): 0.05965420
-0.0
tensor(15.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18500/ 20000/ t/epoch=0.37............. Loss: -0.08551089, mean(E): -19.20370732-0.00652890j, var(E): 0.06711292
-0.0
tensor(15.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18510/ 20000/ t/epoch=0.37............. Loss: -0.08618578, mean(E): -19.17733209+0.00262175j, var(E): 0.09676344
-0.0
tensor(15.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18520/ 20000/ t/epoch=0.37............. Loss: -0.00655630, mean(E): -19.22685697+0.00627042j, var(E): 0.05719823
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18530/ 20000/ t/epoch=0.37............. Loss: 0.09474913, mean(E): -19.23090308+0.00132338j, var(E): 0.06213616
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18540/ 20000/ t/epoch=0.37............. Loss: -0.07568554, mean(E): -19.19470536-0.00420057j, var(E): 0.06014168
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18550/ 20000/ t/epoch=0.37............. Loss: 0.02886467, mean(E): -19.22692378-0.00618417j, var(E): 0.07613432
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18560/ 20000/ t/epoch=0.37............. Loss: -0.22709793, mean(E): -19.19765091-0.00861784j, var(E): 0.07218519
-0.0
tensor(15.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18570/ 20000/ t/epoch=0.38............. Loss: -0.08751664, mean(E): -19.21502713-0.00276559j, var(E): 0.07366148
-0.0
tensor(15.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18580/ 20000/ t/epoch=0.37............. Loss: 0.07665317, mean(E): -19.24527476-0.00296534j, var(E): 0.16682070
-0.0
tensor(15.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18590/ 20000/ t/epoch=0.37............. Loss: 0.15999452, mean(E): -19.25859303+0.01032071j, var(E): 0.10239017
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18600/ 20000/ t/epoch=0.37............. Loss: -0.02231242, mean(E): -19.21877207+0.00077720j, var(E): 0.06978885
-0.0
tensor(15.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18610/ 20000/ t/epoch=0.37............. Loss: 0.02828684, mean(E): -19.22176444+0.00428400j, var(E): 0.10954617
-0.0
tensor(15.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18620/ 20000/ t/epoch=0.37............. Loss: 0.18143279, mean(E): -19.26583935+0.01661874j, var(E): 0.12119944
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18630/ 20000/ t/epoch=0.37............. Loss: -0.05807549, mean(E): -19.23296250-0.00984244j, var(E): 0.07243751
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18640/ 20000/ t/epoch=0.37............. Loss: 0.11160157, mean(E): -19.23795938+0.00832837j, var(E): 0.07865480
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18650/ 20000/ t/epoch=0.37............. Loss: -0.25363478, mean(E): -19.17336086+0.01058673j, var(E): 0.11055141
-0.0
tensor(15.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18660/ 20000/ t/epoch=0.37............. Loss: -0.09962840, mean(E): -19.23060022+0.00521197j, var(E): 0.09906575
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18670/ 20000/ t/epoch=0.37............. Loss: 0.11311350, mean(E): -19.19258182-0.00819156j, var(E): 0.06901971
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18680/ 20000/ t/epoch=0.37............. Loss: 0.01504823, mean(E): -19.22184640-0.00312138j, var(E): 0.04898476
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18690/ 20000/ t/epoch=0.37............. Loss: -0.15764052, mean(E): -19.21445165-0.00034340j, var(E): 0.06159878
-0.0
tensor(15.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18700/ 20000/ t/epoch=0.37............. Loss: -0.08572981, mean(E): -19.22303442+0.00054991j, var(E): 0.08077136
-0.0
tensor(15.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18710/ 20000/ t/epoch=0.37............. Loss: -0.13377385, mean(E): -19.22911181-0.00290876j, var(E): 0.11783294
-0.0
tensor(15.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18720/ 20000/ t/epoch=0.37............. Loss: 0.18219710, mean(E): -19.21567016+0.00446183j, var(E): 0.08595497
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18730/ 20000/ t/epoch=0.37............. Loss: -0.01633111, mean(E): -19.19594309+0.00797993j, var(E): 0.08889943
-0.0
tensor(15.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18740/ 20000/ t/epoch=0.37............. Loss: -0.00265261, mean(E): -19.21401727-0.00152114j, var(E): 0.08640525
-0.0
tensor(15.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18750/ 20000/ t/epoch=0.37............. Loss: 0.07767749, mean(E): -19.24356307+0.00390947j, var(E): 0.08797377
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18760/ 20000/ t/epoch=0.37............. Loss: -0.01655382, mean(E): -19.23312455+0.00515226j, var(E): 0.09200129
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18770/ 20000/ t/epoch=0.37............. Loss: 0.23876071, mean(E): -19.25391316-0.00285275j, var(E): 0.08002086
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18780/ 20000/ t/epoch=0.37............. Loss: -0.01676498, mean(E): -19.20624147+0.00801473j, var(E): 0.15203523
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18790/ 20000/ t/epoch=0.37............. Loss: -0.04860072, mean(E): -19.23269913+0.00891514j, var(E): 0.09910211
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18800/ 20000/ t/epoch=0.37............. Loss: -0.01360071, mean(E): -19.22001285+0.01212036j, var(E): 0.18485410
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18810/ 20000/ t/epoch=0.37............. Loss: 0.00459922, mean(E): -19.23843768+0.00070250j, var(E): 0.08994770
-0.0
tensor(15.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18820/ 20000/ t/epoch=0.37............. Loss: 0.02205298, mean(E): -19.23743084+0.00736576j, var(E): 0.09295716
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18830/ 20000/ t/epoch=0.37............. Loss: 0.02399160, mean(E): -19.20183410-0.00392600j, var(E): 0.06554685
-0.0
tensor(15.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18840/ 20000/ t/epoch=0.37............. Loss: 0.13449890, mean(E): -19.23485289+0.01533223j, var(E): 0.16664242
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18850/ 20000/ t/epoch=0.37............. Loss: -0.09785424, mean(E): -19.21264658+0.01564774j, var(E): 0.12881336
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18860/ 20000/ t/epoch=0.37............. Loss: 0.09426791, mean(E): -19.22897030-0.00328162j, var(E): 0.03935312
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18870/ 20000/ t/epoch=0.37............. Loss: -0.01588142, mean(E): -19.20964857+0.01585323j, var(E): 0.05559912
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18880/ 20000/ t/epoch=0.37............. Loss: -0.09312543, mean(E): -19.22175540+0.00072675j, var(E): 0.11350955
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18890/ 20000/ t/epoch=0.37............. Loss: 0.14387542, mean(E): -19.21507159+0.00775518j, var(E): 0.08469343
-0.0
tensor(15.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18900/ 20000/ t/epoch=0.37............. Loss: -0.29790116, mean(E): -19.20255206+0.00736094j, var(E): 0.09968652
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18910/ 20000/ t/epoch=0.37............. Loss: 0.00116444, mean(E): -19.20182466-0.00799391j, var(E): 0.08193531
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18920/ 20000/ t/epoch=0.37............. Loss: 0.07828135, mean(E): -19.22831077+0.00598636j, var(E): 0.11693766
-0.0
tensor(15.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18930/ 20000/ t/epoch=0.37............. Loss: -0.09536679, mean(E): -19.22806036-0.00941984j, var(E): 0.04357159
-0.0
tensor(15.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18940/ 20000/ t/epoch=0.38............. Loss: -0.00683964, mean(E): -19.21247733-0.00316764j, var(E): 0.08853077
-0.0
tensor(15.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18950/ 20000/ t/epoch=0.38............. Loss: -0.02552797, mean(E): -19.21357130-0.00811967j, var(E): 0.08497018
-0.0
tensor(15.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18960/ 20000/ t/epoch=0.38............. Loss: 0.16338552, mean(E): -19.23401650-0.00375867j, var(E): 0.09541686
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18970/ 20000/ t/epoch=0.37............. Loss: -0.29861735, mean(E): -19.20449006-0.00675362j, var(E): 0.07409243
-0.0
tensor(15.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18980/ 20000/ t/epoch=0.37............. Loss: 0.03320529, mean(E): -19.22887819+0.00975616j, var(E): 0.08061299
-0.0
tensor(15.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18990/ 20000/ t/epoch=0.37............. Loss: 0.01095330, mean(E): -19.19845941+0.00248651j, var(E): 0.08682061
-0.0
tensor(15.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19000/ 20000/ t/epoch=0.37............. Loss: -0.19494596, mean(E): -19.18541870+0.01097830j, var(E): 0.11369734
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19010/ 20000/ t/epoch=0.37............. Loss: 0.15006140, mean(E): -19.22952885-0.00546764j, var(E): 0.13490037
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19020/ 20000/ t/epoch=0.37............. Loss: -0.10369122, mean(E): -19.21689412-0.00531211j, var(E): 0.08564202
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19030/ 20000/ t/epoch=0.37............. Loss: -0.00724891, mean(E): -19.21612199-0.00202177j, var(E): 0.08486853
-0.0
tensor(15.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19040/ 20000/ t/epoch=0.37............. Loss: 0.08831163, mean(E): -19.23814561+0.00806396j, var(E): 0.09621985
-0.0
tensor(15.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19050/ 20000/ t/epoch=0.37............. Loss: -0.03410225, mean(E): -19.21790699+0.00669315j, var(E): 0.10925021
-0.0
tensor(15.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19060/ 20000/ t/epoch=0.37............. Loss: 0.03013901, mean(E): -19.23691299-0.00469728j, var(E): 0.07555055
-0.0
tensor(15.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19070/ 20000/ t/epoch=0.37............. Loss: -0.07860232, mean(E): -19.22142367-0.01768109j, var(E): 0.08644384
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19080/ 20000/ t/epoch=0.37............. Loss: -0.03867402, mean(E): -19.19512027+0.00288681j, var(E): 0.06306080
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19090/ 20000/ t/epoch=0.37............. Loss: -0.08395129, mean(E): -19.23233735-0.00964248j, var(E): 0.09406943
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19100/ 20000/ t/epoch=0.37............. Loss: 0.00012917, mean(E): -19.22451662-0.00639555j, var(E): 0.09408266
-0.0
tensor(15.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19110/ 20000/ t/epoch=0.37............. Loss: 0.13454370, mean(E): -19.24064822+0.00268164j, var(E): 0.10214779
-0.0
tensor(15.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19120/ 20000/ t/epoch=0.37............. Loss: -0.07726061, mean(E): -19.20165111-0.01261465j, var(E): 0.07508418
-0.0
tensor(15.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19130/ 20000/ t/epoch=0.37............. Loss: -0.04761819, mean(E): -19.19973441-0.01556985j, var(E): 0.07909615
-0.0
tensor(15.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19140/ 20000/ t/epoch=0.37............. Loss: -0.14667464, mean(E): -19.18236839-0.00408667j, var(E): 0.08887617
-0.0
tensor(15.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19150/ 20000/ t/epoch=0.37............. Loss: -0.12841468, mean(E): -19.21878189-0.00120801j, var(E): 0.07477615
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19160/ 20000/ t/epoch=0.37............. Loss: -0.29572627, mean(E): -19.18028531-0.00879005j, var(E): 0.08543211
-0.0
tensor(15.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19170/ 20000/ t/epoch=0.37............. Loss: 0.05238013, mean(E): -19.22801257+0.00236610j, var(E): 0.08326369
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19180/ 20000/ t/epoch=0.37............. Loss: -0.02102164, mean(E): -19.21744382+0.01097005j, var(E): 0.07614459
-0.0
tensor(15.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19190/ 20000/ t/epoch=0.37............. Loss: 0.01095423, mean(E): -19.20774380-0.00079958j, var(E): 0.07208835
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19200/ 20000/ t/epoch=0.37............. Loss: -0.07882360, mean(E): -19.20262467-0.00157129j, var(E): 0.05481888
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19210/ 20000/ t/epoch=0.37............. Loss: -0.00948910, mean(E): -19.22573126+0.00750030j, var(E): 0.08996001
-0.0
tensor(15.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19220/ 20000/ t/epoch=0.37............. Loss: 0.04404566, mean(E): -19.22915836-0.01039249j, var(E): 0.06237065
-0.0
tensor(15.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19230/ 20000/ t/epoch=0.37............. Loss: -0.19612657, mean(E): -19.21480470+0.01232693j, var(E): 0.07859032
-0.0
tensor(15.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19240/ 20000/ t/epoch=0.37............. Loss: 0.04278248, mean(E): -19.25640872-0.01142834j, var(E): 0.10228058
-0.0
tensor(15.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19250/ 20000/ t/epoch=0.37............. Loss: 0.05274058, mean(E): -19.22626203+0.00703526j, var(E): 0.07952400
-0.0
tensor(15.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19260/ 20000/ t/epoch=0.37............. Loss: -0.03369714, mean(E): -19.22465328-0.00281173j, var(E): 0.11753129
-0.0
tensor(15.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19270/ 20000/ t/epoch=0.37............. Loss: -0.13258352, mean(E): -19.21411439+0.00136405j, var(E): 0.09510703
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19280/ 20000/ t/epoch=0.38............. Loss: -0.07469627, mean(E): -19.20899961-0.00259048j, var(E): 0.09868204
-0.0
tensor(15.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19290/ 20000/ t/epoch=0.37............. Loss: 0.01939928, mean(E): -19.22643301+0.00005579j, var(E): 0.07572296
-0.0
tensor(15.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19300/ 20000/ t/epoch=0.37............. Loss: -0.12700758, mean(E): -19.18203391-0.00669049j, var(E): 0.06888520
-0.0
tensor(15.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19310/ 20000/ t/epoch=0.37............. Loss: -0.21495072, mean(E): -19.17574018+0.01265574j, var(E): 0.06679420
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19320/ 20000/ t/epoch=0.37............. Loss: -0.20100078, mean(E): -19.19384429-0.01560255j, var(E): 0.15386924
-0.0
tensor(15.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19330/ 20000/ t/epoch=0.37............. Loss: 0.02205564, mean(E): -19.21659369+0.00031609j, var(E): 0.05469960
-0.0
tensor(15.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19340/ 20000/ t/epoch=0.37............. Loss: 0.01767519, mean(E): -19.20125639+0.00025883j, var(E): 0.07326295
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19350/ 20000/ t/epoch=0.37............. Loss: 0.16137359, mean(E): -19.20863150+0.00289294j, var(E): 0.07659927
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19360/ 20000/ t/epoch=0.37............. Loss: -0.02771832, mean(E): -19.22769135+0.00820152j, var(E): 0.08732597
-0.0
tensor(15.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19370/ 20000/ t/epoch=0.37............. Loss: 0.12141625, mean(E): -19.21574590+0.00491792j, var(E): 0.08219183
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19380/ 20000/ t/epoch=0.37............. Loss: -0.09241630, mean(E): -19.21917297-0.00083752j, var(E): 0.09270475
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19390/ 20000/ t/epoch=0.38............. Loss: 0.06036429, mean(E): -19.22576335-0.00197061j, var(E): 0.05748675
-0.0
tensor(15.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19400/ 20000/ t/epoch=0.37............. Loss: 0.06280716, mean(E): -19.21283975-0.01172355j, var(E): 0.09177935
-0.0
tensor(15.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19410/ 20000/ t/epoch=0.37............. Loss: -0.07851397, mean(E): -19.19192853-0.00658892j, var(E): 0.10671566
-0.0
tensor(15.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19420/ 20000/ t/epoch=0.37............. Loss: -0.19592384, mean(E): -19.19177180-0.00210658j, var(E): 0.05436886
-0.0
tensor(15.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19430/ 20000/ t/epoch=0.37............. Loss: -0.02466989, mean(E): -19.18448008+0.00227275j, var(E): 0.10924859
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19440/ 20000/ t/epoch=0.37............. Loss: 0.08696100, mean(E): -19.21344001+0.01365085j, var(E): 0.05577805
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19450/ 20000/ t/epoch=0.37............. Loss: 0.14125816, mean(E): -19.18906416-0.01758053j, var(E): 0.10217925
-0.0
tensor(15.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19460/ 20000/ t/epoch=0.37............. Loss: 0.05257784, mean(E): -19.20918412+0.00016605j, var(E): 0.08629022
-0.0
tensor(15.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19470/ 20000/ t/epoch=0.37............. Loss: -0.02569512, mean(E): -19.22763745+0.00601478j, var(E): 0.07568486
-0.0
tensor(15.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19480/ 20000/ t/epoch=0.37............. Loss: -0.04159237, mean(E): -19.23368128+0.00368696j, var(E): 0.09240943
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19490/ 20000/ t/epoch=0.37............. Loss: -0.02545432, mean(E): -19.21969998+0.01568326j, var(E): 0.09025464
-0.0
tensor(15.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19500/ 20000/ t/epoch=0.37............. Loss: 0.06713412, mean(E): -19.21359425+0.00282896j, var(E): 0.09571609
-0.0
tensor(15.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19510/ 20000/ t/epoch=0.37............. Loss: -0.23471890, mean(E): -19.20120564-0.00232786j, var(E): 0.06931129
-0.0
tensor(15.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19520/ 20000/ t/epoch=0.37............. Loss: -0.02218898, mean(E): -19.19325435+0.00010324j, var(E): 0.09189340
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19530/ 20000/ t/epoch=0.38............. Loss: 0.15549985, mean(E): -19.26526021+0.00375841j, var(E): 0.15798241
-0.0
tensor(15.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19540/ 20000/ t/epoch=0.37............. Loss: 0.09150000, mean(E): -19.21811827-0.00090779j, var(E): 0.08040769
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19550/ 20000/ t/epoch=0.37............. Loss: -0.13436831, mean(E): -19.24104948+0.00648082j, var(E): 0.05625738
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19560/ 20000/ t/epoch=0.37............. Loss: 0.00595014, mean(E): -19.18861675-0.00828547j, var(E): 0.08299625
-0.0
tensor(15.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19570/ 20000/ t/epoch=0.37............. Loss: -0.03185094, mean(E): -19.19541519-0.01130558j, var(E): 0.09244348
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19580/ 20000/ t/epoch=0.37............. Loss: -0.05564666, mean(E): -19.21258727-0.01767485j, var(E): 0.06063266
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19590/ 20000/ t/epoch=0.37............. Loss: -0.08258118, mean(E): -19.21803200-0.00777128j, var(E): 0.09819468
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19600/ 20000/ t/epoch=0.37............. Loss: -0.06184681, mean(E): -19.19093047+0.00717181j, var(E): 0.07777728
-0.0
tensor(15.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19610/ 20000/ t/epoch=0.37............. Loss: 0.13995508, mean(E): -19.20122743+0.00135759j, var(E): 0.08144539
-0.0
tensor(15.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19620/ 20000/ t/epoch=0.37............. Loss: 0.00036858, mean(E): -19.23314986-0.00437278j, var(E): 0.11128787
-0.0
tensor(15.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19630/ 20000/ t/epoch=0.37............. Loss: 0.23583238, mean(E): -19.26534860+0.00428572j, var(E): 0.10007855
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19640/ 20000/ t/epoch=0.37............. Loss: 0.05614003, mean(E): -19.23123533-0.01243400j, var(E): 0.10260224
-0.0
tensor(15.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19650/ 20000/ t/epoch=0.37............. Loss: 0.03079740, mean(E): -19.22118773+0.00035702j, var(E): 0.06371919
-0.0
tensor(15.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19660/ 20000/ t/epoch=0.37............. Loss: -0.05808642, mean(E): -19.19860725+0.00390038j, var(E): 0.08548015
-0.0
tensor(15.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19670/ 20000/ t/epoch=0.37............. Loss: 0.03670959, mean(E): -19.21615398-0.00376241j, var(E): 0.11857680
-0.0
tensor(15.0596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19680/ 20000/ t/epoch=0.37............. Loss: 0.06195103, mean(E): -19.22432631-0.01579341j, var(E): 0.08618744
-0.0
tensor(15.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19690/ 20000/ t/epoch=0.37............. Loss: -0.04154714, mean(E): -19.24857113-0.01437484j, var(E): 0.11377502
-0.0
tensor(15.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19700/ 20000/ t/epoch=0.37............. Loss: 0.01050879, mean(E): -19.22924796-0.01004553j, var(E): 0.09403698
-0.0
tensor(15.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19710/ 20000/ t/epoch=0.37............. Loss: 0.17756434, mean(E): -19.24244428-0.00823957j, var(E): 0.11188469
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19720/ 20000/ t/epoch=0.37............. Loss: 0.14092275, mean(E): -19.24934804-0.00486302j, var(E): 0.08486901
-0.0
tensor(15.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19730/ 20000/ t/epoch=0.37............. Loss: 0.06280136, mean(E): -19.22400205+0.00090357j, var(E): 0.13947399
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19740/ 20000/ t/epoch=0.38............. Loss: 0.09646028, mean(E): -19.21895115+0.00236001j, var(E): 0.08005824
-0.0
tensor(15.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19750/ 20000/ t/epoch=0.37............. Loss: -0.10966911, mean(E): -19.22700235+0.00261847j, var(E): 0.06399661
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19760/ 20000/ t/epoch=0.37............. Loss: -0.03755912, mean(E): -19.22881506+0.00594418j, var(E): 0.09449679
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19770/ 20000/ t/epoch=0.37............. Loss: 0.08377877, mean(E): -19.23265028-0.00057077j, var(E): 0.10208504
-0.0
tensor(15.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19780/ 20000/ t/epoch=0.37............. Loss: 0.08257790, mean(E): -19.23143968+0.00850660j, var(E): 0.07072593
-0.0
tensor(15.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19790/ 20000/ t/epoch=0.37............. Loss: -0.00537997, mean(E): -19.19570045-0.00502374j, var(E): 0.06433038
-0.0
tensor(15.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19800/ 20000/ t/epoch=0.37............. Loss: -0.13683726, mean(E): -19.21248662+0.00216407j, var(E): 0.06404303
-0.0
tensor(15.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19810/ 20000/ t/epoch=0.37............. Loss: 0.19282388, mean(E): -19.21915240+0.00205656j, var(E): 0.14062883
-0.0
tensor(15.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19820/ 20000/ t/epoch=0.37............. Loss: 0.19908875, mean(E): -19.24880242-0.02563475j, var(E): 0.11107279
-0.0
tensor(15.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19830/ 20000/ t/epoch=0.37............. Loss: 0.01699244, mean(E): -19.21891214-0.00745098j, var(E): 0.08807883
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19840/ 20000/ t/epoch=0.37............. Loss: 0.17364033, mean(E): -19.23347211+0.00150157j, var(E): 0.12677986
-0.0
tensor(15.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19850/ 20000/ t/epoch=0.37............. Loss: -0.04578628, mean(E): -19.22320865-0.00535197j, var(E): 0.07679382
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19860/ 20000/ t/epoch=0.38............. Loss: 0.00194490, mean(E): -19.22198743-0.00101262j, var(E): 0.13170767
-0.0
tensor(15.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19870/ 20000/ t/epoch=0.37............. Loss: -0.20675136, mean(E): -19.18493868-0.00367533j, var(E): 0.09728200
-0.0
tensor(15.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19880/ 20000/ t/epoch=0.37............. Loss: -0.10779546, mean(E): -19.19915286-0.00864651j, var(E): 0.07600448
-0.0
tensor(15.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19890/ 20000/ t/epoch=0.37............. Loss: -0.09305287, mean(E): -19.20298475+0.00529670j, var(E): 0.07406113
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19900/ 20000/ t/epoch=0.37............. Loss: -0.03808444, mean(E): -19.22393756+0.01197801j, var(E): 0.12053466
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19910/ 20000/ t/epoch=0.37............. Loss: 0.02900730, mean(E): -19.23988390+0.00027291j, var(E): 0.08959442
-0.0
tensor(15.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19920/ 20000/ t/epoch=0.37............. Loss: -0.09155704, mean(E): -19.20399743+0.00281569j, var(E): 0.06065316
-0.0
tensor(15.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19930/ 20000/ t/epoch=0.37............. Loss: -0.03220768, mean(E): -19.20615178+0.00512852j, var(E): 0.06149739
-0.0
tensor(15.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19940/ 20000/ t/epoch=0.37............. Loss: -0.19504350, mean(E): -19.18958241+0.00058555j, var(E): 0.09545588
-0.0
tensor(15.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19950/ 20000/ t/epoch=0.37............. Loss: -0.03348989, mean(E): -19.20011366+0.01366438j, var(E): 0.07157362
-0.0
tensor(15.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19960/ 20000/ t/epoch=0.37............. Loss: -0.04648333, mean(E): -19.21879761+0.00136539j, var(E): 0.11215334
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19970/ 20000/ t/epoch=0.37............. Loss: 0.16077814, mean(E): -19.21925437-0.00556522j, var(E): 0.09598669
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19980/ 20000/ t/epoch=0.37............. Loss: -0.06630463, mean(E): -19.20158662+0.00538980j, var(E): 0.09805293
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19990/ 20000/ t/epoch=0.37............. Loss: 0.10457227, mean(E): -19.23855530+0.00628926j, var(E): 0.06519371
-0.0
tensor(15.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20000/ 20000/ t/epoch=0.37............. Loss: 0.06197333, mean(E): -19.21527124-0.00406468j, var(E): 0.09318848
