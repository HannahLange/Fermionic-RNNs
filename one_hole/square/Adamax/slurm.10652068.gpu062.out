1.13.1+cu117
GPU is available
Namespace(Jp=1.0, Jz=1.0, U=1.0, t=3.0, density=1.0, Nx=4, Ny=4, bounds=1, boundsx=0, boundsy=0, load_model=0, sym=0.0, antisym=0.0, hd=100)
4x4_qubits/periodic/Jp=1.0Jz=1.0t=0.0den=1.00/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 120000
rnn.b1: 100
rnn.W2: 120000
rnn.b2: 100
rnn.Wmerge: 20000
lin1.weight: 300
lin1.bias: 3
lin2.weight: 300
lin2.bias: 3
Total number of parameters in the network: 260806
0.0
tensor(12.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 20000/ t/epoch=3.49............. Loss: -1.54746905, mean(E): -0.66403234+0.00113113j, var(E): 1.90720141
0.0
tensor(12.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 20000/ t/epoch=1.02............. Loss: -1.46231865, mean(E): -0.75573894+0.01482324j, var(E): 2.03474449
0.0
tensor(12.7070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 20000/ t/epoch=1.02............. Loss: -4.73148595, mean(E): -3.67982713-0.28467294j, var(E): 5.67132212
0.0
tensor(12.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 20000/ t/epoch=1.01............. Loss: -1.25155163, mean(E): -7.18107645-0.12125301j, var(E): 4.50797961
0.0
tensor(13.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 20000/ t/epoch=1.01............. Loss: 6.01635492, mean(E): -8.31882923-0.20570449j, var(E): 9.33926713
0.0
tensor(13.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 20000/ t/epoch=1.02............. Loss: -1.12016347, mean(E): -9.05821918-0.05365024j, var(E): 6.42969038
0.0
tensor(13.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 20000/ t/epoch=1.02............. Loss: 2.69916001, mean(E): -9.73988093+0.11109234j, var(E): 6.88548352
0.0
tensor(13.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 20000/ t/epoch=1.02............. Loss: -1.83498207, mean(E): -10.36956623+0.15487954j, var(E): 6.54042127
0.0
tensor(13.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 20000/ t/epoch=1.02............. Loss: 3.37518723, mean(E): -11.12473682-0.17833387j, var(E): 8.08200233
0.0
tensor(13.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 20000/ t/epoch=1.02............. Loss: -1.96716786, mean(E): -12.66436192+0.04556851j, var(E): 10.64549256
0.0
tensor(13.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 20000/ t/epoch=1.03............. Loss: -2.24139074, mean(E): -13.54039713-0.12940546j, var(E): 12.59419868
0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 20000/ t/epoch=1.03............. Loss: 9.47800012, mean(E): -14.47946309+0.19013424j, var(E): 12.88183172
0.0
tensor(13.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 20000/ t/epoch=1.03............. Loss: 5.21482350, mean(E): -15.18349995+0.11011826j, var(E): 12.31238250
0.0
tensor(13.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 20000/ t/epoch=1.04............. Loss: 0.49821446, mean(E): -16.32389899-0.06844470j, var(E): 10.85108952
0.0
tensor(13.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 20000/ t/epoch=1.03............. Loss: -9.89177313, mean(E): -16.30796100-0.01499634j, var(E): 11.00977966
0.0
tensor(13.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 20000/ t/epoch=1.03............. Loss: -5.94867377, mean(E): -16.34038802+0.04195735j, var(E): 8.86790765
0.0
tensor(13.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 20000/ t/epoch=1.03............. Loss: -6.32973570, mean(E): -16.83335162-0.01386671j, var(E): 10.39555789
0.0
tensor(13.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 20000/ t/epoch=1.04............. Loss: 1.58188793, mean(E): -16.80002538+0.02861206j, var(E): 7.80471170
0.0
tensor(13.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 20000/ t/epoch=1.03............. Loss: 0.67467932, mean(E): -16.86675549+0.00808946j, var(E): 7.14545234
0.0
tensor(13.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 20000/ t/epoch=1.03............. Loss: -1.64616707, mean(E): -17.16940713-0.03257491j, var(E): 6.10777742
0.0
tensor(14.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 20000/ t/epoch=1.03............. Loss: 4.21707585, mean(E): -17.39446070+0.08542820j, var(E): 5.90086550
0.0
tensor(14.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 20000/ t/epoch=1.03............. Loss: -0.40623459, mean(E): -17.29831964+0.01650563j, var(E): 5.45730367
0.0
tensor(14.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 20000/ t/epoch=1.03............. Loss: -3.07904392, mean(E): -17.41560680+0.03288358j, var(E): 6.46126841
0.0
tensor(14.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 20000/ t/epoch=1.03............. Loss: 2.26096311, mean(E): -17.55514987-0.09080894j, var(E): 4.85544586
0.0
tensor(14.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 20000/ t/epoch=1.03............. Loss: 1.47684457, mean(E): -17.76496963-0.10724968j, var(E): 4.34040972
0.0
tensor(14.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 20000/ t/epoch=1.03............. Loss: -0.84973101, mean(E): -17.82371180-0.00869632j, var(E): 3.58729862
0.0
tensor(14.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 20000/ t/epoch=1.04............. Loss: -0.68556909, mean(E): -18.13600463+0.02560740j, var(E): 2.93456442
0.0
tensor(14.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 20000/ t/epoch=1.04............. Loss: -0.34890376, mean(E): -17.93064405+0.00546994j, var(E): 3.75730116
0.0
tensor(14.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 20000/ t/epoch=1.04............. Loss: -3.13598742, mean(E): -18.18251623+0.04447063j, var(E): 2.99347044
0.0
tensor(14.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 20000/ t/epoch=1.04............. Loss: -1.14247963, mean(E): -18.35242653+0.05047231j, var(E): 2.79654035
0.0
tensor(14.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 20000/ t/epoch=1.03............. Loss: -1.80865933, mean(E): -18.31880507+0.01300627j, var(E): 3.28997988
0.0
tensor(14.3434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 20000/ t/epoch=1.04............. Loss: -0.01885847, mean(E): -18.50323660-0.06236826j, var(E): 2.44801886
0.0
tensor(14.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 20000/ t/epoch=1.03............. Loss: 0.28011984, mean(E): -18.31723218-0.07101418j, var(E): 2.74651421
0.0
tensor(14.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 20000/ t/epoch=1.03............. Loss: 0.79453724, mean(E): -18.34062011-0.04219963j, var(E): 2.47942635
0.0
tensor(14.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 20000/ t/epoch=1.03............. Loss: -0.92909766, mean(E): -18.47601983+0.03746967j, var(E): 2.42141002
0.0
tensor(14.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 20000/ t/epoch=1.04............. Loss: -2.66493644, mean(E): -18.55223693-0.01072805j, var(E): 2.66076219
0.0
tensor(14.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 20000/ t/epoch=1.03............. Loss: 0.27316497, mean(E): -18.42734312-0.01573406j, var(E): 2.24674165
0.0
tensor(14.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 20000/ t/epoch=1.04............. Loss: 0.46362601, mean(E): -18.50076887+0.03240860j, var(E): 2.36841131
0.0
tensor(14.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 20000/ t/epoch=1.04............. Loss: -1.61621672, mean(E): -18.33733204-0.01120389j, var(E): 2.00547991
0.0
tensor(14.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 20000/ t/epoch=1.04............. Loss: 1.19512699, mean(E): -18.55651208+0.00393524j, var(E): 2.02929033
0.0
tensor(14.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 20000/ t/epoch=1.03............. Loss: -0.85489223, mean(E): -18.53850859-0.02316122j, var(E): 1.90621087
0.0
tensor(14.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 20000/ t/epoch=1.04............. Loss: -2.10123048, mean(E): -18.51311977+0.01508910j, var(E): 1.95642361
0.0
tensor(14.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 20000/ t/epoch=1.03............. Loss: 0.30632320, mean(E): -18.59562296+0.00327433j, var(E): 2.14091142
0.0
tensor(14.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 20000/ t/epoch=1.04............. Loss: -0.38425078, mean(E): -18.59833678-0.03855092j, var(E): 2.06287931
0.0
tensor(14.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 20000/ t/epoch=1.03............. Loss: -1.51055778, mean(E): -18.49351505+0.03062179j, var(E): 1.89562058
0.0
tensor(14.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 20000/ t/epoch=1.03............. Loss: -2.37454103, mean(E): -18.68459365-0.02739951j, var(E): 2.06875797
0.0
tensor(14.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 20000/ t/epoch=1.03............. Loss: -0.62349544, mean(E): -18.72511313-0.00175662j, var(E): 1.70486517
0.0
tensor(14.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 20000/ t/epoch=1.03............. Loss: 0.48565419, mean(E): -18.70608525-0.01750537j, var(E): 1.80696599
0.0
tensor(14.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 20000/ t/epoch=1.04............. Loss: -0.09350141, mean(E): -18.60000907+0.04476129j, var(E): 2.08828735
0.0
tensor(14.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 20000/ t/epoch=1.04............. Loss: 1.13516494, mean(E): -18.82372541-0.00286930j, var(E): 1.99305281
0.0
tensor(14.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 20000/ t/epoch=1.04............. Loss: -0.80872777, mean(E): -18.70030751-0.01536225j, var(E): 1.54892912
0.0
tensor(14.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 20000/ t/epoch=1.03............. Loss: -1.50449739, mean(E): -18.62319100-0.02319356j, var(E): 1.89507397
0.0
tensor(14.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 20000/ t/epoch=1.04............. Loss: 0.42847792, mean(E): -18.60229892+0.01342870j, var(E): 1.74506114
0.0
tensor(14.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 20000/ t/epoch=1.03............. Loss: 0.55435303, mean(E): -18.79530916-0.01047690j, var(E): 1.61647725
0.0
tensor(14.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 20000/ t/epoch=1.03............. Loss: -1.38729211, mean(E): -18.68228821+0.01496351j, var(E): 1.56028015
0.0
tensor(14.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 20000/ t/epoch=1.03............. Loss: 0.23660188, mean(E): -18.69028013-0.06074135j, var(E): 1.49298277
0.0
tensor(14.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 20000/ t/epoch=1.04............. Loss: -1.96148695, mean(E): -18.77428788-0.00589927j, var(E): 1.58880438
0.0
tensor(14.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 20000/ t/epoch=1.03............. Loss: -0.07094710, mean(E): -18.74596676+0.01720959j, var(E): 1.56913549
0.0
tensor(14.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 20000/ t/epoch=1.04............. Loss: 1.10853389, mean(E): -18.54370008-0.00729806j, var(E): 1.23983144
0.0
tensor(14.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 20000/ t/epoch=1.04............. Loss: -2.26481396, mean(E): -18.67047173-0.05009335j, var(E): 1.35584733
0.0
tensor(14.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 20000/ t/epoch=1.03............. Loss: -0.76849887, mean(E): -18.81659084-0.01908800j, var(E): 1.40570567
0.0
tensor(14.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 20000/ t/epoch=1.04............. Loss: 0.68487932, mean(E): -18.82758508+0.01552222j, var(E): 1.50661967
0.0
tensor(14.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 20000/ t/epoch=1.03............. Loss: -0.08154974, mean(E): -18.79063823+0.00352307j, var(E): 1.75202031
0.0
tensor(14.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 20000/ t/epoch=1.03............. Loss: 0.24871318, mean(E): -18.74021033-0.00497908j, var(E): 1.68235682
0.0
tensor(14.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 20000/ t/epoch=1.04............. Loss: -0.75300022, mean(E): -18.71817299-0.00564573j, var(E): 1.46123335
0.0
tensor(14.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 20000/ t/epoch=1.03............. Loss: 0.71722793, mean(E): -18.90367624+0.01778429j, var(E): 1.50850866
0.0
tensor(14.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 20000/ t/epoch=1.04............. Loss: 0.37864266, mean(E): -18.78147082+0.00048176j, var(E): 1.38256826
0.0
tensor(14.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 20000/ t/epoch=1.04............. Loss: -1.85887784, mean(E): -18.88216772+0.00945657j, var(E): 1.54465011
0.0
tensor(14.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 20000/ t/epoch=1.04............. Loss: -1.02911193, mean(E): -18.70156684+0.01360389j, var(E): 1.41877562
0.0
tensor(14.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 20000/ t/epoch=1.03............. Loss: -2.00941215, mean(E): -18.75248024-0.01270344j, var(E): 1.40231131
0.0
tensor(14.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 20000/ t/epoch=1.03............. Loss: 0.87950039, mean(E): -18.73360468-0.03450351j, var(E): 1.33534090
0.0
tensor(14.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 20000/ t/epoch=1.03............. Loss: 0.42251202, mean(E): -18.79942006+0.00063373j, var(E): 1.37323130
0.0
tensor(14.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 20000/ t/epoch=1.03............. Loss: 0.32763780, mean(E): -18.81799823+0.01314650j, var(E): 1.44475374
0.0
tensor(14.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 20000/ t/epoch=1.04............. Loss: 0.50545538, mean(E): -18.83843110+0.02839132j, var(E): 1.52762664
0.0
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 20000/ t/epoch=1.04............. Loss: -0.97950218, mean(E): -18.68972397-0.02349957j, var(E): 1.24428796
0.0
tensor(14.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 20000/ t/epoch=1.04............. Loss: 0.90691931, mean(E): -18.83280054-0.01828810j, var(E): 1.29085220
0.0
tensor(14.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 20000/ t/epoch=1.04............. Loss: -1.33602452, mean(E): -18.89742483-0.00923638j, var(E): 1.22185623
0.0
tensor(14.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 20000/ t/epoch=1.03............. Loss: 0.40489680, mean(E): -18.81097888+0.00267622j, var(E): 1.07808834
0.0
tensor(14.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 20000/ t/epoch=1.04............. Loss: -0.15610216, mean(E): -19.03116088-0.01527375j, var(E): 1.54953599
0.0
tensor(14.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 20000/ t/epoch=1.03............. Loss: -1.81639271, mean(E): -18.66643167+0.01953157j, var(E): 1.21100024
0.0
tensor(14.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 20000/ t/epoch=1.03............. Loss: -0.05388830, mean(E): -18.80104076-0.03566981j, var(E): 1.25391274
0.0
tensor(14.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 20000/ t/epoch=1.03............. Loss: 0.68462773, mean(E): -18.84157908+0.00463144j, var(E): 1.34716839
0.0
tensor(14.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 20000/ t/epoch=1.03............. Loss: -0.49460292, mean(E): -18.81003795-0.00715729j, var(E): 1.57506546
0.0
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 20000/ t/epoch=1.03............. Loss: -1.58346378, mean(E): -18.84708636-0.02390451j, var(E): 1.18717814
0.0
tensor(14.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 20000/ t/epoch=1.03............. Loss: -1.40746519, mean(E): -18.86791653-0.01598427j, var(E): 1.17600107
0.0
tensor(14.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 20000/ t/epoch=1.03............. Loss: -0.55916247, mean(E): -18.72844987-0.04675328j, var(E): 1.41790848
0.0
tensor(14.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 20000/ t/epoch=1.03............. Loss: -0.10847747, mean(E): -18.87802166-0.03050748j, var(E): 1.18270494
0.0
tensor(14.8941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 20000/ t/epoch=1.03............. Loss: -0.35731800, mean(E): -18.90849665+0.00651894j, var(E): 1.12771368
0.0
tensor(14.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 20000/ t/epoch=1.04............. Loss: 1.08430076, mean(E): -18.91042039-0.00144484j, var(E): 1.28456480
0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 20000/ t/epoch=1.04............. Loss: -2.21522117, mean(E): -18.84107553-0.01929153j, var(E): 1.17292056
0.0
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 20000/ t/epoch=1.03............. Loss: 1.42645476, mean(E): -18.75957607+0.02854797j, var(E): 1.12683960
0.0
tensor(14.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 20000/ t/epoch=1.04............. Loss: -0.27625586, mean(E): -18.90300144+0.02939187j, var(E): 1.23551513
0.0
tensor(14.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 20000/ t/epoch=1.04............. Loss: -1.34676981, mean(E): -18.96020382+0.01073749j, var(E): 1.22890600
0.0
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 20000/ t/epoch=1.03............. Loss: 0.48762974, mean(E): -18.79085144-0.01762882j, var(E): 1.26715986
0.0
tensor(14.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 20000/ t/epoch=1.03............. Loss: -1.15118902, mean(E): -18.94106636-0.02740487j, var(E): 1.31429556
0.0
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 20000/ t/epoch=1.04............. Loss: -1.19954583, mean(E): -18.78464069+0.00513949j, var(E): 1.34734137
0.0
tensor(14.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 20000/ t/epoch=1.03............. Loss: 1.61598016, mean(E): -18.85155596-0.00799816j, var(E): 1.15061471
0.0
tensor(14.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 20000/ t/epoch=1.04............. Loss: 1.15270163, mean(E): -18.89358512-0.00606969j, var(E): 1.10577327
0.0
tensor(14.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 20000/ t/epoch=1.03............. Loss: 1.66533584, mean(E): -18.73812362-0.01428488j, var(E): 1.43277604
0.0
tensor(14.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 20000/ t/epoch=1.04............. Loss: -1.70486940, mean(E): -18.83755071+0.02325187j, var(E): 1.15797629
0.0
tensor(14.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 20000/ t/epoch=1.04............. Loss: -1.56765867, mean(E): -18.86495968-0.02745653j, var(E): 1.14240575
-0.0
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 20000/ t/epoch=1.03............. Loss: -0.35021269, mean(E): -18.89639647+0.01796926j, var(E): 0.92884727
-0.0
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 20000/ t/epoch=1.03............. Loss: -0.24057335, mean(E): -18.93417035-0.02393455j, var(E): 1.13625778
-0.0
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 20000/ t/epoch=1.03............. Loss: -1.16396169, mean(E): -18.81276128-0.01172789j, var(E): 1.08904119
-0.0
tensor(15.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 20000/ t/epoch=1.03............. Loss: -0.66680258, mean(E): -18.84285296+0.01787476j, var(E): 1.13369207
-0.0
tensor(15.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 20000/ t/epoch=1.03............. Loss: -1.86274670, mean(E): -18.94142543-0.02295328j, var(E): 1.44783422
-0.0
tensor(15.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 20000/ t/epoch=1.03............. Loss: 1.58954722, mean(E): -18.92635101-0.03936856j, var(E): 0.98645078
-0.0
tensor(15.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 20000/ t/epoch=1.04............. Loss: -1.43454223, mean(E): -18.84822366-0.01700068j, var(E): 1.09756146
-0.0
tensor(15.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 20000/ t/epoch=1.04............. Loss: -0.34607090, mean(E): -18.94062424+0.01522345j, var(E): 1.06882373
-0.0
tensor(15.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 20000/ t/epoch=1.03............. Loss: -0.75532616, mean(E): -18.79414525-0.01563743j, var(E): 1.05066828
-0.0
tensor(15.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 20000/ t/epoch=1.03............. Loss: -0.23579397, mean(E): -18.85058535-0.02175471j, var(E): 1.17576459
-0.0
tensor(15.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 20000/ t/epoch=1.03............. Loss: -1.02331539, mean(E): -18.88779904+0.02204560j, var(E): 1.20536614
-0.0
tensor(15.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 20000/ t/epoch=1.03............. Loss: -1.45188323, mean(E): -19.00645383-0.03601300j, var(E): 1.06297230
-0.0
tensor(15.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 20000/ t/epoch=1.04............. Loss: -0.01237121, mean(E): -18.99336847+0.00190563j, var(E): 0.99995272
-0.0
tensor(15.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 20000/ t/epoch=1.03............. Loss: -0.21170822, mean(E): -18.89138976-0.00186123j, var(E): 1.09736554
-0.0
tensor(15.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 20000/ t/epoch=1.04............. Loss: 0.03205125, mean(E): -18.92508736-0.02043238j, var(E): 1.11332231
-0.0
tensor(15.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 20000/ t/epoch=1.03............. Loss: -0.28242455, mean(E): -18.88038746+0.02257955j, var(E): 0.95937970
-0.0
tensor(15.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 20000/ t/epoch=1.04............. Loss: 0.56993207, mean(E): -18.94965702+0.00292974j, var(E): 1.20023204
-0.0
tensor(15.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 20000/ t/epoch=1.03............. Loss: 0.35283284, mean(E): -18.99073394+0.00422121j, var(E): 1.05484696
-0.0
tensor(15.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 20000/ t/epoch=1.03............. Loss: -0.06705908, mean(E): -18.84536505-0.00106328j, var(E): 1.13905328
-0.0
tensor(15.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 20000/ t/epoch=1.03............. Loss: -0.37063894, mean(E): -18.88309759-0.00805101j, var(E): 1.04073119
-0.0
tensor(15.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 20000/ t/epoch=1.03............. Loss: -1.82762625, mean(E): -18.94796009-0.01217607j, var(E): 1.03039092
-0.0
tensor(15.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 20000/ t/epoch=1.03............. Loss: -0.82399105, mean(E): -18.97742226+0.01894340j, var(E): 1.22757227
-0.0
tensor(15.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 20000/ t/epoch=1.03............. Loss: -0.54507356, mean(E): -18.86448364-0.01411862j, var(E): 1.04973281
-0.0
tensor(15.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 20000/ t/epoch=1.03............. Loss: -0.82907834, mean(E): -19.03297487+0.00654332j, var(E): 1.10729848
-0.0
tensor(15.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 20000/ t/epoch=1.04............. Loss: -1.60390319, mean(E): -18.89183090+0.01838352j, var(E): 0.92622332
-0.0
tensor(15.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 20000/ t/epoch=1.04............. Loss: -0.81017024, mean(E): -18.96316568+0.01962091j, var(E): 1.03158313
-0.0
tensor(15.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 20000/ t/epoch=1.04............. Loss: -1.15269484, mean(E): -18.87606404+0.00525560j, var(E): 0.90355590
-0.0
tensor(15.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 20000/ t/epoch=1.03............. Loss: -0.78757244, mean(E): -18.79238173-0.00558000j, var(E): 1.00158130
-0.0
tensor(15.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 20000/ t/epoch=1.04............. Loss: -0.74270121, mean(E): -19.04685026-0.02574315j, var(E): 0.77375517
-0.0
tensor(15.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 20000/ t/epoch=1.04............. Loss: -1.52095984, mean(E): -18.95231259-0.00834583j, var(E): 0.99084930
-0.0
tensor(15.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 20000/ t/epoch=1.04............. Loss: -0.51134034, mean(E): -18.94237756-0.00358659j, var(E): 1.10570527
-0.0
tensor(15.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 20000/ t/epoch=1.03............. Loss: -1.22502473, mean(E): -19.01150198+0.00928513j, var(E): 0.96910652
-0.0
tensor(15.3037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 20000/ t/epoch=1.03............. Loss: -0.14885694, mean(E): -18.98411043+0.01150032j, var(E): 0.98059682
-0.0
tensor(15.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 20000/ t/epoch=1.04............. Loss: -0.37789170, mean(E): -18.98932490-0.00958507j, var(E): 0.88698618
-0.0
tensor(15.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 20000/ t/epoch=1.03............. Loss: -0.99531316, mean(E): -18.94273880+0.01242906j, var(E): 0.98824039
-0.0
tensor(15.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 20000/ t/epoch=1.04............. Loss: 0.47411812, mean(E): -18.89965532+0.00577391j, var(E): 0.81824806
-0.0
tensor(15.3525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 20000/ t/epoch=1.03............. Loss: 0.34145076, mean(E): -19.01342225+0.02561009j, var(E): 0.82418699
-0.0
tensor(15.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 20000/ t/epoch=1.03............. Loss: 0.59551357, mean(E): -18.97073463+0.01483232j, var(E): 1.02515559
-0.0
tensor(15.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 20000/ t/epoch=1.04............. Loss: -2.41101060, mean(E): -18.94601359-0.02912885j, var(E): 0.83418890
-0.0
tensor(15.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 20000/ t/epoch=1.03............. Loss: 0.85107489, mean(E): -19.10018674+0.00743035j, var(E): 0.94461128
-0.0
tensor(15.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 20000/ t/epoch=1.03............. Loss: -1.20843818, mean(E): -18.99637997-0.01227513j, var(E): 1.00699876
-0.0
tensor(15.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 20000/ t/epoch=1.03............. Loss: -0.48272998, mean(E): -18.92449556-0.02090345j, var(E): 0.80820439
-0.0
tensor(15.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 20000/ t/epoch=1.04............. Loss: -0.95440734, mean(E): -19.07998187+0.01492317j, var(E): 0.82771408
-0.0
tensor(15.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 20000/ t/epoch=1.03............. Loss: -0.86775465, mean(E): -19.06355462-0.01757425j, var(E): 0.81650174
-0.0
tensor(15.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 20000/ t/epoch=1.04............. Loss: -0.86624094, mean(E): -19.02880639+0.00499337j, var(E): 0.92006815
-0.0
tensor(15.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 20000/ t/epoch=1.03............. Loss: -0.75405662, mean(E): -18.94922901-0.01265119j, var(E): 0.77220316
-0.0
tensor(15.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 20000/ t/epoch=1.03............. Loss: -2.27415212, mean(E): -18.98762988+0.00939798j, var(E): 0.83792600
-0.0
tensor(15.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 20000/ t/epoch=1.04............. Loss: -0.35728224, mean(E): -19.03701243-0.00559516j, var(E): 0.93976957
-0.0
tensor(15.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 20000/ t/epoch=1.03............. Loss: -1.48937135, mean(E): -19.01930912+0.02053546j, var(E): 0.87905334
-0.0
tensor(15.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 20000/ t/epoch=1.03............. Loss: -0.68073739, mean(E): -19.03984891-0.01379424j, var(E): 0.81670124
-0.0
tensor(15.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 20000/ t/epoch=1.04............. Loss: -1.01372990, mean(E): -18.94809933+0.01909808j, var(E): 0.79847960
-0.0
tensor(15.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 20000/ t/epoch=1.03............. Loss: 0.79270354, mean(E): -18.91013199-0.01111453j, var(E): 0.72618341
-0.0
tensor(15.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 20000/ t/epoch=1.03............. Loss: -0.37037374, mean(E): -19.05777549-0.04002133j, var(E): 0.80823794
-0.0
tensor(15.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 20000/ t/epoch=1.03............. Loss: -0.26476785, mean(E): -19.09722568+0.00116219j, var(E): 0.79930037
-0.0
tensor(15.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 20000/ t/epoch=1.04............. Loss: -0.79238158, mean(E): -19.07090148+0.03000706j, var(E): 0.73396255
-0.0
tensor(15.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 20000/ t/epoch=1.03............. Loss: -0.31997831, mean(E): -18.91185018-0.01913013j, var(E): 0.64147285
-0.0
tensor(15.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 20000/ t/epoch=1.03............. Loss: -0.98362125, mean(E): -19.00252093+0.02109341j, var(E): 0.76654840
-0.0
tensor(15.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 20000/ t/epoch=1.04............. Loss: -1.37243032, mean(E): -19.10122174+0.03366568j, var(E): 0.67732633
-0.0
tensor(15.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 20000/ t/epoch=1.03............. Loss: 0.35617963, mean(E): -19.01461219+0.00836197j, var(E): 0.75855504
-0.0
tensor(15.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 20000/ t/epoch=1.04............. Loss: 0.35321437, mean(E): -19.10711892-0.03392299j, var(E): 0.59181151
-0.0
tensor(15.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 20000/ t/epoch=1.04............. Loss: -0.62095316, mean(E): -19.09316551+0.01997975j, var(E): 0.68848872
-0.0
tensor(15.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 20000/ t/epoch=1.03............. Loss: 0.46434880, mean(E): -19.17492777-0.00528493j, var(E): 0.78007687
-0.0
tensor(15.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 20000/ t/epoch=1.03............. Loss: 0.01363912, mean(E): -19.00800805+0.00168408j, var(E): 0.73903229
-0.0
tensor(15.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 20000/ t/epoch=1.03............. Loss: 0.63850637, mean(E): -19.12630736+0.01556614j, var(E): 0.73714360
-0.0
tensor(15.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 20000/ t/epoch=1.03............. Loss: -1.88620554, mean(E): -19.13569017-0.03426333j, var(E): 0.60769545
-0.0
tensor(15.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 20000/ t/epoch=1.03............. Loss: -0.16587202, mean(E): -18.95413303+0.00281218j, var(E): 0.96300480
-0.0
tensor(15.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 20000/ t/epoch=1.04............. Loss: -0.67723801, mean(E): -19.03262363+0.00718794j, var(E): 0.73409657
-0.0
tensor(15.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 20000/ t/epoch=1.03............. Loss: 0.03869400, mean(E): -19.06415429-0.02370444j, var(E): 0.80585902
-0.0
tensor(15.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 20000/ t/epoch=1.03............. Loss: 0.65577597, mean(E): -19.04967406-0.04759628j, var(E): 0.58928556
-0.0
tensor(15.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 20000/ t/epoch=1.03............. Loss: 1.35093623, mean(E): -19.06447164-0.01814624j, var(E): 0.64488498
-0.0
tensor(15.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 20000/ t/epoch=1.03............. Loss: 0.14214883, mean(E): -19.11587580+0.00395309j, var(E): 0.50006416
-0.0
tensor(15.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 20000/ t/epoch=1.03............. Loss: -1.57020608, mean(E): -18.98297260+0.02724617j, var(E): 0.75000490
-0.0
tensor(15.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 20000/ t/epoch=1.03............. Loss: -1.27888749, mean(E): -19.04570749-0.01074984j, var(E): 0.61675998
-0.0
tensor(15.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 20000/ t/epoch=1.04............. Loss: -0.72102169, mean(E): -19.07162157+0.01227853j, var(E): 0.59479649
-0.0
tensor(15.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 20000/ t/epoch=1.04............. Loss: -1.06426461, mean(E): -19.09054161-0.00879754j, var(E): 0.58194731
-0.0
tensor(15.8436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 20000/ t/epoch=1.03............. Loss: -0.97289851, mean(E): -18.99870549-0.02529534j, var(E): 0.63828844
-0.0
tensor(15.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 20000/ t/epoch=1.03............. Loss: 0.91967375, mean(E): -19.00339363-0.01876031j, var(E): 0.85216723
-0.0
tensor(15.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 20000/ t/epoch=1.04............. Loss: 0.06494812, mean(E): -19.03755814+0.00257948j, var(E): 0.73922977
-0.0
tensor(15.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 20000/ t/epoch=1.03............. Loss: -1.90116378, mean(E): -19.09863767-0.00460716j, var(E): 0.65831193
-0.0
tensor(15.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 20000/ t/epoch=1.03............. Loss: -0.42384439, mean(E): -19.06461040+0.01354242j, var(E): 0.50516211
-0.0
tensor(15.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 20000/ t/epoch=1.03............. Loss: -1.57039693, mean(E): -19.05142040+0.02589073j, var(E): 0.55854318
-0.0
tensor(15.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 20000/ t/epoch=1.04............. Loss: 0.11563772, mean(E): -19.09413794+0.03712006j, var(E): 0.61815391
-0.0
tensor(15.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 20000/ t/epoch=1.03............. Loss: -0.64887640, mean(E): -19.15660734-0.00568935j, var(E): 0.51875879
-0.0
tensor(15.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 20000/ t/epoch=1.03............. Loss: -0.58106894, mean(E): -19.10891486+0.01856087j, var(E): 0.61714086
-0.0
tensor(15.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 20000/ t/epoch=1.03............. Loss: 0.38168524, mean(E): -19.07947020+0.01177516j, var(E): 0.49946341
-0.0
tensor(15.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 20000/ t/epoch=1.03............. Loss: 0.75369146, mean(E): -19.06922041+0.00912045j, var(E): 0.59151873
-0.0
tensor(15.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 20000/ t/epoch=1.03............. Loss: 0.52335933, mean(E): -19.11768175-0.02568089j, var(E): 0.49264608
-0.0
tensor(15.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 20000/ t/epoch=1.03............. Loss: 0.47682766, mean(E): -19.08192776+0.00674982j, var(E): 0.70171200
-0.0
tensor(15.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 20000/ t/epoch=1.04............. Loss: -0.06831312, mean(E): -19.09935605+0.03542627j, var(E): 0.50009883
-0.0
tensor(15.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 20000/ t/epoch=1.04............. Loss: 0.24307548, mean(E): -19.17264871+0.02546959j, var(E): 0.79926369
-0.0
tensor(15.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 20000/ t/epoch=1.04............. Loss: -0.17204063, mean(E): -19.16411622-0.00121097j, var(E): 0.51609904
-0.0
tensor(15.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(15.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 20000/ t/epoch=1.03............. Loss: -0.45442674, mean(E): -19.11451022+0.03816503j, var(E): 0.57237780
-0.0
tensor(16.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 20000/ t/epoch=1.03............. Loss: 0.85728987, mean(E): -19.07761795-0.01072193j, var(E): 0.52691756
-0.0
tensor(16.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 20000/ t/epoch=1.03............. Loss: -0.51584104, mean(E): -19.12401593+0.03459499j, var(E): 0.69647238
-0.0
tensor(16.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 20000/ t/epoch=1.04............. Loss: -1.58972679, mean(E): -19.16179355+0.01621796j, var(E): 0.68196384
-0.0
tensor(16.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 20000/ t/epoch=1.03............. Loss: -0.42627037, mean(E): -19.02072875-0.00659558j, var(E): 0.59876781
-0.0
tensor(16.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 20000/ t/epoch=1.03............. Loss: -0.61582974, mean(E): -19.13089484+0.00052490j, var(E): 0.51023988
-0.0
tensor(16.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 20000/ t/epoch=1.04............. Loss: 0.86260067, mean(E): -18.99198611+0.01377054j, var(E): 0.76234482
-0.0
tensor(16.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 20000/ t/epoch=1.03............. Loss: 0.37119441, mean(E): -19.13812180-0.00356310j, var(E): 0.52309088
-0.0
tensor(16.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 20000/ t/epoch=1.04............. Loss: -0.93239053, mean(E): -19.12929602-0.02506868j, var(E): 0.58379069
-0.0
tensor(16.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 20000/ t/epoch=1.03............. Loss: -0.70433747, mean(E): -19.23589281+0.02457407j, var(E): 0.44034379
-0.0
tensor(16.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 20000/ t/epoch=1.03............. Loss: 0.65054417, mean(E): -19.09389264+0.02601932j, var(E): 0.58635338
-0.0
tensor(16.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 20000/ t/epoch=1.03............. Loss: -0.45203777, mean(E): -19.06119552-0.00817300j, var(E): 0.61458192
-0.0
tensor(16.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 20000/ t/epoch=1.03............. Loss: -0.42551668, mean(E): -19.06158335-0.00953121j, var(E): 0.45513103
-0.0
tensor(16.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 20000/ t/epoch=1.03............. Loss: -0.02527986, mean(E): -19.13721130-0.01616159j, var(E): 0.54930626
-0.0
tensor(16.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 20000/ t/epoch=1.03............. Loss: -0.58192497, mean(E): -19.07780415+0.01713887j, var(E): 0.53305955
-0.0
tensor(16.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 20000/ t/epoch=1.03............. Loss: -0.43946731, mean(E): -19.13989879+0.00732602j, var(E): 0.48266719
-0.0
tensor(16.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 20000/ t/epoch=1.03............. Loss: 1.74427005, mean(E): -19.15490383+0.01451201j, var(E): 0.57624202
-0.0
tensor(16.1392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 20000/ t/epoch=1.04............. Loss: 0.73393928, mean(E): -19.05585127-0.00609905j, var(E): 0.54290969
-0.0
tensor(16.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 20000/ t/epoch=1.04............. Loss: 1.45822301, mean(E): -19.11510119-0.01936010j, var(E): 0.46811022
-0.0
tensor(16.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 20000/ t/epoch=1.04............. Loss: -0.15545937, mean(E): -19.17530738-0.00737874j, var(E): 0.51901911
-0.0
tensor(16.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 20000/ t/epoch=1.04............. Loss: 0.23427868, mean(E): -19.17572467-0.00098510j, var(E): 0.52184199
-0.0
tensor(16.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 20000/ t/epoch=1.04............. Loss: -0.78329695, mean(E): -19.18945358-0.01115670j, var(E): 0.42679060
-0.0
tensor(16.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 20000/ t/epoch=1.03............. Loss: 0.26866495, mean(E): -19.15940619+0.00628113j, var(E): 0.46868793
-0.0
tensor(16.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 20000/ t/epoch=1.04............. Loss: -0.95039685, mean(E): -19.14493743+0.01539374j, var(E): 0.46193161
-0.0
tensor(16.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 20000/ t/epoch=1.03............. Loss: 0.97612566, mean(E): -19.10892036+0.02667350j, var(E): 0.98052965
-0.0
tensor(16.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 20000/ t/epoch=1.03............. Loss: -0.57158086, mean(E): -19.08020830+0.00539790j, var(E): 0.50478461
-0.0
tensor(16.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 20000/ t/epoch=1.04............. Loss: 0.21311223, mean(E): -19.16348556-0.00323856j, var(E): 0.47963376
-0.0
tensor(16.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 20000/ t/epoch=1.03............. Loss: -0.35826190, mean(E): -19.07593456-0.02098952j, var(E): 0.39185378
-0.0
tensor(16.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 20000/ t/epoch=1.04............. Loss: 1.09031667, mean(E): -19.12837355-0.03105852j, var(E): 0.39475501
-0.0
tensor(16.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 20000/ t/epoch=1.03............. Loss: -0.24719897, mean(E): -19.11888255+0.03193690j, var(E): 0.50615756
-0.0
tensor(16.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 20000/ t/epoch=1.04............. Loss: -0.38041744, mean(E): -19.10704428-0.00958729j, var(E): 0.48299063
-0.0
tensor(16.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 20000/ t/epoch=1.04............. Loss: 0.54581546, mean(E): -19.13581504-0.00290210j, var(E): 0.60624460
-0.0
tensor(16.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 20000/ t/epoch=1.03............. Loss: -0.18421959, mean(E): -19.20288806-0.02071421j, var(E): 0.43872877
-0.0
tensor(16.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 20000/ t/epoch=1.03............. Loss: 0.39408227, mean(E): -19.10915189+0.01235962j, var(E): 0.50513971
-0.0
tensor(16.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 20000/ t/epoch=1.04............. Loss: 1.15673049, mean(E): -19.18066921-0.00076551j, var(E): 0.53732042
-0.0
tensor(16.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 20000/ t/epoch=1.03............. Loss: 0.93635269, mean(E): -19.13736850-0.01797452j, var(E): 0.46709156
-0.0
tensor(16.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 20000/ t/epoch=1.03............. Loss: 1.01295127, mean(E): -19.22041376+0.02376420j, var(E): 0.50874930
-0.0
tensor(16.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 20000/ t/epoch=1.03............. Loss: 0.26176602, mean(E): -19.22968723-0.00065952j, var(E): 0.49142510
-0.0
tensor(16.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 20000/ t/epoch=1.04............. Loss: -0.81055193, mean(E): -19.17965552-0.01618775j, var(E): 0.47663095
-0.0
tensor(16.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 20000/ t/epoch=1.04............. Loss: -0.83119034, mean(E): -19.11141943+0.00328814j, var(E): 0.52849722
-0.0
tensor(16.3178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 20000/ t/epoch=1.05............. Loss: -0.22987817, mean(E): -19.13883279-0.00188765j, var(E): 0.49374227
-0.0
tensor(16.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 20000/ t/epoch=1.04............. Loss: -0.10307118, mean(E): -19.11267688-0.00233799j, var(E): 0.57349536
-0.0
tensor(16.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 20000/ t/epoch=1.04............. Loss: 0.43104988, mean(E): -19.12203796-0.02591864j, var(E): 0.47361036
-0.0
tensor(16.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 20000/ t/epoch=1.04............. Loss: -1.16008389, mean(E): -19.05184918-0.00371564j, var(E): 0.58140234
-0.0
tensor(16.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 20000/ t/epoch=1.04............. Loss: -0.45063307, mean(E): -19.15535026-0.00090780j, var(E): 0.54376409
-0.0
tensor(16.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 20000/ t/epoch=1.04............. Loss: 0.84682580, mean(E): -19.17522803-0.01195360j, var(E): 0.38855888
-0.0
tensor(16.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 20000/ t/epoch=1.04............. Loss: 0.19230714, mean(E): -19.17040195+0.00173448j, var(E): 0.41433455
-0.0
tensor(16.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 20000/ t/epoch=1.03............. Loss: 1.27940826, mean(E): -19.13315216+0.01716400j, var(E): 0.60690402
-0.0
tensor(16.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 20000/ t/epoch=1.04............. Loss: -0.76292108, mean(E): -19.14503038-0.00637280j, var(E): 0.54908628
-0.0
tensor(16.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 20000/ t/epoch=1.03............. Loss: -1.05296190, mean(E): -19.15793965+0.00621592j, var(E): 0.57094227
-0.0
tensor(16.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 20000/ t/epoch=1.03............. Loss: 0.57545889, mean(E): -19.23159922-0.00301114j, var(E): 0.50611548
-0.0
tensor(16.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 20000/ t/epoch=1.04............. Loss: -0.92047612, mean(E): -19.11400317-0.01104719j, var(E): 0.38849486
-0.0
tensor(16.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 20000/ t/epoch=1.03............. Loss: 0.07892930, mean(E): -19.06186158+0.01041908j, var(E): 0.35400641
-0.0
tensor(16.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 20000/ t/epoch=1.03............. Loss: 0.34336509, mean(E): -19.17690193+0.00009902j, var(E): 0.45669899
-0.0
tensor(16.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 20000/ t/epoch=1.04............. Loss: -1.31675874, mean(E): -19.13211974-0.00292967j, var(E): 0.38642312
-0.0
tensor(16.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 20000/ t/epoch=1.04............. Loss: 1.47996498, mean(E): -19.13259701-0.00113036j, var(E): 0.38619947
-0.0
tensor(16.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 20000/ t/epoch=1.04............. Loss: -0.16764335, mean(E): -19.10295769+0.01040200j, var(E): 0.45628827
-0.0
tensor(16.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 20000/ t/epoch=1.04............. Loss: -0.82296268, mean(E): -19.24769352-0.03718111j, var(E): 0.41390288
-0.0
tensor(16.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 20000/ t/epoch=1.03............. Loss: -0.31988291, mean(E): -19.19115416+0.00566044j, var(E): 0.35616319
-0.0
tensor(16.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 20000/ t/epoch=1.04............. Loss: -0.41035507, mean(E): -19.25761395-0.01070643j, var(E): 0.48005003
-0.0
tensor(16.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 20000/ t/epoch=1.03............. Loss: -0.06308090, mean(E): -19.15245865+0.00463997j, var(E): 0.38856410
-0.0
tensor(16.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 20000/ t/epoch=1.04............. Loss: -0.54547100, mean(E): -19.16675752+0.00388207j, var(E): 0.26976231
-0.0
tensor(16.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 20000/ t/epoch=1.04............. Loss: -0.00788494, mean(E): -19.15046725-0.01401013j, var(E): 0.45383734
-0.0
tensor(16.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 20000/ t/epoch=1.04............. Loss: -0.44160274, mean(E): -19.24526461-0.03559293j, var(E): 0.37713663
-0.0
tensor(16.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 20000/ t/epoch=1.04............. Loss: -0.11635790, mean(E): -19.13572346-0.01187488j, var(E): 0.26774816
-0.0
tensor(16.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 20000/ t/epoch=1.04............. Loss: 0.23529863, mean(E): -19.20127941-0.00429156j, var(E): 0.31941152
-0.0
tensor(16.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 20000/ t/epoch=1.04............. Loss: -0.62380875, mean(E): -19.16577674+0.02041695j, var(E): 0.48750652
-0.0
tensor(16.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 20000/ t/epoch=1.04............. Loss: -0.71858823, mean(E): -19.08487194+0.02651929j, var(E): 0.33786749
-0.0
tensor(16.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 20000/ t/epoch=1.03............. Loss: 0.95935183, mean(E): -19.17861028+0.02323328j, var(E): 0.39622928
-0.0
tensor(16.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 20000/ t/epoch=1.03............. Loss: -1.24177486, mean(E): -19.20378606-0.01833802j, var(E): 0.46442081
-0.0
tensor(16.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 20000/ t/epoch=1.03............. Loss: 0.62452478, mean(E): -19.11078299-0.01019842j, var(E): 0.36323051
-0.0
tensor(16.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 20000/ t/epoch=1.03............. Loss: 0.98773353, mean(E): -19.14431283-0.00419575j, var(E): 0.55283242
-0.0
tensor(16.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 20000/ t/epoch=1.04............. Loss: -0.25949702, mean(E): -19.16692363+0.01419028j, var(E): 0.44945425
-0.0
tensor(16.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 20000/ t/epoch=1.04............. Loss: 0.30550025, mean(E): -19.13854333-0.00892790j, var(E): 0.39678732
-0.0
tensor(16.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 20000/ t/epoch=1.04............. Loss: 0.21712267, mean(E): -19.17473663+0.01957274j, var(E): 0.33967321
-0.0
tensor(16.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 20000/ t/epoch=1.04............. Loss: -0.78139362, mean(E): -19.16468500+0.00840264j, var(E): 0.32524159
-0.0
tensor(16.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 20000/ t/epoch=1.04............. Loss: -0.31183870, mean(E): -19.14543293-0.00808842j, var(E): 0.35087770
-0.0
tensor(16.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 20000/ t/epoch=1.04............. Loss: 1.21700615, mean(E): -19.16441829-0.00971810j, var(E): 0.35576026
-0.0
tensor(16.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 20000/ t/epoch=1.04............. Loss: -0.84365855, mean(E): -19.26383103+0.01766780j, var(E): 0.25304961
-0.0
tensor(16.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 20000/ t/epoch=1.03............. Loss: 0.21648058, mean(E): -19.21921784+0.01108157j, var(E): 0.24969207
-0.0
tensor(16.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 20000/ t/epoch=1.03............. Loss: 0.39626606, mean(E): -19.17946456-0.03055176j, var(E): 0.53663644
-0.0
tensor(16.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 20000/ t/epoch=1.03............. Loss: 0.62843167, mean(E): -19.16477509+0.03602675j, var(E): 0.27890431
-0.0
tensor(16.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 20000/ t/epoch=1.03............. Loss: 0.73294735, mean(E): -19.15548376-0.02331479j, var(E): 0.30108912
-0.0
tensor(16.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 20000/ t/epoch=1.04............. Loss: -0.21311819, mean(E): -19.10952862-0.00149461j, var(E): 0.43458547
-0.0
tensor(16.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 20000/ t/epoch=1.03............. Loss: -0.46288124, mean(E): -19.20079526+0.01121908j, var(E): 0.30012182
-0.0
tensor(16.6115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 20000/ t/epoch=1.03............. Loss: -0.27957065, mean(E): -19.20513098+0.00756861j, var(E): 0.32366023
-0.0
tensor(16.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 20000/ t/epoch=1.04............. Loss: -1.32358944, mean(E): -19.17682137-0.03214757j, var(E): 0.39964233
-0.0
tensor(16.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 20000/ t/epoch=1.03............. Loss: 1.28320818, mean(E): -19.18043002+0.00309936j, var(E): 0.28534536
-0.0
tensor(16.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 20000/ t/epoch=1.03............. Loss: 0.12887998, mean(E): -19.19271820-0.01892819j, var(E): 0.25354640
-0.0
tensor(16.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 20000/ t/epoch=1.04............. Loss: -1.32458273, mean(E): -19.19925503+0.01221515j, var(E): 0.31679159
-0.0
tensor(16.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 20000/ t/epoch=1.04............. Loss: -0.36796068, mean(E): -19.17136574+0.01535849j, var(E): 0.62485500
-0.0
tensor(16.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 20000/ t/epoch=1.03............. Loss: -0.52449170, mean(E): -19.15389240-0.02118560j, var(E): 0.29235792
-0.0
tensor(16.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 20000/ t/epoch=1.03............. Loss: 0.37698837, mean(E): -19.21716848-0.02377856j, var(E): 0.29788079
-0.0
tensor(16.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 20000/ t/epoch=1.03............. Loss: 0.35436973, mean(E): -19.13278319-0.02210442j, var(E): 0.32374609
-0.0
tensor(16.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 20000/ t/epoch=1.03............. Loss: -0.29625205, mean(E): -19.11223493-0.00196715j, var(E): 0.31329338
-0.0
tensor(16.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 20000/ t/epoch=1.03............. Loss: -0.60355135, mean(E): -19.10776427+0.00248332j, var(E): 0.35655863
-0.0
tensor(16.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 20000/ t/epoch=1.03............. Loss: 1.04184214, mean(E): -19.13518303+0.00610404j, var(E): 0.30287358
-0.0
tensor(16.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 20000/ t/epoch=1.04............. Loss: -0.22462857, mean(E): -19.16470075+0.02496156j, var(E): 0.30436001
-0.0
tensor(16.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 20000/ t/epoch=1.04............. Loss: -0.19083411, mean(E): -19.24203195+0.00012965j, var(E): 0.30013407
-0.0
tensor(16.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 20000/ t/epoch=1.04............. Loss: 0.91245266, mean(E): -19.16224663+0.01184316j, var(E): 0.43624155
-0.0
tensor(16.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 20000/ t/epoch=1.03............. Loss: -0.39255444, mean(E): -19.18285297+0.00198674j, var(E): 0.29446866
-0.0
tensor(16.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 20000/ t/epoch=1.03............. Loss: 0.05113843, mean(E): -19.13547591+0.00149806j, var(E): 0.38232812
-0.0
tensor(16.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 20000/ t/epoch=1.04............. Loss: -0.21651394, mean(E): -19.21157536-0.02742263j, var(E): 0.36527122
-0.0
tensor(16.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 20000/ t/epoch=1.04............. Loss: -0.54712108, mean(E): -19.10327631-0.02145891j, var(E): 0.31398460
-0.0
tensor(16.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 20000/ t/epoch=1.03............. Loss: 0.65867266, mean(E): -19.20289806+0.00514034j, var(E): 0.38975041
-0.0
tensor(16.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 20000/ t/epoch=1.03............. Loss: 0.71937973, mean(E): -19.16921793+0.00263168j, var(E): 0.21203425
-0.0
tensor(16.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 20000/ t/epoch=1.03............. Loss: 0.56109260, mean(E): -19.21200516-0.01068477j, var(E): 0.49800261
-0.0
tensor(16.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 20000/ t/epoch=1.03............. Loss: 0.06722897, mean(E): -19.16807148-0.01462839j, var(E): 0.19221090
-0.0
tensor(16.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 20000/ t/epoch=1.03............. Loss: -0.40490603, mean(E): -19.23004161+0.03037177j, var(E): 0.31810860
-0.0
tensor(16.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 20000/ t/epoch=1.04............. Loss: 0.25212292, mean(E): -19.17853732-0.00578073j, var(E): 0.28621868
-0.0
tensor(16.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 20000/ t/epoch=1.03............. Loss: 1.00129706, mean(E): -19.12744972+0.00337658j, var(E): 0.27900113
-0.0
tensor(16.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 20000/ t/epoch=1.03............. Loss: 1.08123427, mean(E): -19.15564834+0.02501702j, var(E): 0.24082527
-0.0
tensor(16.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 20000/ t/epoch=1.04............. Loss: -0.49648615, mean(E): -19.21047886+0.01923583j, var(E): 0.22301344
-0.0
tensor(16.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 20000/ t/epoch=1.03............. Loss: 0.20834874, mean(E): -19.26152705+0.01378821j, var(E): 0.44399553
-0.0
tensor(16.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 20000/ t/epoch=1.04............. Loss: 0.12334642, mean(E): -19.12241250-0.02357357j, var(E): 0.35135261
-0.0
tensor(16.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 20000/ t/epoch=1.04............. Loss: 1.31573594, mean(E): -19.25286350-0.00124957j, var(E): 0.39282386
-0.0
tensor(16.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 20000/ t/epoch=1.04............. Loss: -0.60727604, mean(E): -19.12021567-0.00414392j, var(E): 0.27890149
-0.0
tensor(16.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 20000/ t/epoch=1.04............. Loss: -0.32361529, mean(E): -19.22284728+0.00257242j, var(E): 0.29208666
-0.0
tensor(16.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 20000/ t/epoch=1.03............. Loss: -1.11148162, mean(E): -19.13099087-0.00527294j, var(E): 0.23855336
-0.0
tensor(16.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 20000/ t/epoch=1.03............. Loss: 0.79933681, mean(E): -19.19732378+0.02401946j, var(E): 0.28868004
-0.0
tensor(16.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 20000/ t/epoch=1.04............. Loss: 0.07056912, mean(E): -19.19922304-0.00016025j, var(E): 0.33010973
-0.0
tensor(16.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 20000/ t/epoch=1.04............. Loss: -1.47251604, mean(E): -19.17860977-0.01010411j, var(E): 0.23957896
-0.0
tensor(16.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 20000/ t/epoch=1.04............. Loss: 0.06406423, mean(E): -19.18722171+0.02664577j, var(E): 0.24282379
-0.0
tensor(16.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 20000/ t/epoch=1.04............. Loss: -0.52965939, mean(E): -19.28165575+0.01250909j, var(E): 0.25044892
-0.0
tensor(16.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 20000/ t/epoch=1.04............. Loss: -0.19472753, mean(E): -19.19853758+0.00973362j, var(E): 0.26831585
-0.0
tensor(16.8426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 20000/ t/epoch=1.04............. Loss: 0.22035631, mean(E): -19.13361631+0.00549202j, var(E): 0.34410711
-0.0
tensor(16.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 20000/ t/epoch=1.03............. Loss: -0.31943907, mean(E): -19.17020187-0.00663963j, var(E): 0.24401376
-0.0
tensor(16.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 20000/ t/epoch=1.04............. Loss: -1.67161620, mean(E): -19.16423775-0.01154585j, var(E): 0.37209728
-0.0
tensor(16.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 20000/ t/epoch=1.03............. Loss: -1.14111894, mean(E): -19.14977762+0.03230270j, var(E): 0.27384510
-0.0
tensor(16.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 20000/ t/epoch=1.03............. Loss: 1.77462758, mean(E): -19.20531553-0.00276922j, var(E): 0.42097151
-0.0
tensor(16.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 20000/ t/epoch=1.04............. Loss: 1.37899159, mean(E): -19.14239552+0.01656222j, var(E): 0.43937128
-0.0
tensor(16.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 20000/ t/epoch=1.04............. Loss: 0.64610406, mean(E): -19.25407906-0.00989584j, var(E): 0.32091085
-0.0
tensor(16.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 20000/ t/epoch=1.04............. Loss: 0.33690277, mean(E): -19.20409445+0.01659746j, var(E): 0.38373458
-0.0
tensor(16.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 20000/ t/epoch=1.04............. Loss: -0.48624589, mean(E): -19.18893055-0.00071682j, var(E): 0.36540224
-0.0
tensor(16.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 20000/ t/epoch=1.04............. Loss: 0.18876651, mean(E): -19.16176105-0.01886295j, var(E): 0.27645814
-0.0
tensor(16.8978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 20000/ t/epoch=1.03............. Loss: -0.28734058, mean(E): -19.16174149+0.01037185j, var(E): 0.19583122
-0.0
tensor(16.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 20000/ t/epoch=1.03............. Loss: 0.15803476, mean(E): -19.22677547-0.00489933j, var(E): 0.28270856
-0.0
tensor(16.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 20000/ t/epoch=1.04............. Loss: -0.01570748, mean(E): -19.18040949-0.01312321j, var(E): 0.25211335
-0.0
tensor(16.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 20000/ t/epoch=1.04............. Loss: -0.30871976, mean(E): -19.17673592-0.00546233j, var(E): 0.18591636
-0.0
tensor(16.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 20000/ t/epoch=1.04............. Loss: 0.27812481, mean(E): -19.17766054-0.01041524j, var(E): 0.24869822
-0.0
tensor(16.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 20000/ t/epoch=1.04............. Loss: 1.33479994, mean(E): -19.22355720-0.03279702j, var(E): 0.40643116
-0.0
tensor(16.9252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 20000/ t/epoch=1.04............. Loss: 0.25434245, mean(E): -19.18572708+0.01419926j, var(E): 0.32772710
-0.0
tensor(16.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 20000/ t/epoch=1.03............. Loss: 0.24438407, mean(E): -19.17948655+0.01548805j, var(E): 0.23566801
-0.0
tensor(16.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 20000/ t/epoch=1.04............. Loss: -0.25610316, mean(E): -19.21554959-0.01626902j, var(E): 0.26890171
-0.0
tensor(16.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 20000/ t/epoch=1.03............. Loss: -0.49743169, mean(E): -19.19272227-0.00276188j, var(E): 0.24195576
-0.0
tensor(16.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 20000/ t/epoch=1.03............. Loss: 1.09770382, mean(E): -19.21172981-0.00224974j, var(E): 0.30736298
-0.0
tensor(16.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 20000/ t/epoch=1.04............. Loss: 0.20280339, mean(E): -19.20039603-0.01965062j, var(E): 0.26693088
-0.0
tensor(16.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 20000/ t/epoch=1.03............. Loss: 0.11502767, mean(E): -19.22997351-0.00987069j, var(E): 0.29072643
-0.0
tensor(16.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 20000/ t/epoch=1.04............. Loss: 0.55594976, mean(E): -19.18895321-0.02125769j, var(E): 0.35694044
-0.0
tensor(16.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 20000/ t/epoch=1.03............. Loss: -0.64231698, mean(E): -19.15456569-0.02797016j, var(E): 0.22842329
-0.0
tensor(16.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 20000/ t/epoch=1.04............. Loss: -0.26399196, mean(E): -19.17895753-0.00726737j, var(E): 0.24667793
-0.0
tensor(16.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 20000/ t/epoch=1.04............. Loss: 0.25235395, mean(E): -19.21114105-0.01153205j, var(E): 0.25850150
-0.0
tensor(16.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 20000/ t/epoch=1.04............. Loss: -0.48576409, mean(E): -19.18971543+0.01550004j, var(E): 0.20544408
-0.0
tensor(16.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 20000/ t/epoch=1.03............. Loss: 0.09364798, mean(E): -19.21515050+0.00150261j, var(E): 0.16485775
-0.0
tensor(16.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 20000/ t/epoch=1.03............. Loss: 0.38728721, mean(E): -19.17092528-0.00619250j, var(E): 0.27154218
-0.0
tensor(16.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 20000/ t/epoch=1.04............. Loss: -0.09498222, mean(E): -19.21145507+0.01663756j, var(E): 0.22205267
-0.0
tensor(16.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 20000/ t/epoch=1.04............. Loss: 0.01045530, mean(E): -19.14632520+0.00374501j, var(E): 0.24432474
-0.0
tensor(17.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 20000/ t/epoch=1.04............. Loss: -0.69747612, mean(E): -19.16167717+0.00035993j, var(E): 0.21198891
-0.0
tensor(17.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 20000/ t/epoch=1.04............. Loss: 0.03336098, mean(E): -19.22949253+0.00742667j, var(E): 0.19045694
-0.0
tensor(17.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 20000/ t/epoch=1.04............. Loss: 0.61676431, mean(E): -19.11413765-0.00586304j, var(E): 0.22761165
-0.0
tensor(17.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 20000/ t/epoch=1.03............. Loss: 0.69648653, mean(E): -19.13638044-0.01102939j, var(E): 0.23001322
-0.0
tensor(17.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 20000/ t/epoch=1.03............. Loss: -0.20586304, mean(E): -19.19395041-0.00513061j, var(E): 0.33625171
-0.0
tensor(17.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 20000/ t/epoch=1.03............. Loss: -0.41670777, mean(E): -19.20039558+0.04620286j, var(E): 0.23552390
-0.0
tensor(17.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 20000/ t/epoch=1.03............. Loss: 1.01244669, mean(E): -19.16485975-0.00050548j, var(E): 0.25178121
-0.0
tensor(17.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 20000/ t/epoch=1.03............. Loss: -1.15616320, mean(E): -19.21900267-0.01628050j, var(E): 0.24452209
-0.0
tensor(17.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 20000/ t/epoch=1.04............. Loss: -0.55816962, mean(E): -19.15332986+0.01148551j, var(E): 0.23166909
-0.0
tensor(17.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 20000/ t/epoch=1.04............. Loss: 1.39407919, mean(E): -19.22372189+0.01533766j, var(E): 0.21996844
-0.0
tensor(17.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 20000/ t/epoch=1.04............. Loss: -0.81357313, mean(E): -19.14608773+0.03084106j, var(E): 0.25870926
-0.0
tensor(17.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 20000/ t/epoch=1.03............. Loss: -1.28344553, mean(E): -19.20022782+0.00505687j, var(E): 0.19399675
-0.0
tensor(17.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 20000/ t/epoch=1.03............. Loss: -0.73856414, mean(E): -19.18130903-0.00245070j, var(E): 0.23213492
-0.0
tensor(17.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 20000/ t/epoch=1.04............. Loss: 0.96509271, mean(E): -19.15838137-0.00396394j, var(E): 0.17199687
-0.0
tensor(17.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 20000/ t/epoch=1.04............. Loss: 1.25248450, mean(E): -19.21894004+0.02200941j, var(E): 0.21916320
-0.0
tensor(17.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 20000/ t/epoch=1.04............. Loss: -0.49326194, mean(E): -19.17793327+0.00549172j, var(E): 0.24351610
-0.0
tensor(17.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 20000/ t/epoch=1.04............. Loss: -0.24385084, mean(E): -19.12628708-0.00414192j, var(E): 0.25870357
-0.0
tensor(17.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 20000/ t/epoch=1.04............. Loss: -0.98418463, mean(E): -19.10658739+0.01640668j, var(E): 0.23632901
-0.0
tensor(17.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 20000/ t/epoch=1.04............. Loss: 0.27121584, mean(E): -19.18557094-0.00674909j, var(E): 0.24062621
-0.0
tensor(17.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 20000/ t/epoch=1.04............. Loss: 1.16693339, mean(E): -19.15883373+0.01604384j, var(E): 0.18338767
-0.0
tensor(17.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 20000/ t/epoch=1.04............. Loss: -0.17264306, mean(E): -19.16172897-0.03994880j, var(E): 0.22705133
-0.0
tensor(17.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 20000/ t/epoch=1.03............. Loss: 0.39369434, mean(E): -19.17602741-0.01418708j, var(E): 0.26828199
-0.0
tensor(17.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 20000/ t/epoch=1.04............. Loss: -0.83354916, mean(E): -19.21028329+0.01064047j, var(E): 0.17075653
-0.0
tensor(17.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 20000/ t/epoch=1.04............. Loss: -0.06364657, mean(E): -19.20841495-0.00074271j, var(E): 0.17664090
-0.0
tensor(17.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 20000/ t/epoch=1.03............. Loss: -0.76915596, mean(E): -19.23250121+0.02391999j, var(E): 0.40785228
-0.0
tensor(17.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 20000/ t/epoch=1.04............. Loss: 0.17277134, mean(E): -19.19104807+0.00873630j, var(E): 0.16859024
-0.0
tensor(17.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 20000/ t/epoch=1.04............. Loss: -0.12205435, mean(E): -19.13378814+0.00714765j, var(E): 0.19499499
-0.0
tensor(17.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 20000/ t/epoch=1.04............. Loss: -0.26613116, mean(E): -19.18734360-0.00480431j, var(E): 0.28488324
-0.0
tensor(17.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 20000/ t/epoch=1.04............. Loss: 0.89710060, mean(E): -19.19501411-0.00108385j, var(E): 0.18136247
-0.0
tensor(17.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 20000/ t/epoch=1.04............. Loss: -0.56582746, mean(E): -19.18615943-0.00572578j, var(E): 0.24967744
-0.0
tensor(17.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 20000/ t/epoch=1.04............. Loss: 0.39409950, mean(E): -19.18618994+0.00657191j, var(E): 0.20360330
-0.0
tensor(17.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 20000/ t/epoch=1.04............. Loss: -0.32344527, mean(E): -19.22051466+0.01690492j, var(E): 0.14502511
-0.0
tensor(17.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 20000/ t/epoch=1.03............. Loss: -0.15067276, mean(E): -19.19068725+0.01754176j, var(E): 0.30168446
-0.0
tensor(17.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 20000/ t/epoch=1.04............. Loss: -0.09913157, mean(E): -19.17893568-0.03238989j, var(E): 0.12929234
-0.0
tensor(17.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 20000/ t/epoch=1.04............. Loss: 0.02038022, mean(E): -19.22834557-0.03242016j, var(E): 0.23668864
-0.0
tensor(17.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 20000/ t/epoch=1.04............. Loss: 1.45711988, mean(E): -19.27383701-0.02119400j, var(E): 0.18666956
-0.0
tensor(17.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 20000/ t/epoch=1.03............. Loss: 0.44383002, mean(E): -19.17241591-0.01708630j, var(E): 0.28512479
-0.0
tensor(17.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 20000/ t/epoch=1.03............. Loss: -1.42899100, mean(E): -19.19665970-0.01264626j, var(E): 0.14657797
-0.0
tensor(17.1917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 20000/ t/epoch=1.03............. Loss: 0.36018099, mean(E): -19.18412360+0.00057813j, var(E): 0.20265514
-0.0
tensor(17.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 20000/ t/epoch=1.03............. Loss: 0.09357240, mean(E): -19.24754942-0.01091671j, var(E): 0.23312641
-0.0
tensor(17.2010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 20000/ t/epoch=1.03............. Loss: 1.24839027, mean(E): -19.17367828-0.01210843j, var(E): 0.14418437
-0.0
tensor(17.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 20000/ t/epoch=1.03............. Loss: 0.13976522, mean(E): -19.24463132-0.02065534j, var(E): 0.15987338
-0.0
tensor(17.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 20000/ t/epoch=1.03............. Loss: 0.31530754, mean(E): -19.17128034-0.00174534j, var(E): 0.15228982
-0.0
tensor(17.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 20000/ t/epoch=1.03............. Loss: -0.15108466, mean(E): -19.14984279+0.00130212j, var(E): 0.23174317
-0.0
tensor(17.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 20000/ t/epoch=1.04............. Loss: 0.04918051, mean(E): -19.17989226-0.01728518j, var(E): 0.24396202
-0.0
tensor(17.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 20000/ t/epoch=1.04............. Loss: -0.38674401, mean(E): -19.15055342+0.00362700j, var(E): 0.20480598
-0.0
tensor(17.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 20000/ t/epoch=1.04............. Loss: -0.04265958, mean(E): -19.20996702+0.01221200j, var(E): 0.35200788
-0.0
tensor(17.2330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 20000/ t/epoch=1.03............. Loss: -0.51472573, mean(E): -19.24461547-0.03235292j, var(E): 0.18919332
-0.0
tensor(17.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 20000/ t/epoch=1.04............. Loss: 1.18352329, mean(E): -19.17648129-0.00546481j, var(E): 0.18339361
-0.0
tensor(17.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 20000/ t/epoch=1.04............. Loss: -1.09831294, mean(E): -19.18744161-0.01105646j, var(E): 0.19499426
-0.0
tensor(17.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 20000/ t/epoch=1.03............. Loss: -0.11677455, mean(E): -19.18580436+0.02042650j, var(E): 0.19572374
-0.0
tensor(17.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 20000/ t/epoch=1.04............. Loss: 0.03902430, mean(E): -19.20497551-0.01523808j, var(E): 0.19577168
-0.0
tensor(17.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 20000/ t/epoch=1.03............. Loss: 0.63163057, mean(E): -19.09828586-0.01728978j, var(E): 0.27885022
-0.0
tensor(17.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 20000/ t/epoch=1.03............. Loss: 0.40352056, mean(E): -19.19959569-0.01180653j, var(E): 0.23891005
-0.0
tensor(17.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 20000/ t/epoch=1.04............. Loss: 1.23797786, mean(E): -19.22534654-0.00310163j, var(E): 0.21164379
-0.0
tensor(17.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 20000/ t/epoch=1.04............. Loss: -0.64150213, mean(E): -19.19897223+0.00087318j, var(E): 0.20291546
-0.0
tensor(17.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 20000/ t/epoch=1.04............. Loss: -1.13419507, mean(E): -19.21714084+0.00451526j, var(E): 0.26851185
-0.0
tensor(17.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 20000/ t/epoch=1.04............. Loss: 0.18965658, mean(E): -19.21475347+0.00956214j, var(E): 0.14645428
-0.0
tensor(17.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 20000/ t/epoch=1.04............. Loss: -0.16225598, mean(E): -19.18134732-0.01199218j, var(E): 0.18405449
-0.0
tensor(17.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 20000/ t/epoch=1.04............. Loss: -1.00576546, mean(E): -19.20586602-0.01796488j, var(E): 0.13307908
-0.0
tensor(17.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 20000/ t/epoch=1.04............. Loss: 0.54940141, mean(E): -19.19555959+0.00367075j, var(E): 0.15557288
-0.0
tensor(17.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 20000/ t/epoch=1.03............. Loss: -1.16937543, mean(E): -19.20129541+0.03360715j, var(E): 0.23652847
-0.0
tensor(17.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 20000/ t/epoch=1.03............. Loss: -0.71994697, mean(E): -19.22365839-0.02562553j, var(E): 0.16062358
-0.0
tensor(17.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 20000/ t/epoch=1.04............. Loss: -0.07097969, mean(E): -19.21741085-0.00413612j, var(E): 0.14580537
-0.0
tensor(17.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 20000/ t/epoch=1.04............. Loss: -0.39707225, mean(E): -19.24978799-0.01472268j, var(E): 0.15947365
-0.0
tensor(17.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 20000/ t/epoch=1.04............. Loss: -0.67126512, mean(E): -19.22000187-0.01310874j, var(E): 0.27845135
-0.0
tensor(17.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 20000/ t/epoch=1.04............. Loss: 0.58375044, mean(E): -19.23065162-0.01631541j, var(E): 0.18815549
-0.0
tensor(17.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 20000/ t/epoch=1.04............. Loss: -0.11939173, mean(E): -19.19447014-0.00039051j, var(E): 0.21007492
-0.0
tensor(17.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 20000/ t/epoch=1.03............. Loss: -0.14956705, mean(E): -19.17893015+0.00103564j, var(E): 0.19208879
-0.0
tensor(17.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 20000/ t/epoch=1.04............. Loss: 0.01317366, mean(E): -19.22774951+0.00101208j, var(E): 0.16098813
-0.0
tensor(17.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 20000/ t/epoch=1.04............. Loss: -0.11014130, mean(E): -19.21655774+0.00048045j, var(E): 0.20658352
-0.0
tensor(17.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 20000/ t/epoch=1.03............. Loss: -0.03999425, mean(E): -19.15622802+0.01594197j, var(E): 0.23721324
-0.0
tensor(17.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 20000/ t/epoch=1.04............. Loss: 0.51863628, mean(E): -19.21499609+0.00055356j, var(E): 0.20514741
-0.0
tensor(17.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 20000/ t/epoch=1.03............. Loss: -0.47893523, mean(E): -19.18994800-0.00133563j, var(E): 0.11970650
-0.0
tensor(17.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 20000/ t/epoch=1.03............. Loss: -0.25898113, mean(E): -19.16003516-0.00849070j, var(E): 0.23372529
-0.0
tensor(17.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 20000/ t/epoch=1.04............. Loss: -0.08573961, mean(E): -19.23875634-0.00633191j, var(E): 0.18554969
-0.0
tensor(17.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 20000/ t/epoch=1.03............. Loss: 0.17049425, mean(E): -19.16328569+0.00868742j, var(E): 0.24178478
-0.0
tensor(17.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 20000/ t/epoch=1.04............. Loss: -0.54456485, mean(E): -19.18780451+0.00278382j, var(E): 0.16896064
-0.0
tensor(17.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 20000/ t/epoch=1.03............. Loss: -0.48717938, mean(E): -19.16708177+0.02467670j, var(E): 0.16532779
-0.0
tensor(17.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 20000/ t/epoch=1.04............. Loss: 0.38691210, mean(E): -19.23642514-0.00612246j, var(E): 0.19346774
-0.0
tensor(17.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 20000/ t/epoch=1.04............. Loss: -0.47467248, mean(E): -19.15108930-0.00961096j, var(E): 0.20941788
-0.0
tensor(17.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 20000/ t/epoch=1.03............. Loss: 0.57048995, mean(E): -19.20447883+0.00483834j, var(E): 0.27127228
-0.0
tensor(17.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 20000/ t/epoch=1.03............. Loss: 0.13264572, mean(E): -19.20204063-0.00254710j, var(E): 0.14293172
-0.0
tensor(17.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 20000/ t/epoch=1.03............. Loss: -0.08426736, mean(E): -19.15861165+0.00977519j, var(E): 0.18995995
-0.0
tensor(17.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 20000/ t/epoch=1.03............. Loss: 0.45179859, mean(E): -19.19664503-0.01593456j, var(E): 0.19079831
-0.0
tensor(17.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 20000/ t/epoch=1.03............. Loss: -0.76346587, mean(E): -19.16628854-0.00207252j, var(E): 0.22525962
-0.0
tensor(17.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 20000/ t/epoch=1.03............. Loss: -0.03819455, mean(E): -19.13778980-0.00430672j, var(E): 0.22106015
-0.0
tensor(17.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 20000/ t/epoch=1.04............. Loss: 0.74537023, mean(E): -19.21436880+0.01584329j, var(E): 0.15189119
-0.0
tensor(17.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 20000/ t/epoch=1.03............. Loss: 1.08745666, mean(E): -19.13488442-0.04547340j, var(E): 0.24659372
-0.0
tensor(17.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 20000/ t/epoch=1.03............. Loss: -0.51225632, mean(E): -19.16531395+0.00015289j, var(E): 0.22224708
-0.0
tensor(17.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 20000/ t/epoch=1.04............. Loss: 0.15568274, mean(E): -19.18605867-0.00630928j, var(E): 0.15875686
-0.0
tensor(17.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 20000/ t/epoch=1.04............. Loss: 0.72074047, mean(E): -19.24864520-0.01236089j, var(E): 0.11260246
-0.0
tensor(17.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 20000/ t/epoch=1.04............. Loss: 0.63942677, mean(E): -19.17786554+0.00497486j, var(E): 0.28152435
-0.0
tensor(17.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 20000/ t/epoch=1.04............. Loss: 0.03526266, mean(E): -19.16935975-0.00520349j, var(E): 0.22410755
-0.0
tensor(17.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 20000/ t/epoch=1.03............. Loss: -0.39775623, mean(E): -19.15870214+0.01141546j, var(E): 0.17115312
-0.0
tensor(17.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 20000/ t/epoch=1.03............. Loss: -0.00424218, mean(E): -19.15760115-0.01715592j, var(E): 0.16618368
-0.0
tensor(17.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 20000/ t/epoch=1.04............. Loss: 0.45340582, mean(E): -19.22888877-0.00751615j, var(E): 0.16607108
-0.0
tensor(17.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 20000/ t/epoch=1.04............. Loss: -0.01032199, mean(E): -19.23704535-0.01007431j, var(E): 0.20778727
-0.0
tensor(17.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 20000/ t/epoch=1.04............. Loss: 0.10528870, mean(E): -19.17475066-0.01105306j, var(E): 0.16823528
-0.0
tensor(17.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 20000/ t/epoch=1.04............. Loss: -0.02679404, mean(E): -19.20498096+0.02145834j, var(E): 0.10852604
-0.0
tensor(17.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 20000/ t/epoch=1.04............. Loss: 0.41616968, mean(E): -19.21258015+0.01106891j, var(E): 0.17067582
-0.0
tensor(17.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 20000/ t/epoch=1.03............. Loss: -0.63103468, mean(E): -19.15170390+0.00355341j, var(E): 0.18656389
-0.0
tensor(17.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 20000/ t/epoch=1.04............. Loss: 0.49402467, mean(E): -19.22180410+0.00429532j, var(E): 0.25672796
-0.0
tensor(17.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 20000/ t/epoch=1.04............. Loss: -0.42654278, mean(E): -19.19578495-0.01081692j, var(E): 0.10857305
-0.0
tensor(17.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 20000/ t/epoch=1.04............. Loss: -0.40685799, mean(E): -19.20793336-0.00210600j, var(E): 0.22433359
-0.0
tensor(17.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 20000/ t/epoch=1.04............. Loss: 0.54460096, mean(E): -19.23442241-0.00319789j, var(E): 0.16337581
-0.0
tensor(17.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 20000/ t/epoch=1.04............. Loss: 0.59058729, mean(E): -19.19151208+0.00613798j, var(E): 0.15241346
-0.0
tensor(17.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 20000/ t/epoch=1.03............. Loss: -0.71211680, mean(E): -19.22022889+0.00286239j, var(E): 0.13092359
-0.0
tensor(17.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 20000/ t/epoch=1.03............. Loss: 0.16131367, mean(E): -19.23202473-0.00289200j, var(E): 0.14579114
-0.0
tensor(17.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 20000/ t/epoch=1.03............. Loss: 0.18385260, mean(E): -19.15796121-0.01151200j, var(E): 0.10079707
-0.0
tensor(17.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 20000/ t/epoch=1.04............. Loss: -0.77783789, mean(E): -19.21855520-0.00871844j, var(E): 0.17366610
-0.0
tensor(17.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 20000/ t/epoch=1.04............. Loss: -0.98761067, mean(E): -19.15172699-0.00714183j, var(E): 0.15428719
-0.0
tensor(17.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 20000/ t/epoch=1.04............. Loss: 0.40235325, mean(E): -19.19536843-0.01176120j, var(E): 0.12113300
-0.0
tensor(17.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 20000/ t/epoch=1.03............. Loss: 0.07560286, mean(E): -19.21807207+0.00065306j, var(E): 0.16604470
-0.0
tensor(17.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 20000/ t/epoch=1.04............. Loss: 0.15570396, mean(E): -19.18492732-0.00732518j, var(E): 0.25715289
-0.0
tensor(17.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 20000/ t/epoch=1.03............. Loss: -1.46316363, mean(E): -19.23228564-0.00990805j, var(E): 0.20259679
-0.0
tensor(17.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 20000/ t/epoch=1.04............. Loss: -0.33202653, mean(E): -19.18463912-0.00745291j, var(E): 0.13701607
-0.0
tensor(17.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 20000/ t/epoch=1.04............. Loss: 1.13349208, mean(E): -19.15779106+0.01608601j, var(E): 0.19950015
-0.0
tensor(17.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 20000/ t/epoch=1.04............. Loss: 1.17983134, mean(E): -19.17931811+0.03184243j, var(E): 0.15246713
-0.0
tensor(17.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 20000/ t/epoch=1.04............. Loss: -0.50956476, mean(E): -19.18420596-0.00897876j, var(E): 0.18646572
-0.0
tensor(17.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 20000/ t/epoch=1.04............. Loss: -0.82253735, mean(E): -19.17537091-0.01708695j, var(E): 0.16487424
-0.0
tensor(17.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 20000/ t/epoch=1.04............. Loss: -0.20560363, mean(E): -19.20139798+0.00877880j, var(E): 0.13904840
-0.0
tensor(17.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 20000/ t/epoch=1.04............. Loss: -0.18021867, mean(E): -19.22464872+0.02015535j, var(E): 0.11102160
-0.0
tensor(17.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 20000/ t/epoch=1.04............. Loss: -0.30349105, mean(E): -19.24065449-0.00967864j, var(E): 0.17027295
-0.0
tensor(17.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 20000/ t/epoch=1.04............. Loss: -0.42518175, mean(E): -19.14103903+0.00183325j, var(E): 0.18122662
-0.0
tensor(17.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 20000/ t/epoch=1.04............. Loss: 0.06297610, mean(E): -19.20861903-0.01843432j, var(E): 0.20656631
-0.0
tensor(17.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 20000/ t/epoch=1.04............. Loss: 0.50536429, mean(E): -19.24385903+0.00931069j, var(E): 0.14791369
-0.0
tensor(17.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 20000/ t/epoch=1.04............. Loss: -0.38673286, mean(E): -19.24324007-0.01744518j, var(E): 0.14001500
-0.0
tensor(17.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 20000/ t/epoch=1.04............. Loss: -0.00689043, mean(E): -19.20054995-0.00491662j, var(E): 0.16988632
-0.0
tensor(17.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 20000/ t/epoch=1.04............. Loss: 0.47271665, mean(E): -19.22899538-0.01485843j, var(E): 0.15504034
-0.0
tensor(17.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 20000/ t/epoch=1.04............. Loss: -0.06011209, mean(E): -19.17655872-0.00256102j, var(E): 0.29179271
-0.0
tensor(17.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 20000/ t/epoch=1.03............. Loss: -0.28190200, mean(E): -19.17571634+0.00111801j, var(E): 0.15230080
-0.0
tensor(17.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 20000/ t/epoch=1.04............. Loss: 0.27274675, mean(E): -19.24498006-0.01012844j, var(E): 0.14747562
-0.0
tensor(17.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 20000/ t/epoch=1.03............. Loss: 0.35013887, mean(E): -19.20684231-0.00713284j, var(E): 0.20031524
-0.0
tensor(17.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 20000/ t/epoch=1.03............. Loss: 0.52113871, mean(E): -19.21551899-0.00894351j, var(E): 0.12135848
-0.0
tensor(17.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 20000/ t/epoch=1.04............. Loss: -0.22823987, mean(E): -19.21143617+0.01399345j, var(E): 0.14583148
-0.0
tensor(17.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 20000/ t/epoch=1.03............. Loss: 0.18438271, mean(E): -19.18460360+0.00957055j, var(E): 0.18050271
-0.0
tensor(17.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 20000/ t/epoch=1.04............. Loss: 0.28621761, mean(E): -19.20682045+0.01461610j, var(E): 0.14441742
-0.0
tensor(17.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 20000/ t/epoch=1.04............. Loss: -0.07463542, mean(E): -19.23142444+0.02091501j, var(E): 0.16558944
-0.0
tensor(17.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 20000/ t/epoch=1.04............. Loss: 0.03641222, mean(E): -19.22214070-0.00716122j, var(E): 0.10051124
-0.0
tensor(17.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 20000/ t/epoch=1.04............. Loss: 1.86986669, mean(E): -19.18465320-0.00879222j, var(E): 0.19455358
-0.0
tensor(17.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 20000/ t/epoch=1.04............. Loss: -0.74471910, mean(E): -19.15688732+0.01485228j, var(E): 0.14964177
-0.0
tensor(17.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 20000/ t/epoch=1.04............. Loss: -0.34447970, mean(E): -19.23614555-0.01784703j, var(E): 0.13642896
-0.0
tensor(17.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 20000/ t/epoch=1.04............. Loss: 0.46807685, mean(E): -19.18428645-0.00131837j, var(E): 0.15066116
-0.0
tensor(17.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 20000/ t/epoch=1.03............. Loss: 0.44275926, mean(E): -19.20191974+0.00428537j, var(E): 0.13083747
-0.0
tensor(17.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 20000/ t/epoch=1.04............. Loss: -0.23343667, mean(E): -19.17874538+0.00203328j, var(E): 0.16475524
-0.0
tensor(17.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 20000/ t/epoch=1.03............. Loss: -0.49822273, mean(E): -19.21325861-0.00348500j, var(E): 0.12367532
-0.0
tensor(17.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 20000/ t/epoch=1.04............. Loss: 0.57151346, mean(E): -19.19495018+0.01440688j, var(E): 0.10625653
-0.0
tensor(17.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 20000/ t/epoch=1.04............. Loss: -0.50694169, mean(E): -19.21526195-0.00542414j, var(E): 0.14877980
-0.0
tensor(17.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 20000/ t/epoch=1.04............. Loss: -0.55466866, mean(E): -19.19633486-0.00825235j, var(E): 0.11878783
-0.0
tensor(17.6700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 20000/ t/epoch=1.04............. Loss: 0.24472806, mean(E): -19.19474456-0.01413304j, var(E): 0.09551528
-0.0
tensor(17.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 20000/ t/epoch=1.04............. Loss: 0.29019094, mean(E): -19.20615639+0.00653880j, var(E): 0.17240630
-0.0
tensor(17.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 20000/ t/epoch=1.04............. Loss: 0.29508050, mean(E): -19.21581455+0.00759005j, var(E): 0.16880701
-0.0
tensor(17.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 20000/ t/epoch=1.04............. Loss: -0.17099207, mean(E): -19.17112598+0.00271959j, var(E): 0.09676752
-0.0
tensor(17.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 20000/ t/epoch=1.04............. Loss: 0.56386751, mean(E): -19.23975459-0.00311525j, var(E): 0.14112561
-0.0
tensor(17.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 20000/ t/epoch=1.04............. Loss: 0.02783941, mean(E): -19.22924804+0.02434409j, var(E): 0.22781164
-0.0
tensor(17.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 20000/ t/epoch=1.04............. Loss: 0.09395475, mean(E): -19.20507269+0.00634874j, var(E): 0.20623151
-0.0
tensor(17.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 20000/ t/epoch=1.04............. Loss: 0.62451162, mean(E): -19.16416294-0.00618526j, var(E): 0.12986777
-0.0
tensor(17.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 20000/ t/epoch=1.04............. Loss: -0.01355516, mean(E): -19.22227048-0.00249721j, var(E): 0.18278036
-0.0
tensor(17.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 20000/ t/epoch=1.04............. Loss: 0.86508828, mean(E): -19.21466746-0.00381618j, var(E): 0.12053783
-0.0
tensor(17.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 20000/ t/epoch=1.04............. Loss: -0.59528869, mean(E): -19.22212223-0.02525440j, var(E): 0.13716260
-0.0
tensor(17.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 20000/ t/epoch=1.04............. Loss: 0.46871316, mean(E): -19.22207419+0.00741752j, var(E): 0.12962787
-0.0
tensor(17.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 20000/ t/epoch=1.04............. Loss: -0.52206127, mean(E): -19.22732797-0.00536434j, var(E): 0.16920062
-0.0
tensor(17.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 20000/ t/epoch=1.04............. Loss: 0.46998151, mean(E): -19.20316872-0.00289575j, var(E): 0.18911255
-0.0
tensor(17.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 20000/ t/epoch=1.04............. Loss: -0.08658979, mean(E): -19.20572885+0.00369115j, var(E): 0.11665407
-0.0
tensor(17.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 20000/ t/epoch=1.03............. Loss: 0.01046768, mean(E): -19.21459389-0.02198524j, var(E): 0.10374778
-0.0
tensor(17.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 20000/ t/epoch=1.04............. Loss: -0.35156625, mean(E): -19.20185858-0.01702683j, var(E): 0.12333464
-0.0
tensor(17.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 20000/ t/epoch=1.04............. Loss: 0.55184054, mean(E): -19.22024875-0.00110226j, var(E): 0.15611339
-0.0
tensor(17.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 20000/ t/epoch=1.04............. Loss: 0.28876189, mean(E): -19.20367624-0.01276898j, var(E): 0.08581204
-0.0
tensor(17.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 20000/ t/epoch=1.04............. Loss: -0.33863553, mean(E): -19.18971779-0.00133646j, var(E): 0.14792941
-0.0
tensor(17.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 20000/ t/epoch=1.04............. Loss: -0.85313853, mean(E): -19.22442737+0.00834094j, var(E): 0.18443954
-0.0
tensor(17.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 20000/ t/epoch=1.03............. Loss: 0.17667905, mean(E): -19.19310621+0.00261717j, var(E): 0.12750818
-0.0
tensor(17.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 20000/ t/epoch=1.04............. Loss: 0.19575533, mean(E): -19.19401039+0.00863348j, var(E): 0.12098410
-0.0
tensor(17.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 20000/ t/epoch=1.04............. Loss: -0.49397861, mean(E): -19.21944901+0.01118071j, var(E): 0.18168733
-0.0
tensor(17.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 20000/ t/epoch=1.04............. Loss: 0.04136297, mean(E): -19.22440987-0.00520724j, var(E): 0.12464698
-0.0
tensor(17.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 20000/ t/epoch=1.04............. Loss: -0.18062784, mean(E): -19.23765495-0.00293746j, var(E): 0.15311853
-0.0
tensor(17.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 20000/ t/epoch=1.04............. Loss: 0.23029165, mean(E): -19.18228821-0.00502066j, var(E): 0.12514609
-0.0
tensor(17.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 20000/ t/epoch=1.04............. Loss: 0.34129599, mean(E): -19.25072013+0.00678426j, var(E): 0.20644808
-0.0
tensor(17.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 20000/ t/epoch=1.04............. Loss: 0.35181109, mean(E): -19.22260684-0.00269202j, var(E): 0.11097969
-0.0
tensor(17.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 20000/ t/epoch=1.04............. Loss: -0.88100589, mean(E): -19.18749825-0.00039577j, var(E): 0.14853035
-0.0
tensor(17.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 20000/ t/epoch=1.04............. Loss: -0.27913636, mean(E): -19.22067166+0.00497003j, var(E): 0.17126941
-0.0
tensor(17.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 20000/ t/epoch=1.04............. Loss: 0.12276378, mean(E): -19.23604906-0.00314619j, var(E): 0.13659209
-0.0
tensor(17.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 20000/ t/epoch=1.04............. Loss: -0.73323155, mean(E): -19.19901073+0.00848062j, var(E): 0.09786752
-0.0
tensor(17.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 20000/ t/epoch=1.04............. Loss: 0.17220659, mean(E): -19.18240657-0.00721891j, var(E): 0.12227845
-0.0
tensor(17.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 20000/ t/epoch=1.04............. Loss: 0.04424389, mean(E): -19.18672827+0.00335667j, var(E): 0.13073303
-0.0
tensor(17.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 20000/ t/epoch=1.04............. Loss: 0.08162589, mean(E): -19.18673889-0.02381403j, var(E): 0.13730338
-0.0
tensor(17.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 20000/ t/epoch=1.03............. Loss: -0.15629013, mean(E): -19.18085859-0.00654095j, var(E): 0.12466118
-0.0
tensor(17.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 20000/ t/epoch=1.04............. Loss: -0.39036093, mean(E): -19.20158368-0.01077026j, var(E): 0.21227600
-0.0
tensor(17.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 20000/ t/epoch=1.04............. Loss: -0.65402482, mean(E): -19.15584114-0.00205436j, var(E): 0.15946027
-0.0
tensor(17.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 20000/ t/epoch=1.04............. Loss: 0.71101759, mean(E): -19.17960006+0.00083220j, var(E): 0.12475698
-0.0
tensor(17.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 20000/ t/epoch=1.04............. Loss: -0.05140551, mean(E): -19.26452103+0.02110478j, var(E): 0.11414008
-0.0
tensor(17.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 20000/ t/epoch=1.04............. Loss: 0.10996948, mean(E): -19.21901263-0.00858764j, var(E): 0.07960880
-0.0
tensor(17.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 20000/ t/epoch=1.04............. Loss: -0.48547685, mean(E): -19.15652149-0.00865933j, var(E): 0.16883048
-0.0
tensor(17.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 20000/ t/epoch=1.04............. Loss: -0.81988031, mean(E): -19.19835127+0.00667423j, var(E): 0.09290833
-0.0
tensor(17.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 20000/ t/epoch=1.05............. Loss: 0.88443531, mean(E): -19.19859786-0.00987009j, var(E): 0.09963881
-0.0
tensor(17.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 20000/ t/epoch=1.04............. Loss: -0.01469746, mean(E): -19.23604418-0.00301130j, var(E): 0.11931539
-0.0
tensor(17.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 20000/ t/epoch=1.04............. Loss: -0.30134223, mean(E): -19.20997146+0.01243194j, var(E): 0.12692488
-0.0
tensor(17.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 20000/ t/epoch=1.03............. Loss: 0.48991013, mean(E): -19.20617450+0.00242999j, var(E): 0.13860906
-0.0
tensor(17.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 20000/ t/epoch=1.04............. Loss: 0.03665686, mean(E): -19.16821034-0.00518795j, var(E): 0.29834396
-0.0
tensor(17.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 20000/ t/epoch=1.04............. Loss: -0.16753986, mean(E): -19.20170857+0.00180601j, var(E): 0.07561223
-0.0
tensor(17.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 20000/ t/epoch=1.04............. Loss: -0.34053728, mean(E): -19.20415201+0.00128021j, var(E): 0.14291330
-0.0
tensor(17.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 20000/ t/epoch=1.04............. Loss: 0.30164237, mean(E): -19.19829307+0.01510585j, var(E): 0.10785628
-0.0
tensor(17.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 20000/ t/epoch=1.04............. Loss: 0.71428089, mean(E): -19.17364388-0.01060080j, var(E): 0.11417654
-0.0
tensor(17.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 20000/ t/epoch=1.03............. Loss: 0.39382308, mean(E): -19.25032343-0.01083852j, var(E): 0.09580309
-0.0
tensor(17.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 20000/ t/epoch=1.04............. Loss: 0.28071572, mean(E): -19.24293760-0.00200425j, var(E): 0.08100271
-0.0
tensor(17.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 20000/ t/epoch=1.04............. Loss: -0.27857500, mean(E): -19.19097128+0.01008112j, var(E): 0.12038539
-0.0
tensor(17.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 20000/ t/epoch=1.04............. Loss: 0.23569920, mean(E): -19.22748459+0.01495499j, var(E): 0.09916062
-0.0
tensor(17.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 20000/ t/epoch=1.04............. Loss: 0.32757899, mean(E): -19.21429045+0.02076130j, var(E): 0.09086617
-0.0
tensor(17.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 20000/ t/epoch=1.04............. Loss: 0.10654795, mean(E): -19.24170219+0.00159290j, var(E): 0.10221481
-0.0
tensor(17.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 20000/ t/epoch=1.04............. Loss: 0.09659679, mean(E): -19.19152701-0.02025460j, var(E): 0.11045008
-0.0
tensor(17.8445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 20000/ t/epoch=1.04............. Loss: -0.42748726, mean(E): -19.20617446-0.00868720j, var(E): 0.14283464
-0.0
tensor(17.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 20000/ t/epoch=1.03............. Loss: 0.11419473, mean(E): -19.20427473+0.00117041j, var(E): 0.09033119
-0.0
tensor(17.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 20000/ t/epoch=1.04............. Loss: 0.10632761, mean(E): -19.21896314-0.01097228j, var(E): 0.08523309
-0.0
tensor(17.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 20000/ t/epoch=1.04............. Loss: 0.38048287, mean(E): -19.23317144-0.00671728j, var(E): 0.11122512
-0.0
tensor(17.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 20000/ t/epoch=1.04............. Loss: -0.27668199, mean(E): -19.21192757+0.00361238j, var(E): 0.07953627
-0.0
tensor(17.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 20000/ t/epoch=1.04............. Loss: 0.43627231, mean(E): -19.21735694-0.00958329j, var(E): 0.11579417
-0.0
tensor(17.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 20000/ t/epoch=1.04............. Loss: -0.30093424, mean(E): -19.21752606+0.01376569j, var(E): 0.13624774
-0.0
tensor(17.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 20000/ t/epoch=1.04............. Loss: 0.16045889, mean(E): -19.20900296+0.00812080j, var(E): 0.10794918
-0.0
tensor(17.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 20000/ t/epoch=1.04............. Loss: -0.69666908, mean(E): -19.21115272-0.00576384j, var(E): 0.10138218
-0.0
tensor(17.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 20000/ t/epoch=1.04............. Loss: -0.26709267, mean(E): -19.23107125+0.01134346j, var(E): 0.06856386
-0.0
tensor(17.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 20000/ t/epoch=1.04............. Loss: 0.29967849, mean(E): -19.19795754+0.00755630j, var(E): 0.11508880
-0.0
tensor(17.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 20000/ t/epoch=1.04............. Loss: -0.80831419, mean(E): -19.20488180+0.01221103j, var(E): 0.10364385
-0.0
tensor(17.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 20000/ t/epoch=1.04............. Loss: 0.13689301, mean(E): -19.23002835-0.00351663j, var(E): 0.09766419
-0.0
tensor(17.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 20000/ t/epoch=1.04............. Loss: -0.10096752, mean(E): -19.20556485+0.00733800j, var(E): 0.09097801
-0.0
tensor(17.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 20000/ t/epoch=1.03............. Loss: -0.02303069, mean(E): -19.20740231+0.00982219j, var(E): 0.07182198
-0.0
tensor(17.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 20000/ t/epoch=1.04............. Loss: -0.57294001, mean(E): -19.16239930+0.02510762j, var(E): 0.13973051
-0.0
tensor(17.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 20000/ t/epoch=1.04............. Loss: 0.28353174, mean(E): -19.18717472-0.00078839j, var(E): 0.11089955
-0.0
tensor(17.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 20000/ t/epoch=1.04............. Loss: -1.02197528, mean(E): -19.19354648-0.00849721j, var(E): 0.13556043
-0.0
tensor(17.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 20000/ t/epoch=1.04............. Loss: 0.58404791, mean(E): -19.22980570-0.00189775j, var(E): 0.09482441
-0.0
tensor(17.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 20000/ t/epoch=1.04............. Loss: -0.43595883, mean(E): -19.22204401-0.00365645j, var(E): 0.14740683
-0.0
tensor(17.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 20000/ t/epoch=1.04............. Loss: -0.46026206, mean(E): -19.18789617-0.00512701j, var(E): 0.10108116
-0.0
tensor(17.8941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 20000/ t/epoch=1.04............. Loss: 0.50395248, mean(E): -19.20698192-0.00801688j, var(E): 0.16067734
-0.0
tensor(17.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 20000/ t/epoch=1.04............. Loss: -1.10138092, mean(E): -19.21925930+0.00426810j, var(E): 0.09833089
-0.0
tensor(17.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 20000/ t/epoch=1.04............. Loss: 0.39735599, mean(E): -19.21858882-0.00625302j, var(E): 0.14494292
-0.0
tensor(17.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 20000/ t/epoch=1.04............. Loss: -0.05072493, mean(E): -19.18359546-0.01735833j, var(E): 0.09326531
-0.0
tensor(17.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 20000/ t/epoch=1.04............. Loss: -0.62713452, mean(E): -19.20813367+0.00142234j, var(E): 0.13395918
-0.0
tensor(17.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 20000/ t/epoch=1.04............. Loss: 0.13769041, mean(E): -19.20816959+0.01018370j, var(E): 0.09799087
-0.0
tensor(17.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 20000/ t/epoch=1.04............. Loss: -0.15756933, mean(E): -19.21648392+0.00321322j, var(E): 0.12018556
-0.0
tensor(17.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 20000/ t/epoch=1.04............. Loss: -0.23373577, mean(E): -19.19980618+0.00912736j, var(E): 0.06221552
-0.0
tensor(17.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 20000/ t/epoch=1.04............. Loss: -0.15033769, mean(E): -19.21717758+0.00290171j, var(E): 0.07224278
-0.0
tensor(17.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 20000/ t/epoch=1.04............. Loss: 0.27940888, mean(E): -19.21890765+0.00056416j, var(E): 0.07713832
-0.0
tensor(17.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 20000/ t/epoch=1.04............. Loss: 0.45604824, mean(E): -19.21800112-0.00770585j, var(E): 0.11557734
-0.0
tensor(17.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 20000/ t/epoch=1.04............. Loss: 0.38551703, mean(E): -19.19946123+0.00808004j, var(E): 0.09832943
-0.0
tensor(17.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 20000/ t/epoch=1.04............. Loss: -0.55275428, mean(E): -19.24562544+0.00288215j, var(E): 0.10791383
-0.0
tensor(17.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 20000/ t/epoch=1.04............. Loss: 0.40683662, mean(E): -19.22036679+0.01823913j, var(E): 0.07526897
-0.0
tensor(17.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 20000/ t/epoch=1.04............. Loss: -0.34056440, mean(E): -19.21415240+0.00754199j, var(E): 0.10646655
-0.0
tensor(17.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 20000/ t/epoch=1.04............. Loss: 0.26876719, mean(E): -19.21257229+0.00371658j, var(E): 0.08243321
-0.0
tensor(17.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 20000/ t/epoch=1.05............. Loss: 0.01467473, mean(E): -19.20271249+0.00818401j, var(E): 0.10531016
-0.0
tensor(17.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 20000/ t/epoch=1.04............. Loss: -0.33371615, mean(E): -19.20546697+0.01076123j, var(E): 0.12358169
-0.0
tensor(17.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 20000/ t/epoch=1.04............. Loss: 0.38884646, mean(E): -19.15966962+0.00154586j, var(E): 0.11184599
-0.0
tensor(17.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 20000/ t/epoch=1.04............. Loss: 0.02914159, mean(E): -19.21611639-0.00045350j, var(E): 0.10342211
-0.0
tensor(17.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 20000/ t/epoch=1.04............. Loss: 0.14095124, mean(E): -19.25791932-0.00361154j, var(E): 0.11307292
-0.0
tensor(17.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 20000/ t/epoch=1.04............. Loss: 0.44246962, mean(E): -19.19137908+0.00277659j, var(E): 0.11785602
-0.0
tensor(17.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 20000/ t/epoch=1.04............. Loss: -0.36748313, mean(E): -19.18980099-0.01636708j, var(E): 0.16249609
-0.0
tensor(17.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 20000/ t/epoch=1.04............. Loss: -0.42859794, mean(E): -19.23438712+0.01158231j, var(E): 0.09770854
-0.0
tensor(17.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 20000/ t/epoch=1.04............. Loss: 0.18104868, mean(E): -19.21323798+0.01030524j, var(E): 0.11631755
-0.0
tensor(17.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 20000/ t/epoch=1.04............. Loss: -0.46594519, mean(E): -19.20629086-0.00417286j, var(E): 0.12684257
-0.0
tensor(17.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 20000/ t/epoch=1.04............. Loss: -0.22051391, mean(E): -19.17437086+0.00188920j, var(E): 0.07919887
-0.0
tensor(17.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 20000/ t/epoch=1.04............. Loss: -0.39503956, mean(E): -19.19022384+0.00477161j, var(E): 0.13363423
-0.0
tensor(17.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 20000/ t/epoch=1.04............. Loss: -0.24363700, mean(E): -19.22477569-0.00168972j, var(E): 0.08940807
-0.0
tensor(17.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 20000/ t/epoch=1.04............. Loss: 0.32697026, mean(E): -19.22449221+0.00133620j, var(E): 0.11844601
-0.0
tensor(17.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 20000/ t/epoch=1.04............. Loss: -0.11787771, mean(E): -19.21476950+0.00175326j, var(E): 0.06506628
-0.0
tensor(17.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 20000/ t/epoch=1.04............. Loss: 0.12819107, mean(E): -19.19874587-0.00494166j, var(E): 0.08665071
-0.0
tensor(17.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 20000/ t/epoch=1.04............. Loss: 0.12855946, mean(E): -19.16557213-0.00134182j, var(E): 0.11744032
-0.0
tensor(17.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 20000/ t/epoch=1.04............. Loss: -0.04562808, mean(E): -19.19123117+0.00509743j, var(E): 0.11955195
-0.0
tensor(17.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 20000/ t/epoch=1.04............. Loss: -0.10765690, mean(E): -19.21427816-0.00028480j, var(E): 0.07696586
-0.0
tensor(17.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 20000/ t/epoch=1.04............. Loss: 0.21594038, mean(E): -19.21773460-0.00268018j, var(E): 0.07485823
-0.0
tensor(17.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 20000/ t/epoch=1.04............. Loss: -0.27063569, mean(E): -19.18913790-0.02172658j, var(E): 0.08985745
-0.0
tensor(17.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 20000/ t/epoch=1.04............. Loss: -0.57779854, mean(E): -19.20871578+0.01788063j, var(E): 0.13856959
-0.0
tensor(17.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 20000/ t/epoch=1.04............. Loss: 0.45441781, mean(E): -19.17566517+0.00948634j, var(E): 0.09814680
-0.0
tensor(17.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 20000/ t/epoch=1.04............. Loss: -0.65655795, mean(E): -19.21673278+0.00862214j, var(E): 0.08813244
-0.0
tensor(17.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 20000/ t/epoch=1.04............. Loss: 0.27153939, mean(E): -19.23625718-0.01216722j, var(E): 0.07990711
-0.0
tensor(17.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 20000/ t/epoch=1.04............. Loss: -0.49495761, mean(E): -19.23636839-0.02300412j, var(E): 0.13365507
-0.0
tensor(17.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 20000/ t/epoch=1.04............. Loss: 0.41314075, mean(E): -19.25799583-0.01852592j, var(E): 0.06561595
-0.0
tensor(17.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 20000/ t/epoch=1.03............. Loss: -0.26974265, mean(E): -19.25197837-0.00572623j, var(E): 0.11312090
-0.0
tensor(17.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 20000/ t/epoch=1.04............. Loss: -0.06887627, mean(E): -19.20619626+0.00233493j, var(E): 0.07536203
-0.0
tensor(17.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 20000/ t/epoch=1.03............. Loss: 0.28204244, mean(E): -19.22339793-0.00680244j, var(E): 0.08887237
-0.0
tensor(17.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 20000/ t/epoch=1.04............. Loss: -0.85177627, mean(E): -19.18646594-0.00230075j, var(E): 0.15966093
-0.0
tensor(17.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 20000/ t/epoch=1.04............. Loss: -0.12212524, mean(E): -19.20954697-0.00209065j, var(E): 0.09874861
-0.0
tensor(17.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 20000/ t/epoch=1.04............. Loss: -0.63562854, mean(E): -19.20361908+0.00593214j, var(E): 0.07666095
-0.0
tensor(17.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 20000/ t/epoch=1.04............. Loss: 0.55144055, mean(E): -19.20116490+0.00452732j, var(E): 0.06322533
-0.0
tensor(17.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 20000/ t/epoch=1.04............. Loss: -0.20848673, mean(E): -19.22546377+0.00077768j, var(E): 0.06707530
-0.0
tensor(17.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 20000/ t/epoch=1.04............. Loss: -0.15686958, mean(E): -19.25126036-0.00200374j, var(E): 0.09304348
-0.0
tensor(17.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 20000/ t/epoch=1.04............. Loss: 0.38369411, mean(E): -19.18828763-0.00835753j, var(E): 0.14215559
-0.0
tensor(17.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 20000/ t/epoch=1.04............. Loss: -0.37865475, mean(E): -19.22253499-0.00387205j, var(E): 0.14016018
-0.0
tensor(17.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 20000/ t/epoch=1.04............. Loss: 0.21239235, mean(E): -19.19636644+0.00282723j, var(E): 0.17700978
-0.0
tensor(17.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 20000/ t/epoch=1.04............. Loss: -0.18289016, mean(E): -19.22478580-0.01356637j, var(E): 0.09464654
-0.0
tensor(17.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 20000/ t/epoch=1.04............. Loss: -0.84796747, mean(E): -19.16999660-0.01062834j, var(E): 0.09049376
-0.0
tensor(17.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 20000/ t/epoch=1.04............. Loss: 0.59787175, mean(E): -19.21797246-0.00106240j, var(E): 0.07243326
-0.0
tensor(17.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 20000/ t/epoch=1.04............. Loss: -0.09887731, mean(E): -19.22393315+0.00608721j, var(E): 0.09041239
-0.0
tensor(18.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 20000/ t/epoch=1.04............. Loss: -0.48925073, mean(E): -19.20834390+0.00260185j, var(E): 0.08889532
-0.0
tensor(18.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 20000/ t/epoch=1.04............. Loss: 0.20191351, mean(E): -19.20029146-0.00690283j, var(E): 0.11649436
-0.0
tensor(18.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 20000/ t/epoch=1.04............. Loss: -0.70719049, mean(E): -19.22968910+0.00519675j, var(E): 0.08827668
-0.0
tensor(18.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 20000/ t/epoch=1.04............. Loss: 0.04395636, mean(E): -19.21654358-0.00125157j, var(E): 0.06080070
-0.0
tensor(18.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 20000/ t/epoch=1.04............. Loss: 0.09967021, mean(E): -19.21622753+0.00048162j, var(E): 0.06294221
-0.0
tensor(18.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 20000/ t/epoch=1.03............. Loss: 0.15083461, mean(E): -19.20039298+0.00537750j, var(E): 0.09450015
-0.0
tensor(18.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 20000/ t/epoch=1.04............. Loss: -0.41272951, mean(E): -19.27828377-0.01309553j, var(E): 0.13275720
-0.0
tensor(18.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 20000/ t/epoch=1.04............. Loss: -0.22010592, mean(E): -19.21983792-0.00587619j, var(E): 0.12922744
-0.0
tensor(18.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 20000/ t/epoch=1.04............. Loss: 0.02042854, mean(E): -19.21388840-0.00207116j, var(E): 0.09108907
-0.0
tensor(18.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 20000/ t/epoch=1.04............. Loss: 0.00035422, mean(E): -19.22632910+0.00396796j, var(E): 0.09910919
-0.0
tensor(18.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 20000/ t/epoch=1.04............. Loss: -0.50824169, mean(E): -19.23056476-0.01031355j, var(E): 0.08849823
-0.0
tensor(18.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 20000/ t/epoch=1.04............. Loss: 0.01660071, mean(E): -19.20928330-0.01342047j, var(E): 0.08421072
-0.0
tensor(18.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 20000/ t/epoch=1.04............. Loss: -0.03047725, mean(E): -19.21609566+0.01112969j, var(E): 0.07481758
-0.0
tensor(18.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 20000/ t/epoch=1.04............. Loss: 0.09082716, mean(E): -19.21913845+0.00157092j, var(E): 0.11645593
-0.0
tensor(18.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 20000/ t/epoch=1.05............. Loss: 0.04050665, mean(E): -19.18402643+0.00328452j, var(E): 0.11979659
-0.0
tensor(18.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 20000/ t/epoch=1.04............. Loss: 0.51327310, mean(E): -19.22993530+0.01251263j, var(E): 0.07105095
-0.0
tensor(18.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 20000/ t/epoch=1.04............. Loss: -0.08464432, mean(E): -19.22124654-0.00172248j, var(E): 0.08447505
-0.0
tensor(18.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 20000/ t/epoch=1.04............. Loss: -0.03876932, mean(E): -19.18912448+0.01069269j, var(E): 0.13256735
-0.0
tensor(18.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 20000/ t/epoch=1.04............. Loss: 0.03104296, mean(E): -19.19997161-0.00252420j, var(E): 0.11957434
-0.0
tensor(18.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 20000/ t/epoch=1.05............. Loss: -0.23409467, mean(E): -19.20447294+0.01206001j, var(E): 0.12619571
-0.0
tensor(18.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 20000/ t/epoch=1.05............. Loss: -0.57766555, mean(E): -19.22429369-0.00150640j, var(E): 0.11434852
-0.0
tensor(18.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 20000/ t/epoch=1.05............. Loss: 0.27472695, mean(E): -19.23317265+0.01392737j, var(E): 0.09787763
-0.0
tensor(18.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 20000/ t/epoch=1.06............. Loss: 0.00713076, mean(E): -19.23946637+0.00240565j, var(E): 0.09667028
-0.0
tensor(18.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 20000/ t/epoch=1.04............. Loss: 0.08532823, mean(E): -19.22540425-0.01695848j, var(E): 0.07333211
-0.0
tensor(18.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 20000/ t/epoch=1.05............. Loss: -0.20691987, mean(E): -19.21636441+0.01276961j, var(E): 0.08377735
-0.0
tensor(18.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 20000/ t/epoch=1.05............. Loss: 0.07009770, mean(E): -19.20688126-0.00464561j, var(E): 0.06825875
-0.0
tensor(18.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 20000/ t/epoch=1.04............. Loss: -0.39930620, mean(E): -19.19214288-0.00098161j, var(E): 0.12183154
-0.0
tensor(18.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 20000/ t/epoch=1.04............. Loss: -0.13126771, mean(E): -19.21582312-0.00204211j, var(E): 0.11122180
-0.0
tensor(18.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 20000/ t/epoch=1.04............. Loss: 0.21215020, mean(E): -19.20833039+0.00872872j, var(E): 0.10893668
-0.0
tensor(18.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 20000/ t/epoch=1.05............. Loss: -0.53899752, mean(E): -19.21675222+0.00095317j, var(E): 0.11319880
-0.0
tensor(18.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 20000/ t/epoch=1.05............. Loss: -0.57147669, mean(E): -19.17280340+0.00926299j, var(E): 0.11441828
-0.0
tensor(18.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 20000/ t/epoch=1.04............. Loss: -0.01085985, mean(E): -19.17256669-0.00202631j, var(E): 0.13789624
-0.0
tensor(18.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 20000/ t/epoch=1.04............. Loss: 0.15471228, mean(E): -19.21088025-0.00109487j, var(E): 0.08869108
-0.0
tensor(18.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 20000/ t/epoch=1.04............. Loss: -0.12021342, mean(E): -19.20173401+0.00348198j, var(E): 0.05747822
-0.0
tensor(18.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 20000/ t/epoch=1.05............. Loss: 0.07372185, mean(E): -19.22399843-0.00851747j, var(E): 0.06023906
-0.0
tensor(18.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 20000/ t/epoch=1.05............. Loss: -0.00096836, mean(E): -19.22534275-0.00085170j, var(E): 0.06486539
-0.0
tensor(18.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 20000/ t/epoch=1.04............. Loss: -0.21081389, mean(E): -19.19545881-0.00592179j, var(E): 0.07499942
-0.0
tensor(18.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 20000/ t/epoch=1.05............. Loss: 0.15548489, mean(E): -19.20903801-0.00968729j, var(E): 0.05953364
-0.0
tensor(18.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 20000/ t/epoch=1.05............. Loss: 0.29987782, mean(E): -19.18608063-0.00784495j, var(E): 0.08573597
-0.0
tensor(18.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 20000/ t/epoch=1.05............. Loss: -0.35914343, mean(E): -19.19130922+0.00011039j, var(E): 0.08614448
-0.0
tensor(18.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 20000/ t/epoch=1.05............. Loss: 0.30267094, mean(E): -19.23217757-0.00810784j, var(E): 0.07664531
-0.0
tensor(18.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 20000/ t/epoch=1.04............. Loss: 0.70788400, mean(E): -19.22513778-0.00383226j, var(E): 0.12861044
-0.0
tensor(18.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 20000/ t/epoch=1.05............. Loss: -0.46411587, mean(E): -19.22196834+0.00064751j, var(E): 0.08888971
-0.0
tensor(18.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 20000/ t/epoch=1.04............. Loss: 0.12344913, mean(E): -19.19929274-0.01076371j, var(E): 0.08134562
-0.0
tensor(18.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 20000/ t/epoch=1.05............. Loss: -0.45456639, mean(E): -19.16655262+0.00374085j, var(E): 0.08520903
-0.0
tensor(18.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 20000/ t/epoch=1.04............. Loss: 0.11406102, mean(E): -19.21048116-0.00551165j, var(E): 0.08120832
-0.0
tensor(18.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 20000/ t/epoch=1.05............. Loss: -0.08690718, mean(E): -19.23249911-0.00712785j, var(E): 0.08911130
-0.0
tensor(18.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 20000/ t/epoch=1.05............. Loss: -0.49472643, mean(E): -19.24534703+0.00339254j, var(E): 0.09280305
-0.0
tensor(18.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 20000/ t/epoch=1.05............. Loss: 0.40140426, mean(E): -19.24575509+0.01653631j, var(E): 0.09274655
-0.0
tensor(18.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 20000/ t/epoch=1.05............. Loss: -0.78031801, mean(E): -19.19397635+0.01752748j, var(E): 0.08317707
-0.0
tensor(18.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 20000/ t/epoch=1.05............. Loss: 0.30275325, mean(E): -19.21047277-0.00912826j, var(E): 0.08313065
-0.0
tensor(18.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 20000/ t/epoch=1.05............. Loss: -1.00855007, mean(E): -19.21825991+0.01607615j, var(E): 0.11299175
-0.0
tensor(18.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 20000/ t/epoch=1.05............. Loss: 0.02762332, mean(E): -19.22523736+0.00605555j, var(E): 0.06969715
-0.0
tensor(18.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 20000/ t/epoch=1.05............. Loss: -0.31928494, mean(E): -19.23119361+0.00599634j, var(E): 0.10451558
-0.0
tensor(18.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 20000/ t/epoch=1.05............. Loss: 0.51727024, mean(E): -19.24000507+0.00349644j, var(E): 0.07381286
-0.0
tensor(18.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 20000/ t/epoch=1.04............. Loss: 0.06563441, mean(E): -19.24352512-0.00077514j, var(E): 0.10809615
-0.0
tensor(18.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 20000/ t/epoch=1.05............. Loss: 0.19391102, mean(E): -19.23784983-0.00307785j, var(E): 0.06743681
-0.0
tensor(18.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 20000/ t/epoch=1.05............. Loss: 0.46703432, mean(E): -19.23620535-0.00014178j, var(E): 0.08550529
-0.0
tensor(18.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 20000/ t/epoch=1.05............. Loss: 0.12127693, mean(E): -19.25140580-0.00057822j, var(E): 0.05538085
-0.0
tensor(18.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 20000/ t/epoch=1.04............. Loss: 0.20021323, mean(E): -19.22436735+0.00302978j, var(E): 0.07281144
-0.0
tensor(18.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 20000/ t/epoch=1.04............. Loss: 0.42430949, mean(E): -19.21634727-0.00084469j, var(E): 0.05527809
-0.0
tensor(18.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 20000/ t/epoch=1.04............. Loss: 0.03749263, mean(E): -19.24702639+0.00184380j, var(E): 0.07887722
-0.0
tensor(18.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 20000/ t/epoch=1.05............. Loss: -0.19085541, mean(E): -19.21275737-0.00394472j, var(E): 0.05634879
-0.0
tensor(18.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 20000/ t/epoch=1.05............. Loss: 0.06624554, mean(E): -19.20684582+0.00621712j, var(E): 0.09629020
-0.0
tensor(18.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 20000/ t/epoch=1.04............. Loss: 0.33052343, mean(E): -19.22731101-0.00219172j, var(E): 0.07995913
-0.0
tensor(18.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 20000/ t/epoch=1.04............. Loss: -0.40568213, mean(E): -19.19380515-0.00209031j, var(E): 0.09381173
-0.0
tensor(18.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 20000/ t/epoch=1.05............. Loss: 0.03541684, mean(E): -19.22453613+0.00214643j, var(E): 0.06585468
-0.0
tensor(18.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 20000/ t/epoch=1.04............. Loss: -0.22800678, mean(E): -19.22556345+0.01267724j, var(E): 0.06564474
-0.0
tensor(18.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 20000/ t/epoch=1.05............. Loss: -0.17851036, mean(E): -19.20621190+0.00062916j, var(E): 0.10208572
-0.0
tensor(18.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 20000/ t/epoch=1.05............. Loss: -0.38830654, mean(E): -19.21915494+0.00317735j, var(E): 0.07974618
-0.0
tensor(18.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 20000/ t/epoch=1.05............. Loss: -0.12590712, mean(E): -19.23797206+0.00023549j, var(E): 0.06120034
-0.0
tensor(18.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 20000/ t/epoch=1.05............. Loss: 0.08353021, mean(E): -19.23923628-0.00113489j, var(E): 0.06564099
-0.0
tensor(18.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 20000/ t/epoch=1.04............. Loss: -0.06538437, mean(E): -19.22531917-0.00254718j, var(E): 0.07434591
-0.0
tensor(18.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 20000/ t/epoch=1.05............. Loss: 0.36387163, mean(E): -19.22832374-0.00782051j, var(E): 0.05009844
-0.0
tensor(18.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 20000/ t/epoch=1.05............. Loss: -0.12798782, mean(E): -19.21884961+0.01225788j, var(E): 0.07435832
-0.0
tensor(18.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 20000/ t/epoch=1.05............. Loss: 0.03614388, mean(E): -19.23246576+0.00847464j, var(E): 0.06316574
-0.0
tensor(18.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 20000/ t/epoch=1.05............. Loss: 0.21274259, mean(E): -19.20843968-0.00943730j, var(E): 0.10156179
-0.0
tensor(18.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 20000/ t/epoch=1.04............. Loss: 0.42537735, mean(E): -19.21262814-0.00213087j, var(E): 0.06630952
-0.0
tensor(18.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 20000/ t/epoch=1.05............. Loss: -0.57986981, mean(E): -19.22303604-0.00107193j, var(E): 0.06752029
-0.0
tensor(18.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 20000/ t/epoch=1.05............. Loss: -0.19430277, mean(E): -19.21595813+0.00109593j, var(E): 0.03601242
-0.0
tensor(18.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 20000/ t/epoch=1.05............. Loss: 0.04586526, mean(E): -19.21550144-0.00246196j, var(E): 0.05083795
-0.0
tensor(18.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 20000/ t/epoch=1.05............. Loss: -0.05947647, mean(E): -19.21142036+0.00279837j, var(E): 0.07053813
-0.0
tensor(18.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 20000/ t/epoch=1.05............. Loss: -0.10729687, mean(E): -19.22421349+0.01092797j, var(E): 0.06018762
-0.0
tensor(18.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 20000/ t/epoch=1.04............. Loss: -0.14816804, mean(E): -19.22711161-0.00653608j, var(E): 0.07424681
-0.0
tensor(18.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 20000/ t/epoch=1.05............. Loss: -0.14595031, mean(E): -19.24030085-0.00731586j, var(E): 0.06969164
-0.0
tensor(18.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 20000/ t/epoch=1.05............. Loss: 0.07777986, mean(E): -19.23360657+0.00930568j, var(E): 0.04943401
-0.0
tensor(18.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 20000/ t/epoch=1.04............. Loss: 0.01002005, mean(E): -19.21125398+0.01086813j, var(E): 0.13260997
-0.0
tensor(18.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 20000/ t/epoch=1.05............. Loss: -0.22778586, mean(E): -19.18052094-0.00683529j, var(E): 0.14143868
-0.0
tensor(18.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 20000/ t/epoch=1.05............. Loss: 0.15912823, mean(E): -19.20636252+0.00448440j, var(E): 0.07549024
-0.0
tensor(18.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 20000/ t/epoch=1.05............. Loss: -0.20703131, mean(E): -19.22155148-0.00900759j, var(E): 0.13719079
-0.0
tensor(18.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 20000/ t/epoch=1.04............. Loss: 0.05893572, mean(E): -19.23337301-0.00459801j, var(E): 0.10383220
-0.0
tensor(18.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 20000/ t/epoch=1.04............. Loss: 0.09704106, mean(E): -19.19153293+0.00244979j, var(E): 0.07831263
-0.0
tensor(18.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 20000/ t/epoch=1.04............. Loss: 0.10779732, mean(E): -19.21844060+0.00548963j, var(E): 0.07911226
-0.0
tensor(18.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 20000/ t/epoch=1.04............. Loss: -0.07714182, mean(E): -19.20670805+0.00646064j, var(E): 0.05809089
-0.0
tensor(18.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 20000/ t/epoch=1.04............. Loss: -0.19789189, mean(E): -19.19321890+0.00255554j, var(E): 0.08693282
-0.0
tensor(18.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 20000/ t/epoch=1.04............. Loss: 0.17983239, mean(E): -19.23272359-0.00706810j, var(E): 0.14791356
-0.0
tensor(18.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 20000/ t/epoch=1.05............. Loss: 0.16226608, mean(E): -19.22078871-0.01158053j, var(E): 0.09463473
-0.0
tensor(18.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 20000/ t/epoch=1.05............. Loss: -0.46708970, mean(E): -19.19882014+0.00427889j, var(E): 0.08029487
-0.0
tensor(18.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 20000/ t/epoch=1.05............. Loss: -0.16408126, mean(E): -19.22233284+0.00425831j, var(E): 0.08842043
-0.0
tensor(18.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 20000/ t/epoch=1.04............. Loss: 0.37221244, mean(E): -19.21612458-0.00036194j, var(E): 0.06081315
-0.0
tensor(18.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 20000/ t/epoch=1.05............. Loss: -0.35041880, mean(E): -19.24006927-0.01283783j, var(E): 0.10280379
-0.0
tensor(18.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 20000/ t/epoch=1.05............. Loss: -0.30713713, mean(E): -19.20828126-0.00294956j, var(E): 0.11065079
-0.0
tensor(18.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 20000/ t/epoch=1.04............. Loss: 0.17471142, mean(E): -19.21700411-0.00348863j, var(E): 0.07131311
-0.0
tensor(18.1460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 20000/ t/epoch=1.05............. Loss: 0.00968074, mean(E): -19.20147129+0.01252366j, var(E): 0.06420633
-0.0
tensor(18.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 20000/ t/epoch=1.05............. Loss: -0.08646176, mean(E): -19.19722546+0.00460226j, var(E): 0.07300607
-0.0
tensor(18.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 20000/ t/epoch=1.05............. Loss: -0.39475575, mean(E): -19.21066671+0.00526005j, var(E): 0.08541269
-0.0
tensor(18.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 20000/ t/epoch=1.05............. Loss: 0.61444468, mean(E): -19.25517455+0.00573374j, var(E): 0.06042682
-0.0
tensor(18.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 20000/ t/epoch=1.05............. Loss: 0.10093195, mean(E): -19.21457581+0.00293530j, var(E): 0.10018451
-0.0
tensor(18.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 20000/ t/epoch=1.05............. Loss: -0.06962869, mean(E): -19.19001125-0.00311977j, var(E): 0.06629566
-0.0
tensor(18.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 20000/ t/epoch=1.04............. Loss: 0.07184899, mean(E): -19.21743138+0.00137608j, var(E): 0.08991931
-0.0
tensor(18.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 20000/ t/epoch=1.05............. Loss: 0.15457027, mean(E): -19.23162189+0.00402036j, var(E): 0.06291054
-0.0
tensor(18.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 20000/ t/epoch=1.05............. Loss: 0.07230122, mean(E): -19.24590561-0.00273241j, var(E): 0.11813895
-0.0
tensor(18.1581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 20000/ t/epoch=1.05............. Loss: -0.12197842, mean(E): -19.21337424-0.00630791j, var(E): 0.07503030
-0.0
tensor(18.1606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 20000/ t/epoch=1.05............. Loss: 0.04515556, mean(E): -19.20638417+0.00783446j, var(E): 0.08347755
-0.0
tensor(18.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 20000/ t/epoch=1.05............. Loss: 0.13084356, mean(E): -19.24262604-0.00045915j, var(E): 0.07000228
-0.0
tensor(18.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 20000/ t/epoch=1.04............. Loss: 0.31372315, mean(E): -19.22983400+0.00330884j, var(E): 0.11335967
-0.0
tensor(18.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 20000/ t/epoch=1.05............. Loss: 0.03839056, mean(E): -19.22353201+0.00221774j, var(E): 0.06292240
-0.0
tensor(18.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 20000/ t/epoch=1.06............. Loss: 0.05127527, mean(E): -19.22587094+0.01749961j, var(E): 0.06477636
-0.0
tensor(18.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 20000/ t/epoch=1.05............. Loss: 0.08804624, mean(E): -19.22311253+0.00638622j, var(E): 0.04990036
-0.0
tensor(18.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 20000/ t/epoch=1.05............. Loss: -0.24658839, mean(E): -19.21260538+0.01073600j, var(E): 0.07598993
-0.0
tensor(18.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 20000/ t/epoch=1.04............. Loss: 0.49996542, mean(E): -19.22647852-0.00777263j, var(E): 0.05428411
-0.0
tensor(18.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 20000/ t/epoch=1.05............. Loss: 0.44645684, mean(E): -19.20441096+0.00640412j, var(E): 0.07297794
-0.0
tensor(18.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 20000/ t/epoch=1.05............. Loss: -0.46870753, mean(E): -19.22423019-0.00731659j, var(E): 0.09932931
-0.0
tensor(18.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 20000/ t/epoch=1.05............. Loss: -0.29230742, mean(E): -19.22408789-0.00117901j, var(E): 0.05780738
-0.0
tensor(18.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 20000/ t/epoch=1.05............. Loss: 0.05990458, mean(E): -19.20897558-0.00325621j, var(E): 0.08048787
-0.0
tensor(18.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 20000/ t/epoch=1.05............. Loss: -0.11888676, mean(E): -19.21191627-0.01190956j, var(E): 0.05855222
-0.0
tensor(18.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 20000/ t/epoch=1.05............. Loss: -0.13790145, mean(E): -19.18090738-0.00289025j, var(E): 0.07156131
-0.0
tensor(18.1753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 20000/ t/epoch=1.04............. Loss: 0.08448867, mean(E): -19.22292455-0.00209243j, var(E): 0.04332644
-0.0
tensor(18.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 20000/ t/epoch=1.05............. Loss: 0.10767437, mean(E): -19.22965175-0.01216046j, var(E): 0.08595389
-0.0
tensor(18.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 20000/ t/epoch=1.05............. Loss: -0.20409060, mean(E): -19.21324611-0.00055182j, var(E): 0.05665879
-0.0
tensor(18.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 20000/ t/epoch=1.05............. Loss: 0.10558076, mean(E): -19.21536841-0.00510474j, var(E): 0.07335254
-0.0
tensor(18.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 20000/ t/epoch=1.06............. Loss: 0.35140541, mean(E): -19.18576999-0.00361449j, var(E): 0.05429103
-0.0
tensor(18.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 20000/ t/epoch=1.04............. Loss: -0.06190612, mean(E): -19.17640192-0.00480662j, var(E): 0.09901201
-0.0
tensor(18.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 20000/ t/epoch=1.05............. Loss: -0.15063906, mean(E): -19.20032584+0.01592636j, var(E): 0.07959013
-0.0
tensor(18.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 20000/ t/epoch=1.05............. Loss: 0.06265262, mean(E): -19.22961004+0.00676468j, var(E): 0.08540071
-0.0
tensor(18.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 20000/ t/epoch=1.06............. Loss: -0.53336367, mean(E): -19.21049127+0.00697710j, var(E): 0.05711823
-0.0
tensor(18.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 20000/ t/epoch=1.05............. Loss: -0.00405054, mean(E): -19.24256133+0.00951988j, var(E): 0.06963969
-0.0
tensor(18.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 20000/ t/epoch=1.05............. Loss: -0.02326747, mean(E): -19.19991466+0.01041410j, var(E): 0.07198075
-0.0
tensor(18.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 20000/ t/epoch=1.04............. Loss: 0.10800847, mean(E): -19.22438813-0.00510659j, var(E): 0.06991896
-0.0
tensor(18.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 20000/ t/epoch=1.05............. Loss: -0.22606693, mean(E): -19.23964771-0.00626466j, var(E): 0.07314713
-0.0
tensor(18.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 20000/ t/epoch=1.04............. Loss: 0.32735937, mean(E): -19.21058874-0.00009587j, var(E): 0.06478417
-0.0
tensor(18.1950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 20000/ t/epoch=1.05............. Loss: 0.16143623, mean(E): -19.21471915-0.00126574j, var(E): 0.06693878
-0.0
tensor(18.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 20000/ t/epoch=1.05............. Loss: -0.42574061, mean(E): -19.19127068-0.00798186j, var(E): 0.06659333
-0.0
tensor(18.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 20000/ t/epoch=1.05............. Loss: -0.09033318, mean(E): -19.22062277-0.00664375j, var(E): 0.07282428
-0.0
tensor(18.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 20000/ t/epoch=1.04............. Loss: -0.05709969, mean(E): -19.22362702-0.00255674j, var(E): 0.04856719
-0.0
tensor(18.2009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 20000/ t/epoch=1.05............. Loss: 0.13427123, mean(E): -19.26113570+0.00439631j, var(E): 0.04720967
-0.0
tensor(18.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 20000/ t/epoch=1.05............. Loss: -0.16046976, mean(E): -19.20722110+0.00375519j, var(E): 0.06081432
-0.0
tensor(18.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 20000/ t/epoch=1.05............. Loss: -0.36092649, mean(E): -19.19556010-0.00267292j, var(E): 0.07047278
-0.0
tensor(18.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 20000/ t/epoch=1.05............. Loss: 0.01147449, mean(E): -19.16097129+0.00654379j, var(E): 0.08477654
-0.0
tensor(18.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 20000/ t/epoch=1.05............. Loss: -0.08366145, mean(E): -19.20951128-0.00296795j, var(E): 0.05535348
-0.0
tensor(18.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 20000/ t/epoch=1.05............. Loss: 0.60814318, mean(E): -19.21970889+0.01308557j, var(E): 0.04858751
-0.0
tensor(18.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 20000/ t/epoch=1.05............. Loss: 0.08178145, mean(E): -19.23252244+0.00308160j, var(E): 0.06241598
-0.0
tensor(18.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 20000/ t/epoch=1.05............. Loss: 0.14252609, mean(E): -19.20190191-0.01413722j, var(E): 0.08716040
-0.0
tensor(18.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 20000/ t/epoch=1.04............. Loss: 0.06164059, mean(E): -19.21210198+0.00673044j, var(E): 0.08474753
-0.0
tensor(18.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 20000/ t/epoch=1.05............. Loss: -0.17236126, mean(E): -19.21074928+0.00712650j, var(E): 0.05730281
-0.0
tensor(18.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 20000/ t/epoch=1.05............. Loss: 0.02603171, mean(E): -19.22388715+0.01532985j, var(E): 0.10086151
-0.0
tensor(18.2141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 20000/ t/epoch=1.04............. Loss: 0.54625507, mean(E): -19.23364746-0.00809636j, var(E): 0.09282231
-0.0
tensor(18.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 20000/ t/epoch=1.05............. Loss: -0.03485544, mean(E): -19.18844078-0.00321423j, var(E): 0.10736181
-0.0
tensor(18.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 20000/ t/epoch=1.05............. Loss: 0.13422989, mean(E): -19.22321126+0.00060226j, var(E): 0.06346272
-0.0
tensor(18.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 20000/ t/epoch=1.05............. Loss: 0.03571647, mean(E): -19.20771437-0.00354064j, var(E): 0.05148557
-0.0
tensor(18.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 20000/ t/epoch=1.05............. Loss: -0.30822438, mean(E): -19.22531254+0.00156228j, var(E): 0.04432150
-0.0
tensor(18.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 20000/ t/epoch=1.05............. Loss: -0.43828253, mean(E): -19.24555202+0.01730746j, var(E): 0.05333512
-0.0
tensor(18.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 20000/ t/epoch=1.05............. Loss: 0.14674166, mean(E): -19.20587035+0.00147239j, var(E): 0.04118697
-0.0
tensor(18.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 20000/ t/epoch=1.04............. Loss: -0.04823695, mean(E): -19.24484629+0.00049146j, var(E): 0.07649247
-0.0
tensor(18.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 20000/ t/epoch=1.05............. Loss: -0.18541454, mean(E): -19.21531020-0.00515303j, var(E): 0.04770659
-0.0
tensor(18.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 20000/ t/epoch=1.05............. Loss: 0.04079796, mean(E): -19.20639751+0.00483014j, var(E): 0.07642478
-0.0
tensor(18.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 20000/ t/epoch=1.05............. Loss: 0.25033029, mean(E): -19.24560204-0.00945823j, var(E): 0.08836516
-0.0
tensor(18.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 20000/ t/epoch=1.05............. Loss: -0.33119393, mean(E): -19.22630403-0.00421046j, var(E): 0.07221536
-0.0
tensor(18.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 20000/ t/epoch=1.05............. Loss: 0.13445885, mean(E): -19.20788861-0.00175136j, var(E): 0.08143110
-0.0
tensor(18.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 20000/ t/epoch=1.05............. Loss: -0.46770656, mean(E): -19.22434197-0.00447858j, var(E): 0.07577371
-0.0
tensor(18.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 20000/ t/epoch=1.05............. Loss: 0.16807307, mean(E): -19.25041233-0.00359504j, var(E): 0.05864173
-0.0
tensor(18.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 20000/ t/epoch=1.05............. Loss: 0.30465339, mean(E): -19.20539560-0.01231647j, var(E): 0.05324099
-0.0
tensor(18.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 20000/ t/epoch=1.04............. Loss: -0.25620811, mean(E): -19.23682082-0.00442234j, var(E): 0.06867028
-0.0
tensor(18.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 20000/ t/epoch=1.05............. Loss: -0.02174153, mean(E): -19.21481910+0.00029709j, var(E): 0.10371591
-0.0
tensor(18.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 20000/ t/epoch=1.05............. Loss: -0.26460226, mean(E): -19.16933562-0.00308493j, var(E): 0.08988509
-0.0
tensor(18.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 20000/ t/epoch=1.05............. Loss: -0.02974291, mean(E): -19.20288408-0.00297836j, var(E): 0.04791258
-0.0
tensor(18.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 20000/ t/epoch=1.04............. Loss: -0.30485062, mean(E): -19.19956977-0.00589217j, var(E): 0.08671647
-0.0
tensor(18.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 20000/ t/epoch=1.05............. Loss: 0.38211723, mean(E): -19.22028227-0.00682973j, var(E): 0.06665290
-0.0
tensor(18.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 20000/ t/epoch=1.06............. Loss: 0.01214745, mean(E): -19.24797492+0.00555557j, var(E): 0.06249186
-0.0
tensor(18.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 20000/ t/epoch=1.05............. Loss: -0.20279289, mean(E): -19.20678033+0.00908407j, var(E): 0.05562445
-0.0
tensor(18.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 20000/ t/epoch=1.05............. Loss: -0.07220857, mean(E): -19.22107362-0.00264588j, var(E): 0.07990271
-0.0
tensor(18.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 20000/ t/epoch=1.05............. Loss: 0.17005586, mean(E): -19.23003522+0.00358018j, var(E): 0.06254909
-0.0
tensor(18.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 20000/ t/epoch=1.05............. Loss: -0.08794645, mean(E): -19.20524757+0.00409773j, var(E): 0.08853425
-0.0
tensor(18.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 20000/ t/epoch=1.06............. Loss: -0.02501976, mean(E): -19.22774467-0.00303861j, var(E): 0.06237033
-0.0
tensor(18.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 20000/ t/epoch=1.05............. Loss: 0.04039343, mean(E): -19.22451625-0.00515414j, var(E): 0.06453108
-0.0
tensor(18.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 20000/ t/epoch=1.05............. Loss: -0.05672676, mean(E): -19.24396677+0.00298193j, var(E): 0.06754116
-0.0
tensor(18.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 20000/ t/epoch=1.05............. Loss: 0.49430276, mean(E): -19.22048174+0.00051371j, var(E): 0.08502830
-0.0
tensor(18.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 20000/ t/epoch=1.05............. Loss: -0.02541243, mean(E): -19.21553555-0.00206261j, var(E): 0.05709010
-0.0
tensor(18.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 20000/ t/epoch=1.05............. Loss: -0.14149642, mean(E): -19.18854029-0.00271650j, var(E): 0.07215000
-0.0
tensor(18.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 20000/ t/epoch=1.05............. Loss: -0.21411938, mean(E): -19.22924632+0.00768997j, var(E): 0.06133487
-0.0
tensor(18.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 20000/ t/epoch=1.05............. Loss: 0.09234057, mean(E): -19.23413250+0.01079602j, var(E): 0.04886337
-0.0
tensor(18.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 20000/ t/epoch=1.05............. Loss: -0.05439385, mean(E): -19.20683579-0.00208540j, var(E): 0.04555326
-0.0
tensor(18.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 20000/ t/epoch=1.05............. Loss: -0.46368584, mean(E): -19.20757576-0.00392619j, var(E): 0.08574484
-0.0
tensor(18.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 20000/ t/epoch=1.05............. Loss: 0.35819654, mean(E): -19.21292485+0.00343244j, var(E): 0.07384089
-0.0
tensor(18.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 20000/ t/epoch=1.06............. Loss: -0.26257715, mean(E): -19.23191186+0.00693953j, var(E): 0.08548407
-0.0
tensor(18.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 20000/ t/epoch=1.05............. Loss: -0.16098660, mean(E): -19.19681370-0.01014417j, var(E): 0.07186562
-0.0
tensor(18.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 20000/ t/epoch=1.05............. Loss: 0.05633571, mean(E): -19.20262974+0.00755738j, var(E): 0.08802220
-0.0
tensor(18.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 20000/ t/epoch=1.04............. Loss: -0.03965803, mean(E): -19.20452555+0.00648478j, var(E): 0.08003417
-0.0
tensor(18.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 20000/ t/epoch=1.05............. Loss: 0.12335909, mean(E): -19.20541707-0.00675564j, var(E): 0.07321165
-0.0
tensor(18.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 20000/ t/epoch=1.05............. Loss: -0.09748827, mean(E): -19.22943271+0.00351192j, var(E): 0.08603794
-0.0
tensor(18.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 20000/ t/epoch=1.05............. Loss: 0.27325470, mean(E): -19.23455916-0.01498644j, var(E): 0.07008427
-0.0
tensor(18.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 20000/ t/epoch=1.05............. Loss: -0.09101313, mean(E): -19.24100077+0.00357981j, var(E): 0.06205805
-0.0
tensor(18.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 20000/ t/epoch=1.05............. Loss: -0.49893745, mean(E): -19.21017501+0.00770769j, var(E): 0.06231699
-0.0
tensor(18.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 20000/ t/epoch=1.04............. Loss: -0.08407347, mean(E): -19.21283659+0.00653550j, var(E): 0.06102429
-0.0
tensor(18.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 20000/ t/epoch=1.05............. Loss: -0.10423208, mean(E): -19.21859134-0.00413833j, var(E): 0.03995825
-0.0
tensor(18.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 20000/ t/epoch=1.04............. Loss: 0.31044141, mean(E): -19.23697703+0.00558787j, var(E): 0.04945217
-0.0
tensor(18.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 20000/ t/epoch=1.05............. Loss: -0.04282494, mean(E): -19.22420226+0.01078248j, var(E): 0.04815365
-0.0
tensor(18.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 20000/ t/epoch=1.04............. Loss: -0.00738856, mean(E): -19.19374849+0.00799075j, var(E): 0.08036469
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 20000/ t/epoch=1.05............. Loss: -0.23418306, mean(E): -19.20102996+0.00304713j, var(E): 0.07007902
-0.0
tensor(18.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 20000/ t/epoch=1.05............. Loss: -0.16175073, mean(E): -19.20744618+0.00134833j, var(E): 0.06747747
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 20000/ t/epoch=1.04............. Loss: 0.25997315, mean(E): -19.23865823+0.00742257j, var(E): 0.08557895
-0.0
tensor(18.2707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 20000/ t/epoch=1.05............. Loss: 0.22440975, mean(E): -19.25220005+0.00271220j, var(E): 0.08929409
-0.0
tensor(18.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 20000/ t/epoch=1.05............. Loss: -0.04763659, mean(E): -19.21610678+0.00227437j, var(E): 0.06980503
-0.0
tensor(18.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 20000/ t/epoch=1.05............. Loss: 0.30954315, mean(E): -19.20892699-0.00428813j, var(E): 0.05990169
-0.0
tensor(18.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 20000/ t/epoch=1.05............. Loss: -0.23948157, mean(E): -19.22115248-0.00512245j, var(E): 0.07310668
-0.0
tensor(18.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 20000/ t/epoch=1.05............. Loss: -0.23013997, mean(E): -19.24361336-0.00570858j, var(E): 0.07794963
-0.0
tensor(18.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 20000/ t/epoch=1.05............. Loss: 0.40092410, mean(E): -19.24127201+0.00733320j, var(E): 0.07095572
-0.0
tensor(18.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 20000/ t/epoch=1.05............. Loss: 0.25839437, mean(E): -19.23035600+0.00891389j, var(E): 0.07859935
-0.0
tensor(18.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 20000/ t/epoch=1.05............. Loss: -0.40871963, mean(E): -19.19618739-0.00520800j, var(E): 0.06985561
-0.0
tensor(18.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 20000/ t/epoch=1.05............. Loss: 0.03324062, mean(E): -19.22172995-0.00497111j, var(E): 0.07581112
-0.0
tensor(18.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 20000/ t/epoch=1.04............. Loss: 0.17982975, mean(E): -19.21059361+0.00158893j, var(E): 0.06883373
-0.0
tensor(18.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 20000/ t/epoch=1.05............. Loss: -0.50972560, mean(E): -19.19600964+0.00029463j, var(E): 0.04936744
-0.0
tensor(18.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 20000/ t/epoch=1.05............. Loss: -0.23901659, mean(E): -19.21878829+0.00179507j, var(E): 0.04944846
-0.0
tensor(18.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 20000/ t/epoch=1.05............. Loss: -0.08709321, mean(E): -19.24147228-0.00609370j, var(E): 0.19215513
-0.0
tensor(18.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 20000/ t/epoch=1.05............. Loss: 0.22986275, mean(E): -19.21491984+0.01523718j, var(E): 0.06549540
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 20000/ t/epoch=1.05............. Loss: -0.14411005, mean(E): -19.21498697+0.00214142j, var(E): 0.03707732
-0.0
tensor(18.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 20000/ t/epoch=1.05............. Loss: 0.04082611, mean(E): -19.21293314-0.00523768j, var(E): 0.07807312
-0.0
tensor(18.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 20000/ t/epoch=1.05............. Loss: 0.05585408, mean(E): -19.22128592-0.00616437j, var(E): 0.04857746
-0.0
tensor(18.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 20000/ t/epoch=1.06............. Loss: 0.17670275, mean(E): -19.21440578-0.00653079j, var(E): 0.07065831
-0.0
tensor(18.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 20000/ t/epoch=1.06............. Loss: -0.23154920, mean(E): -19.17460454+0.00550118j, var(E): 0.05921172
-0.0
tensor(18.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 20000/ t/epoch=1.05............. Loss: -0.00498153, mean(E): -19.20417625+0.00128617j, var(E): 0.03743199
-0.0
tensor(18.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 20000/ t/epoch=1.05............. Loss: -0.14673736, mean(E): -19.20302239+0.00662227j, var(E): 0.08718471
-0.0
tensor(18.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 20000/ t/epoch=1.06............. Loss: 0.00927978, mean(E): -19.19917769+0.00320943j, var(E): 0.15443419
-0.0
tensor(18.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 20000/ t/epoch=1.05............. Loss: -0.17729984, mean(E): -19.24430453+0.00886454j, var(E): 0.08057024
-0.0
tensor(18.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 20000/ t/epoch=1.05............. Loss: -0.04058180, mean(E): -19.22757636+0.00413110j, var(E): 0.07962352
-0.0
tensor(18.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 20000/ t/epoch=1.05............. Loss: 0.21071022, mean(E): -19.20461267+0.01090799j, var(E): 0.05884507
-0.0
tensor(18.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 20000/ t/epoch=1.05............. Loss: -0.23899572, mean(E): -19.19568189+0.00225046j, var(E): 0.08250887
-0.0
tensor(18.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 20000/ t/epoch=1.05............. Loss: -0.12193783, mean(E): -19.23250030-0.00168183j, var(E): 0.05903930
-0.0
tensor(18.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 20000/ t/epoch=1.05............. Loss: -0.22442029, mean(E): -19.20834399+0.00481092j, var(E): 0.05556016
-0.0
tensor(18.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 20000/ t/epoch=1.05............. Loss: 0.35359040, mean(E): -19.23454048-0.01069267j, var(E): 0.10288128
-0.0
tensor(18.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 20000/ t/epoch=1.05............. Loss: 0.10058125, mean(E): -19.22652228+0.00290020j, var(E): 0.05249128
-0.0
tensor(18.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 20000/ t/epoch=1.05............. Loss: -0.37662363, mean(E): -19.20949771+0.00191938j, var(E): 0.04666828
-0.0
tensor(18.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 20000/ t/epoch=1.05............. Loss: -0.05255353, mean(E): -19.22289799-0.00387977j, var(E): 0.06265234
-0.0
tensor(18.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 20000/ t/epoch=1.05............. Loss: -0.04062570, mean(E): -19.20668010-0.00558133j, var(E): 0.05057589
-0.0
tensor(18.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 20000/ t/epoch=1.06............. Loss: 0.12506508, mean(E): -19.23431298-0.00007655j, var(E): 0.07644524
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 20000/ t/epoch=1.05............. Loss: -0.08566903, mean(E): -19.20621139-0.00450449j, var(E): 0.07708886
-0.0
tensor(18.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 20000/ t/epoch=1.05............. Loss: 0.32865943, mean(E): -19.21858436+0.00179454j, var(E): 0.06205951
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 20000/ t/epoch=1.05............. Loss: -0.21937056, mean(E): -19.21158108-0.00013130j, var(E): 0.05061489
-0.0
tensor(18.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 20000/ t/epoch=1.06............. Loss: 0.63539434, mean(E): -19.25134264+0.00770425j, var(E): 0.05092747
-0.0
tensor(18.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 20000/ t/epoch=1.04............. Loss: 0.47177005, mean(E): -19.20053101+0.01377500j, var(E): 0.11795671
-0.0
tensor(18.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 20000/ t/epoch=1.05............. Loss: -0.13478009, mean(E): -19.20046149+0.00481915j, var(E): 0.05449108
-0.0
tensor(18.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 20000/ t/epoch=1.05............. Loss: 0.26264248, mean(E): -19.21796211-0.00316511j, var(E): 0.05293987
-0.0
tensor(18.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 20000/ t/epoch=1.05............. Loss: 0.29687353, mean(E): -19.19327831+0.00938673j, var(E): 0.11761410
-0.0
tensor(18.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 20000/ t/epoch=1.05............. Loss: 0.10802471, mean(E): -19.22020565+0.01190551j, var(E): 0.05756522
-0.0
tensor(18.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 20000/ t/epoch=1.06............. Loss: 0.56026769, mean(E): -19.19764257+0.00534636j, var(E): 0.06965718
-0.0
tensor(18.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 20000/ t/epoch=1.05............. Loss: -0.32657525, mean(E): -19.22186227-0.00521315j, var(E): 0.07559136
-0.0
tensor(18.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 20000/ t/epoch=1.06............. Loss: -0.41399189, mean(E): -19.21381802-0.00843956j, var(E): 0.05011116
-0.0
tensor(18.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 20000/ t/epoch=1.05............. Loss: 0.24247073, mean(E): -19.20389046-0.00006059j, var(E): 0.11973047
-0.0
tensor(18.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 20000/ t/epoch=1.05............. Loss: -0.08120779, mean(E): -19.19770883-0.00561335j, var(E): 0.05213873
-0.0
tensor(18.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 20000/ t/epoch=1.04............. Loss: -0.01393681, mean(E): -19.21580462+0.00246954j, var(E): 0.07398890
-0.0
tensor(18.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 20000/ t/epoch=1.05............. Loss: 0.38241911, mean(E): -19.19790601-0.00178721j, var(E): 0.05393603
-0.0
tensor(18.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 20000/ t/epoch=1.05............. Loss: -0.20053608, mean(E): -19.23490227+0.00267933j, var(E): 0.04258204
-0.0
tensor(18.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 20000/ t/epoch=1.05............. Loss: -0.01801301, mean(E): -19.18758220-0.01134236j, var(E): 0.10356840
-0.0
tensor(18.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 20000/ t/epoch=1.05............. Loss: -0.32451572, mean(E): -19.22644311-0.00295815j, var(E): 0.05201587
-0.0
tensor(18.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 20000/ t/epoch=1.05............. Loss: 0.52724998, mean(E): -19.21533378-0.00103630j, var(E): 0.03606654
-0.0
tensor(18.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 20000/ t/epoch=1.05............. Loss: 0.43046553, mean(E): -19.21149713-0.00109263j, var(E): 0.04558947
-0.0
tensor(18.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 20000/ t/epoch=1.05............. Loss: -0.18970906, mean(E): -19.20834346-0.00304401j, var(E): 0.06072407
-0.0
tensor(18.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 20000/ t/epoch=1.06............. Loss: -0.06841002, mean(E): -19.20437998-0.00001781j, var(E): 0.04832930
-0.0
tensor(18.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 20000/ t/epoch=1.05............. Loss: -0.13763506, mean(E): -19.19896645+0.00797940j, var(E): 0.04419497
-0.0
tensor(18.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 20000/ t/epoch=1.05............. Loss: -0.05479041, mean(E): -19.22739609+0.00306946j, var(E): 0.04340036
-0.0
tensor(18.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 20000/ t/epoch=1.04............. Loss: 0.33101284, mean(E): -19.23558127-0.00755164j, var(E): 0.06119499
-0.0
tensor(18.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 20000/ t/epoch=1.05............. Loss: -0.11810385, mean(E): -19.23590717+0.00318807j, var(E): 0.05350314
-0.0
tensor(18.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 20000/ t/epoch=1.05............. Loss: -0.17454266, mean(E): -19.17895789+0.00073696j, var(E): 0.10978695
-0.0
tensor(18.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 20000/ t/epoch=1.05............. Loss: 0.03710889, mean(E): -19.20733384-0.00290759j, var(E): 0.06018433
-0.0
tensor(18.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 20000/ t/epoch=1.04............. Loss: -0.01505569, mean(E): -19.21387253+0.00500096j, var(E): 0.06431522
-0.0
tensor(18.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 20000/ t/epoch=1.05............. Loss: 0.09989449, mean(E): -19.22766390-0.00657715j, var(E): 0.06189147
-0.0
tensor(18.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 20000/ t/epoch=1.05............. Loss: -0.01718581, mean(E): -19.23008954+0.00610535j, var(E): 0.05994524
-0.0
tensor(18.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 20000/ t/epoch=1.05............. Loss: 0.24944352, mean(E): -19.19572671-0.00407356j, var(E): 0.04511533
-0.0
tensor(18.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 20000/ t/epoch=1.05............. Loss: 0.17100007, mean(E): -19.21519629-0.00231956j, var(E): 0.08099682
-0.0
tensor(18.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 20000/ t/epoch=1.05............. Loss: -0.16223743, mean(E): -19.22604792+0.00376032j, var(E): 0.03757272
-0.0
tensor(18.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 20000/ t/epoch=1.05............. Loss: -0.00130607, mean(E): -19.20384540+0.00424796j, var(E): 0.06368793
-0.0
tensor(18.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 20000/ t/epoch=1.04............. Loss: 0.04989234, mean(E): -19.20547096-0.00082168j, var(E): 0.04600735
-0.0
tensor(18.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 20000/ t/epoch=1.04............. Loss: -0.24892700, mean(E): -19.20371172+0.00479976j, var(E): 0.05904838
-0.0
tensor(18.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 20000/ t/epoch=1.05............. Loss: 0.00420946, mean(E): -19.22156690+0.00235004j, var(E): 0.07224541
-0.0
tensor(18.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 20000/ t/epoch=1.05............. Loss: -0.22966281, mean(E): -19.21989879+0.00008939j, var(E): 0.03987440
-0.0
tensor(18.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 20000/ t/epoch=1.05............. Loss: 0.05756692, mean(E): -19.22001548+0.00472700j, var(E): 0.09778710
-0.0
tensor(18.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 20000/ t/epoch=1.05............. Loss: -0.11198968, mean(E): -19.20223909+0.00648995j, var(E): 0.03973485
-0.0
tensor(18.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 20000/ t/epoch=1.05............. Loss: -0.17190023, mean(E): -19.21837878-0.01255130j, var(E): 0.05590642
-0.0
tensor(18.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 20000/ t/epoch=1.05............. Loss: 0.19740153, mean(E): -19.23945368-0.00554120j, var(E): 0.06850854
-0.0
tensor(18.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 20000/ t/epoch=1.05............. Loss: -0.07193289, mean(E): -19.23610978+0.00007416j, var(E): 0.03903307
-0.0
tensor(18.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 20000/ t/epoch=1.06............. Loss: 0.34874145, mean(E): -19.21370019-0.00419670j, var(E): 0.06585688
-0.0
tensor(18.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 20000/ t/epoch=1.04............. Loss: 0.07055384, mean(E): -19.23068820-0.00321892j, var(E): 0.06307716
-0.0
tensor(18.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 20000/ t/epoch=1.05............. Loss: -0.05145330, mean(E): -19.19868279-0.00058689j, var(E): 0.07635623
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 20000/ t/epoch=1.05............. Loss: 0.25502164, mean(E): -19.24170238+0.00273249j, var(E): 0.05261713
-0.0
tensor(18.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 20000/ t/epoch=1.06............. Loss: -0.22851228, mean(E): -19.22845548+0.00410948j, var(E): 0.04690026
-0.0
tensor(18.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 20000/ t/epoch=1.05............. Loss: 0.15314031, mean(E): -19.23559648+0.00248137j, var(E): 0.04925998
-0.0
tensor(18.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 20000/ t/epoch=1.05............. Loss: 0.21768924, mean(E): -19.22992377-0.00823713j, var(E): 0.06194708
-0.0
tensor(18.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 20000/ t/epoch=1.05............. Loss: 0.14203083, mean(E): -19.24088195-0.00590859j, var(E): 0.07189375
-0.0
tensor(18.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 20000/ t/epoch=1.04............. Loss: -0.30194708, mean(E): -19.22550579+0.00012760j, var(E): 0.08464226
-0.0
tensor(18.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 20000/ t/epoch=1.05............. Loss: 0.32985933, mean(E): -19.23696922-0.00171097j, var(E): 0.06121374
-0.0
tensor(18.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 20000/ t/epoch=1.05............. Loss: -0.00153011, mean(E): -19.21128551+0.00578647j, var(E): 0.09199425
-0.0
tensor(18.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 20000/ t/epoch=1.05............. Loss: -0.44129082, mean(E): -19.23515563-0.00160038j, var(E): 0.05452865
-0.0
tensor(18.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 20000/ t/epoch=1.05............. Loss: -0.02405185, mean(E): -19.22139945-0.00217225j, var(E): 0.05109251
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 20000/ t/epoch=1.06............. Loss: 0.32125545, mean(E): -19.20188607+0.00538884j, var(E): 0.06275644
-0.0
tensor(18.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 20000/ t/epoch=1.05............. Loss: -0.47099325, mean(E): -19.22565146+0.00369745j, var(E): 0.04073150
-0.0
tensor(18.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 20000/ t/epoch=1.05............. Loss: -0.11530473, mean(E): -19.20363976-0.00374995j, var(E): 0.06856026
-0.0
tensor(18.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 20000/ t/epoch=1.05............. Loss: 0.29243636, mean(E): -19.20782616-0.00052464j, var(E): 0.04944310
-0.0
tensor(18.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 20000/ t/epoch=1.06............. Loss: -0.07873034, mean(E): -19.22602536+0.00161647j, var(E): 0.06492187
-0.0
tensor(18.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 20000/ t/epoch=1.05............. Loss: 0.00873241, mean(E): -19.20610221-0.00750548j, var(E): 0.04267128
-0.0
tensor(18.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 20000/ t/epoch=1.05............. Loss: 0.28095864, mean(E): -19.24114444+0.00410929j, var(E): 0.04344219
-0.0
tensor(18.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 20000/ t/epoch=1.05............. Loss: -0.16171905, mean(E): -19.22474571-0.00107862j, var(E): 0.06156326
-0.0
tensor(18.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 20000/ t/epoch=1.05............. Loss: -0.09773161, mean(E): -19.23408326+0.00530452j, var(E): 0.08117323
-0.0
tensor(18.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 20000/ t/epoch=1.05............. Loss: 0.18694365, mean(E): -19.21176298-0.00304198j, var(E): 0.04929087
-0.0
tensor(18.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 20000/ t/epoch=1.04............. Loss: -0.20320326, mean(E): -19.22948039-0.00243644j, var(E): 0.03441573
-0.0
tensor(18.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 20000/ t/epoch=1.05............. Loss: 0.07663723, mean(E): -19.20292674-0.00549759j, var(E): 0.11255670
-0.0
tensor(18.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 20000/ t/epoch=1.05............. Loss: -0.35092510, mean(E): -19.23500800-0.00063908j, var(E): 0.03848060
-0.0
tensor(18.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 20000/ t/epoch=1.05............. Loss: -0.32792589, mean(E): -19.24898226-0.00061635j, var(E): 0.13498115
-0.0
tensor(18.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 20000/ t/epoch=1.05............. Loss: 0.10197297, mean(E): -19.21406243+0.00242714j, var(E): 0.03851464
-0.0
tensor(18.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 20000/ t/epoch=1.06............. Loss: 0.18916109, mean(E): -19.22790826-0.00914501j, var(E): 0.04792912
-0.0
tensor(18.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 20000/ t/epoch=1.05............. Loss: 0.05431437, mean(E): -19.23546888+0.00249619j, var(E): 0.06183550
-0.0
tensor(18.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 20000/ t/epoch=1.05............. Loss: 0.04384240, mean(E): -19.19965183+0.00796912j, var(E): 0.04635163
-0.0
tensor(18.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 20000/ t/epoch=1.05............. Loss: -0.33505870, mean(E): -19.19421533-0.00089977j, var(E): 0.05005741
-0.0
tensor(18.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 20000/ t/epoch=1.04............. Loss: 0.21442558, mean(E): -19.20754889-0.01031973j, var(E): 0.04435942
-0.0
tensor(18.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 20000/ t/epoch=1.05............. Loss: -0.00913474, mean(E): -19.22036140-0.00381465j, var(E): 0.03734380
-0.0
tensor(18.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 20000/ t/epoch=1.05............. Loss: -0.13091876, mean(E): -19.21822571-0.01898893j, var(E): 0.03513952
-0.0
tensor(18.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 20000/ t/epoch=1.05............. Loss: 0.29102272, mean(E): -19.22350004+0.00322440j, var(E): 0.03857320
-0.0
tensor(18.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 20000/ t/epoch=1.06............. Loss: -0.00651374, mean(E): -19.22347707-0.00316730j, var(E): 0.05564178
-0.0
tensor(18.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 20000/ t/epoch=1.05............. Loss: -0.26167636, mean(E): -19.24918775-0.00113551j, var(E): 0.04592793
-0.0
tensor(18.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 20000/ t/epoch=1.05............. Loss: -0.10328505, mean(E): -19.20732040+0.00989592j, var(E): 0.04021275
-0.0
tensor(18.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 20000/ t/epoch=1.05............. Loss: 0.28598505, mean(E): -19.21229512+0.00365022j, var(E): 0.03344138
-0.0
tensor(18.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 20000/ t/epoch=1.05............. Loss: 0.02911602, mean(E): -19.23252282-0.00387792j, var(E): 0.05084479
-0.0
tensor(18.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 20000/ t/epoch=1.06............. Loss: -0.14534949, mean(E): -19.21007585+0.01037306j, var(E): 0.04180687
-0.0
tensor(18.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 20000/ t/epoch=1.05............. Loss: -0.09915665, mean(E): -19.22036434+0.00011981j, var(E): 0.05453969
-0.0
tensor(18.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 20000/ t/epoch=1.05............. Loss: -0.29211683, mean(E): -19.20489691+0.01461282j, var(E): 0.04211971
-0.0
tensor(18.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 20000/ t/epoch=1.05............. Loss: 0.12492395, mean(E): -19.23949544+0.00313436j, var(E): 0.04402235
-0.0
tensor(18.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 20000/ t/epoch=1.04............. Loss: 0.06688221, mean(E): -19.22175872-0.00384750j, var(E): 0.04949095
-0.0
tensor(18.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 20000/ t/epoch=1.06............. Loss: 0.05543617, mean(E): -19.21137188-0.00342300j, var(E): 0.05760334
-0.0
tensor(18.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 20000/ t/epoch=1.05............. Loss: -0.49351057, mean(E): -19.22401565+0.01813630j, var(E): 0.03464523
-0.0
tensor(18.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 20000/ t/epoch=1.05............. Loss: 0.22031546, mean(E): -19.24065152-0.00617669j, var(E): 0.04638174
-0.0
tensor(18.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 20000/ t/epoch=1.05............. Loss: 0.41287867, mean(E): -19.24530926-0.00983805j, var(E): 0.08426133
-0.0
tensor(18.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 20000/ t/epoch=1.05............. Loss: 0.34332892, mean(E): -19.25169464+0.00132274j, var(E): 0.05132593
-0.0
tensor(18.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 20000/ t/epoch=1.05............. Loss: -0.08738053, mean(E): -19.23475847-0.00507151j, var(E): 0.03814847
-0.0
tensor(18.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 20000/ t/epoch=1.04............. Loss: -0.07775881, mean(E): -19.20058551+0.00746300j, var(E): 0.07169024
-0.0
tensor(18.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 20000/ t/epoch=1.05............. Loss: -0.53164446, mean(E): -19.20887394+0.00664043j, var(E): 0.04978467
-0.0
tensor(18.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 20000/ t/epoch=1.04............. Loss: 0.23266436, mean(E): -19.20878475-0.00076433j, var(E): 0.05143757
-0.0
tensor(18.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 20000/ t/epoch=1.05............. Loss: 0.12164334, mean(E): -19.21149709+0.00096745j, var(E): 0.09931502
-0.0
tensor(18.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 20000/ t/epoch=1.05............. Loss: 0.19969065, mean(E): -19.24373479-0.00772128j, var(E): 0.09285347
-0.0
tensor(18.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 20000/ t/epoch=1.05............. Loss: 0.19390073, mean(E): -19.21386410+0.00425732j, var(E): 0.04788084
-0.0
tensor(18.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 20000/ t/epoch=1.05............. Loss: -0.53924180, mean(E): -19.21221286-0.00653454j, var(E): 0.05935239
-0.0
tensor(18.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 20000/ t/epoch=1.05............. Loss: -0.11371774, mean(E): -19.21051800+0.00167652j, var(E): 0.05939019
-0.0
tensor(18.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 20000/ t/epoch=1.05............. Loss: 0.14010590, mean(E): -19.23085404+0.00356133j, var(E): 0.08839651
-0.0
tensor(18.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 20000/ t/epoch=1.04............. Loss: -0.10578411, mean(E): -19.22442512-0.01495865j, var(E): 0.03458287
-0.0
tensor(18.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 20000/ t/epoch=1.05............. Loss: -0.20570515, mean(E): -19.21076621-0.00614091j, var(E): 0.04800210
-0.0
tensor(18.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 20000/ t/epoch=1.04............. Loss: 0.05909615, mean(E): -19.21125760-0.00547782j, var(E): 0.05073307
-0.0
tensor(18.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 20000/ t/epoch=1.05............. Loss: -0.06540075, mean(E): -19.21464811-0.00183806j, var(E): 0.05908623
-0.0
tensor(18.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 20000/ t/epoch=1.05............. Loss: 0.31064379, mean(E): -19.22460642-0.00059787j, var(E): 0.06574075
-0.0
tensor(18.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 20000/ t/epoch=1.04............. Loss: -0.25908996, mean(E): -19.20853450-0.00809228j, var(E): 0.05561553
-0.0
tensor(18.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 20000/ t/epoch=1.04............. Loss: -0.20779613, mean(E): -19.24978134-0.00667614j, var(E): 0.07308874
-0.0
tensor(18.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 20000/ t/epoch=1.04............. Loss: 0.11756213, mean(E): -19.22365403-0.00195335j, var(E): 0.04718241
-0.0
tensor(18.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 20000/ t/epoch=1.04............. Loss: 0.12482631, mean(E): -19.24223894-0.00540110j, var(E): 0.03053417
-0.0
tensor(18.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 20000/ t/epoch=1.05............. Loss: 0.05254692, mean(E): -19.20642641-0.00010892j, var(E): 0.03776679
-0.0
tensor(18.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 20000/ t/epoch=1.06............. Loss: 0.00719531, mean(E): -19.22027376-0.00319111j, var(E): 0.05337170
-0.0
tensor(18.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10010/ 20000/ t/epoch=1.05............. Loss: 0.06518198, mean(E): -19.20446959-0.00412903j, var(E): 0.08279046
-0.0
tensor(18.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10020/ 20000/ t/epoch=1.05............. Loss: 0.00571063, mean(E): -19.22075631-0.00158450j, var(E): 0.04279244
-0.0
tensor(18.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10030/ 20000/ t/epoch=1.05............. Loss: -0.06969827, mean(E): -19.20719668-0.00559249j, var(E): 0.07073678
-0.0
tensor(18.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10040/ 20000/ t/epoch=1.05............. Loss: 0.01419041, mean(E): -19.24293764-0.00057011j, var(E): 0.06110515
-0.0
tensor(18.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10050/ 20000/ t/epoch=1.06............. Loss: -0.30797979, mean(E): -19.20850443+0.00190914j, var(E): 0.03832504
-0.0
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10060/ 20000/ t/epoch=1.05............. Loss: -0.12041741, mean(E): -19.20559013+0.00288270j, var(E): 0.04234089
-0.0
tensor(18.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10070/ 20000/ t/epoch=1.05............. Loss: -0.40259146, mean(E): -19.22702960-0.00121186j, var(E): 0.05353216
-0.0
tensor(18.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10080/ 20000/ t/epoch=1.05............. Loss: -0.18697148, mean(E): -19.23893760-0.00000001j, var(E): 0.05757937
-0.0
tensor(18.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10090/ 20000/ t/epoch=1.05............. Loss: -0.30778094, mean(E): -19.22869251+0.00160093j, var(E): 0.04064673
-0.0
tensor(18.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10100/ 20000/ t/epoch=1.05............. Loss: 0.01651199, mean(E): -19.22209263-0.00584391j, var(E): 0.04127850
-0.0
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10110/ 20000/ t/epoch=1.05............. Loss: 0.03440499, mean(E): -19.21943069+0.00832529j, var(E): 0.05376959
-0.0
tensor(18.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10120/ 20000/ t/epoch=1.05............. Loss: -0.13483856, mean(E): -19.23382717+0.00174618j, var(E): 0.04504469
-0.0
tensor(18.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10130/ 20000/ t/epoch=1.04............. Loss: -0.12927943, mean(E): -19.21998371-0.01264917j, var(E): 0.03827548
-0.0
tensor(18.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10140/ 20000/ t/epoch=1.05............. Loss: 0.25072772, mean(E): -19.21319716-0.00447613j, var(E): 0.03708445
-0.0
tensor(18.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10150/ 20000/ t/epoch=1.05............. Loss: 0.40076480, mean(E): -19.23977145+0.00033641j, var(E): 0.05752379
-0.0
tensor(18.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10160/ 20000/ t/epoch=1.05............. Loss: 0.08655074, mean(E): -19.21817112-0.00435694j, var(E): 0.04415873
-0.0
tensor(18.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10170/ 20000/ t/epoch=1.05............. Loss: 0.07240490, mean(E): -19.19592824-0.00563202j, var(E): 0.05751458
-0.0
tensor(18.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10180/ 20000/ t/epoch=1.05............. Loss: -0.03589875, mean(E): -19.23784460+0.00145170j, var(E): 0.04752913
-0.0
tensor(18.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10190/ 20000/ t/epoch=1.06............. Loss: -0.14585270, mean(E): -19.20858977-0.00148508j, var(E): 0.03533431
-0.0
tensor(18.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10200/ 20000/ t/epoch=1.05............. Loss: -0.24928105, mean(E): -19.22749047-0.00079244j, var(E): 0.04422881
-0.0
tensor(18.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10210/ 20000/ t/epoch=1.05............. Loss: 0.03941835, mean(E): -19.22705076-0.00506905j, var(E): 0.04568472
-0.0
tensor(18.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10220/ 20000/ t/epoch=1.05............. Loss: -0.11250171, mean(E): -19.22998850+0.00286770j, var(E): 0.05374660
-0.0
tensor(18.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10230/ 20000/ t/epoch=1.05............. Loss: 0.40908442, mean(E): -19.23811196-0.00217241j, var(E): 0.04086784
-0.0
tensor(18.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10240/ 20000/ t/epoch=1.06............. Loss: -0.15329355, mean(E): -19.21106660+0.00605904j, var(E): 0.03653986
-0.0
tensor(18.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10250/ 20000/ t/epoch=1.06............. Loss: -0.20736715, mean(E): -19.21613432+0.00264553j, var(E): 0.03277578
-0.0
tensor(18.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10260/ 20000/ t/epoch=1.05............. Loss: -0.20328651, mean(E): -19.20989225+0.00052652j, var(E): 0.04080759
-0.0
tensor(18.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10270/ 20000/ t/epoch=1.05............. Loss: 0.06587284, mean(E): -19.19806548+0.00429288j, var(E): 0.05918024
-0.0
tensor(18.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10280/ 20000/ t/epoch=1.05............. Loss: 0.06784392, mean(E): -19.23139342-0.00797036j, var(E): 0.05713592
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10290/ 20000/ t/epoch=1.05............. Loss: 0.01540951, mean(E): -19.24718618+0.00503866j, var(E): 0.06789092
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10300/ 20000/ t/epoch=1.05............. Loss: 0.13547520, mean(E): -19.24106172-0.00383774j, var(E): 0.05132773
-0.0
tensor(18.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10310/ 20000/ t/epoch=1.06............. Loss: 0.28364496, mean(E): -19.21672453+0.00322718j, var(E): 0.06970436
-0.0
tensor(18.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10320/ 20000/ t/epoch=1.05............. Loss: -0.15036033, mean(E): -19.22379211-0.00527667j, var(E): 0.05182888
-0.0
tensor(18.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10330/ 20000/ t/epoch=1.04............. Loss: -0.27712992, mean(E): -19.19588219+0.00818023j, var(E): 0.07970719
-0.0
tensor(18.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10340/ 20000/ t/epoch=1.05............. Loss: -0.28745637, mean(E): -19.21859526+0.00283773j, var(E): 0.05367024
-0.0
tensor(18.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10350/ 20000/ t/epoch=1.06............. Loss: 0.10425235, mean(E): -19.22798012+0.00285854j, var(E): 0.03351470
-0.0
tensor(18.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10360/ 20000/ t/epoch=1.05............. Loss: 0.23743948, mean(E): -19.22995822+0.00604684j, var(E): 0.04604851
-0.0
tensor(18.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10370/ 20000/ t/epoch=1.05............. Loss: -0.40947749, mean(E): -19.20971315+0.00524504j, var(E): 0.03782084
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10380/ 20000/ t/epoch=1.05............. Loss: -0.00141392, mean(E): -19.22793338-0.00491964j, var(E): 0.05798387
-0.0
tensor(18.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10390/ 20000/ t/epoch=1.05............. Loss: 0.22807574, mean(E): -19.22616842-0.00055739j, var(E): 0.02884199
-0.0
tensor(18.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10400/ 20000/ t/epoch=1.06............. Loss: -0.06158086, mean(E): -19.22314576+0.00626114j, var(E): 0.07253824
-0.0
tensor(18.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10410/ 20000/ t/epoch=1.05............. Loss: 0.03634833, mean(E): -19.23790591+0.00824604j, var(E): 0.04395837
-0.0
tensor(18.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10420/ 20000/ t/epoch=1.06............. Loss: 0.14217090, mean(E): -19.23724861-0.00661362j, var(E): 0.04388109
-0.0
tensor(18.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10430/ 20000/ t/epoch=1.04............. Loss: -0.25246050, mean(E): -19.21379381+0.00221602j, var(E): 0.03583026
-0.0
tensor(18.4224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10440/ 20000/ t/epoch=1.05............. Loss: 0.01625277, mean(E): -19.23406366-0.00505203j, var(E): 0.04581793
-0.0
tensor(18.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10450/ 20000/ t/epoch=1.06............. Loss: -0.05785656, mean(E): -19.21005772+0.00359106j, var(E): 0.04583541
-0.0
tensor(18.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10460/ 20000/ t/epoch=1.06............. Loss: -0.19554026, mean(E): -19.21683866+0.00502131j, var(E): 0.06842715
-0.0
tensor(18.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10470/ 20000/ t/epoch=1.04............. Loss: 0.16871244, mean(E): -19.21250642-0.01064741j, var(E): 0.05456566
-0.0
tensor(18.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10480/ 20000/ t/epoch=1.05............. Loss: -0.03636789, mean(E): -19.22276915-0.00815131j, var(E): 0.05096253
-0.0
tensor(18.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10490/ 20000/ t/epoch=1.06............. Loss: -0.06450220, mean(E): -19.24484673+0.00592902j, var(E): 0.05437181
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10500/ 20000/ t/epoch=1.06............. Loss: 0.02795892, mean(E): -19.22248285+0.00280062j, var(E): 0.05435802
-0.0
tensor(18.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10510/ 20000/ t/epoch=1.05............. Loss: -0.14160357, mean(E): -19.20360182-0.00347370j, var(E): 0.04981442
-0.0
tensor(18.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10520/ 20000/ t/epoch=1.05............. Loss: -0.03012017, mean(E): -19.22161856+0.00111393j, var(E): 0.05426137
-0.0
tensor(18.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10530/ 20000/ t/epoch=1.05............. Loss: -0.28805397, mean(E): -19.23053053+0.00676239j, var(E): 0.03281636
-0.0
tensor(18.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10540/ 20000/ t/epoch=1.05............. Loss: -0.04102283, mean(E): -19.20967325-0.01401676j, var(E): 0.05413370
-0.0
tensor(18.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10550/ 20000/ t/epoch=1.05............. Loss: -0.07414629, mean(E): -19.20497079+0.00089888j, var(E): 0.03180138
-0.0
tensor(18.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10560/ 20000/ t/epoch=1.05............. Loss: 0.34679284, mean(E): -19.23374556+0.00680737j, var(E): 0.04591836
-0.0
tensor(18.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10570/ 20000/ t/epoch=1.04............. Loss: -0.01336051, mean(E): -19.23175694-0.00250182j, var(E): 0.04154106
-0.0
tensor(18.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10580/ 20000/ t/epoch=1.05............. Loss: -0.12524130, mean(E): -19.24331781+0.01363890j, var(E): 0.06078753
-0.0
tensor(18.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10590/ 20000/ t/epoch=1.04............. Loss: 0.11768101, mean(E): -19.23988889+0.00005520j, var(E): 0.03249890
-0.0
tensor(18.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10600/ 20000/ t/epoch=1.05............. Loss: 0.04795690, mean(E): -19.21386498-0.00432034j, var(E): 0.02784776
-0.0
tensor(18.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10610/ 20000/ t/epoch=1.05............. Loss: 0.08415266, mean(E): -19.22969156-0.00797525j, var(E): 0.05230251
-0.0
tensor(18.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10620/ 20000/ t/epoch=1.05............. Loss: -0.22742946, mean(E): -19.21352519+0.00381158j, var(E): 0.04671561
-0.0
tensor(18.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10630/ 20000/ t/epoch=1.05............. Loss: -0.17997657, mean(E): -19.21152108+0.00472920j, var(E): 0.04327204
-0.0
tensor(18.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10640/ 20000/ t/epoch=1.05............. Loss: -0.21628121, mean(E): -19.22686888+0.00338928j, var(E): 0.07784627
-0.0
tensor(18.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10650/ 20000/ t/epoch=1.05............. Loss: -0.19422120, mean(E): -19.21318629+0.00287459j, var(E): 0.05344703
-0.0
tensor(18.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10660/ 20000/ t/epoch=1.04............. Loss: 0.17649245, mean(E): -19.21753002-0.00468705j, var(E): 0.05657341
-0.0
tensor(18.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10670/ 20000/ t/epoch=1.04............. Loss: -0.08518645, mean(E): -19.19766632-0.00121642j, var(E): 0.06701887
-0.0
tensor(18.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10680/ 20000/ t/epoch=1.05............. Loss: 0.07894257, mean(E): -19.24861684+0.00365221j, var(E): 0.06166390
-0.0
tensor(18.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10690/ 20000/ t/epoch=1.05............. Loss: 0.20548629, mean(E): -19.22317958-0.00471950j, var(E): 0.03704879
-0.0
tensor(18.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10700/ 20000/ t/epoch=1.05............. Loss: 0.02634807, mean(E): -19.21490762-0.00472407j, var(E): 0.04814822
-0.0
tensor(18.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10710/ 20000/ t/epoch=1.05............. Loss: 0.30606436, mean(E): -19.21128983-0.00554488j, var(E): 0.07274625
-0.0
tensor(18.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10720/ 20000/ t/epoch=1.05............. Loss: -0.12587215, mean(E): -19.21832671+0.00350903j, var(E): 0.06067765
-0.0
tensor(18.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10730/ 20000/ t/epoch=1.04............. Loss: -0.06960038, mean(E): -19.18452199+0.00229001j, var(E): 0.04748027
-0.0
tensor(18.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10740/ 20000/ t/epoch=1.04............. Loss: 0.03539670, mean(E): -19.21468784-0.00367720j, var(E): 0.03724709
-0.0
tensor(18.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10750/ 20000/ t/epoch=1.05............. Loss: -0.13484578, mean(E): -19.21683836-0.01233614j, var(E): 0.05830421
-0.0
tensor(18.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10760/ 20000/ t/epoch=1.05............. Loss: -0.25911294, mean(E): -19.20167781-0.00444931j, var(E): 0.06769943
-0.0
tensor(18.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10770/ 20000/ t/epoch=1.05............. Loss: -0.33015910, mean(E): -19.20613663+0.00774091j, var(E): 0.03735734
-0.0
tensor(18.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10780/ 20000/ t/epoch=1.04............. Loss: -0.02572496, mean(E): -19.23475048+0.00313088j, var(E): 0.03064650
-0.0
tensor(18.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10790/ 20000/ t/epoch=1.04............. Loss: -0.10663556, mean(E): -19.24671763-0.00714469j, var(E): 0.04790491
-0.0
tensor(18.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10800/ 20000/ t/epoch=1.05............. Loss: -0.18540005, mean(E): -19.23185917-0.00578346j, var(E): 0.03493727
-0.0
tensor(18.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10810/ 20000/ t/epoch=1.05............. Loss: -0.20722739, mean(E): -19.19371202-0.00485785j, var(E): 0.04489333
-0.0
tensor(18.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10820/ 20000/ t/epoch=1.05............. Loss: 0.01631073, mean(E): -19.21694511+0.01246420j, var(E): 0.05407146
-0.0
tensor(18.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10830/ 20000/ t/epoch=1.04............. Loss: -0.15979599, mean(E): -19.22461804-0.01394687j, var(E): 0.04550445
-0.0
tensor(18.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10840/ 20000/ t/epoch=1.05............. Loss: -0.02518467, mean(E): -19.22748329-0.00690176j, var(E): 0.06506206
-0.0
tensor(18.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10850/ 20000/ t/epoch=1.05............. Loss: 0.24550478, mean(E): -19.20764487+0.00584133j, var(E): 0.05479607
-0.0
tensor(18.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10860/ 20000/ t/epoch=1.04............. Loss: -0.27975491, mean(E): -19.22176337+0.00201030j, var(E): 0.03335288
-0.0
tensor(18.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10870/ 20000/ t/epoch=1.05............. Loss: -0.56785054, mean(E): -19.19977390+0.00130090j, var(E): 0.06263390
-0.0
tensor(18.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10880/ 20000/ t/epoch=1.05............. Loss: -0.18880599, mean(E): -19.22790629+0.00118503j, var(E): 0.05630920
-0.0
tensor(18.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10890/ 20000/ t/epoch=1.05............. Loss: 0.28534576, mean(E): -19.22815360-0.00247693j, var(E): 0.06123654
-0.0
tensor(18.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10900/ 20000/ t/epoch=1.05............. Loss: 0.01991044, mean(E): -19.24040395-0.00153799j, var(E): 0.04821228
-0.0
tensor(18.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10910/ 20000/ t/epoch=1.04............. Loss: -0.16849931, mean(E): -19.23985639+0.00346663j, var(E): 0.05122461
-0.0
tensor(18.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10920/ 20000/ t/epoch=1.05............. Loss: -0.02334081, mean(E): -19.23070408-0.00670184j, var(E): 0.04399249
-0.0
tensor(18.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10930/ 20000/ t/epoch=1.05............. Loss: 0.24490401, mean(E): -19.23494628-0.00576560j, var(E): 0.03844769
-0.0
tensor(18.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10940/ 20000/ t/epoch=1.05............. Loss: 0.23645001, mean(E): -19.22520657-0.01289330j, var(E): 0.05342621
-0.0
tensor(18.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10950/ 20000/ t/epoch=1.06............. Loss: -0.02653010, mean(E): -19.20781794+0.00080194j, var(E): 0.04891700
-0.0
tensor(18.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10960/ 20000/ t/epoch=1.05............. Loss: 0.16958961, mean(E): -19.24367248-0.00502727j, var(E): 0.05278699
-0.0
tensor(18.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10970/ 20000/ t/epoch=1.05............. Loss: 0.09066985, mean(E): -19.24257007-0.00313744j, var(E): 0.05315124
-0.0
tensor(18.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10980/ 20000/ t/epoch=1.05............. Loss: -0.30349772, mean(E): -19.20969166-0.00568210j, var(E): 0.05333893
-0.0
tensor(18.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10990/ 20000/ t/epoch=1.04............. Loss: 0.21482764, mean(E): -19.20025581+0.00190847j, var(E): 0.05835454
-0.0
tensor(18.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11000/ 20000/ t/epoch=1.05............. Loss: -0.08031409, mean(E): -19.24079346+0.00744460j, var(E): 0.07326956
-0.0
tensor(18.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11010/ 20000/ t/epoch=1.05............. Loss: 0.01836952, mean(E): -19.21753711-0.00722422j, var(E): 0.09967241
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11020/ 20000/ t/epoch=1.05............. Loss: 0.20312071, mean(E): -19.23594867-0.00870767j, var(E): 0.04205427
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11030/ 20000/ t/epoch=1.05............. Loss: 0.34657759, mean(E): -19.20742394+0.00357108j, var(E): 0.06595928
-0.0
tensor(18.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11040/ 20000/ t/epoch=1.05............. Loss: 0.02647155, mean(E): -19.21309426+0.00405961j, var(E): 0.06039155
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11050/ 20000/ t/epoch=1.04............. Loss: -0.20729401, mean(E): -19.19053589+0.00431255j, var(E): 0.05830404
-0.0
tensor(18.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11060/ 20000/ t/epoch=1.05............. Loss: -0.02939350, mean(E): -19.21652029+0.00915358j, var(E): 0.05770331
-0.0
tensor(18.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11070/ 20000/ t/epoch=1.04............. Loss: 0.14317356, mean(E): -19.22209819-0.00947742j, var(E): 0.06570646
-0.0
tensor(18.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11080/ 20000/ t/epoch=1.05............. Loss: 0.06569875, mean(E): -19.23901018+0.00684313j, var(E): 0.04772569
-0.0
tensor(18.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11090/ 20000/ t/epoch=1.04............. Loss: 0.07345122, mean(E): -19.24202795+0.00990118j, var(E): 0.04552217
-0.0
tensor(18.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11100/ 20000/ t/epoch=1.05............. Loss: -0.07426848, mean(E): -19.20144283+0.00831547j, var(E): 0.05422562
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11110/ 20000/ t/epoch=1.05............. Loss: -0.14374981, mean(E): -19.20589952-0.00421721j, var(E): 0.05533467
-0.0
tensor(18.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11120/ 20000/ t/epoch=1.05............. Loss: -0.12540989, mean(E): -19.22996295+0.00588148j, var(E): 0.05378533
-0.0
tensor(18.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11130/ 20000/ t/epoch=1.05............. Loss: 0.34319839, mean(E): -19.20940012+0.00241396j, var(E): 0.04801470
-0.0
tensor(18.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11140/ 20000/ t/epoch=1.05............. Loss: -0.35875807, mean(E): -19.22401237+0.00259887j, var(E): 0.05678917
-0.0
tensor(18.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11150/ 20000/ t/epoch=1.05............. Loss: -0.17872191, mean(E): -19.21394954-0.00334759j, var(E): 0.05727615
-0.0
tensor(18.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11160/ 20000/ t/epoch=1.05............. Loss: 0.15487885, mean(E): -19.20981499-0.00856274j, var(E): 0.04214716
-0.0
tensor(18.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11170/ 20000/ t/epoch=1.05............. Loss: -0.00413405, mean(E): -19.18810519+0.00749860j, var(E): 0.04632116
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11180/ 20000/ t/epoch=1.06............. Loss: -0.06830409, mean(E): -19.21406682+0.00440744j, var(E): 0.03400142
-0.0
tensor(18.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11190/ 20000/ t/epoch=1.05............. Loss: 0.06390606, mean(E): -19.17791015-0.00155801j, var(E): 0.10431373
-0.0
tensor(18.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11200/ 20000/ t/epoch=1.05............. Loss: -0.34081172, mean(E): -19.23452134+0.00071358j, var(E): 0.04682404
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11210/ 20000/ t/epoch=1.05............. Loss: -0.00581199, mean(E): -19.20924584+0.00039746j, var(E): 0.05802894
-0.0
tensor(18.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11220/ 20000/ t/epoch=1.04............. Loss: 0.06822588, mean(E): -19.21762155-0.00384583j, var(E): 0.05347551
-0.0
tensor(18.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11230/ 20000/ t/epoch=1.05............. Loss: 0.07782860, mean(E): -19.21738361+0.00595027j, var(E): 0.03667092
-0.0
tensor(18.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11240/ 20000/ t/epoch=1.05............. Loss: -0.12533041, mean(E): -19.22933761-0.01822962j, var(E): 0.04270696
-0.0
tensor(18.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11250/ 20000/ t/epoch=1.05............. Loss: 0.20363391, mean(E): -19.22645754-0.00122509j, var(E): 0.04782910
-0.0
tensor(18.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11260/ 20000/ t/epoch=1.05............. Loss: 0.16264775, mean(E): -19.21466996-0.00985188j, var(E): 0.05472273
-0.0
tensor(18.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11270/ 20000/ t/epoch=1.06............. Loss: -0.13584675, mean(E): -19.24565515-0.00396130j, var(E): 0.06827693
-0.0
tensor(18.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11280/ 20000/ t/epoch=1.04............. Loss: 0.02844536, mean(E): -19.22138753+0.01245699j, var(E): 0.03928974
-0.0
tensor(18.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11290/ 20000/ t/epoch=1.05............. Loss: -0.04428006, mean(E): -19.21905642+0.00068060j, var(E): 0.05114790
-0.0
tensor(18.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11300/ 20000/ t/epoch=1.05............. Loss: 0.11721436, mean(E): -19.24909381-0.00444554j, var(E): 0.08786938
-0.0
tensor(18.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11310/ 20000/ t/epoch=1.04............. Loss: -0.03684408, mean(E): -19.23762557+0.00678797j, var(E): 0.03575359
-0.0
tensor(18.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11320/ 20000/ t/epoch=1.05............. Loss: -0.15397329, mean(E): -19.23101389+0.00364283j, var(E): 0.06042637
-0.0
tensor(18.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11330/ 20000/ t/epoch=1.05............. Loss: -0.25775170, mean(E): -19.21780913-0.00074106j, var(E): 0.03659972
-0.0
tensor(18.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11340/ 20000/ t/epoch=1.05............. Loss: -0.17061690, mean(E): -19.23621263-0.01064817j, var(E): 0.04275391
-0.0
tensor(18.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11350/ 20000/ t/epoch=1.04............. Loss: 0.04809755, mean(E): -19.22239623+0.00112836j, var(E): 0.03996429
-0.0
tensor(18.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11360/ 20000/ t/epoch=1.05............. Loss: 0.01240778, mean(E): -19.20079996+0.00256487j, var(E): 0.05185376
-0.0
tensor(18.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11370/ 20000/ t/epoch=1.05............. Loss: -0.33725645, mean(E): -19.21231866+0.00951634j, var(E): 0.03496484
-0.0
tensor(18.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11380/ 20000/ t/epoch=1.06............. Loss: 0.05298310, mean(E): -19.22354625+0.00155944j, var(E): 0.04635922
-0.0
tensor(18.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11390/ 20000/ t/epoch=1.06............. Loss: 0.11674130, mean(E): -19.23291819-0.01060386j, var(E): 0.03920387
-0.0
tensor(18.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11400/ 20000/ t/epoch=1.05............. Loss: -0.07479143, mean(E): -19.25393336+0.00078181j, var(E): 0.05083950
-0.0
tensor(18.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11410/ 20000/ t/epoch=1.05............. Loss: 0.04392173, mean(E): -19.21755228+0.00316541j, var(E): 0.04641666
-0.0
tensor(18.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11420/ 20000/ t/epoch=1.05............. Loss: -0.02422557, mean(E): -19.20873231-0.00191881j, var(E): 0.08189232
-0.0
tensor(18.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11430/ 20000/ t/epoch=1.04............. Loss: -0.28081726, mean(E): -19.21431353-0.00355960j, var(E): 0.07745596
-0.0
tensor(18.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11440/ 20000/ t/epoch=1.05............. Loss: -0.07168605, mean(E): -19.22435875-0.00484907j, var(E): 0.07422838
-0.0
tensor(18.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11450/ 20000/ t/epoch=1.05............. Loss: 0.23437854, mean(E): -19.23327097+0.00386669j, var(E): 0.03727016
-0.0
tensor(18.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11460/ 20000/ t/epoch=1.05............. Loss: -0.22715256, mean(E): -19.21197508+0.00571577j, var(E): 0.04005503
-0.0
tensor(18.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11470/ 20000/ t/epoch=1.05............. Loss: 0.02240951, mean(E): -19.21525040+0.00113615j, var(E): 0.05129214
-0.0
tensor(18.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11480/ 20000/ t/epoch=1.05............. Loss: 0.10050408, mean(E): -19.22606453+0.00859188j, var(E): 0.03707606
-0.0
tensor(18.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11490/ 20000/ t/epoch=1.05............. Loss: -0.29515222, mean(E): -19.24821823+0.00161083j, var(E): 0.07871341
-0.0
tensor(18.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11500/ 20000/ t/epoch=1.05............. Loss: 0.03328911, mean(E): -19.21110401-0.00153912j, var(E): 0.05143800
-0.0
tensor(18.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11510/ 20000/ t/epoch=1.05............. Loss: 0.04384792, mean(E): -19.21614985-0.00045692j, var(E): 0.02403543
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11520/ 20000/ t/epoch=1.05............. Loss: 0.10630251, mean(E): -19.22798006+0.00639493j, var(E): 0.04675884
-0.0
tensor(18.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11530/ 20000/ t/epoch=1.04............. Loss: -0.29460377, mean(E): -19.21636450+0.00921402j, var(E): 0.06052171
-0.0
tensor(18.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11540/ 20000/ t/epoch=1.05............. Loss: 0.03721602, mean(E): -19.22194844+0.00324179j, var(E): 0.03321413
-0.0
tensor(18.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11550/ 20000/ t/epoch=1.05............. Loss: 0.13760791, mean(E): -19.20206689-0.00671258j, var(E): 0.04264163
-0.0
tensor(18.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11560/ 20000/ t/epoch=1.05............. Loss: 0.17367242, mean(E): -19.23846881-0.00288185j, var(E): 0.05572628
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11570/ 20000/ t/epoch=1.05............. Loss: 0.01304355, mean(E): -19.23758570+0.00258664j, var(E): 0.07529152
-0.0
tensor(18.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11580/ 20000/ t/epoch=1.05............. Loss: -0.14157712, mean(E): -19.17855668-0.00557353j, var(E): 0.06647382
-0.0
tensor(18.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11590/ 20000/ t/epoch=1.05............. Loss: -0.03300646, mean(E): -19.22620661-0.00125998j, var(E): 0.06841558
-0.0
tensor(18.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11600/ 20000/ t/epoch=1.05............. Loss: -0.09706665, mean(E): -19.18996624-0.00230252j, var(E): 0.08725560
-0.0
tensor(18.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11610/ 20000/ t/epoch=1.05............. Loss: 0.35935196, mean(E): -19.23528640+0.00378774j, var(E): 0.03931723
-0.0
tensor(18.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11620/ 20000/ t/epoch=1.05............. Loss: -0.01661488, mean(E): -19.21448528-0.00388193j, var(E): 0.04541403
-0.0
tensor(18.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11630/ 20000/ t/epoch=1.05............. Loss: -0.27807670, mean(E): -19.21715513+0.00095881j, var(E): 0.03934905
-0.0
tensor(18.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11640/ 20000/ t/epoch=1.05............. Loss: 0.15101263, mean(E): -19.22873713-0.00508946j, var(E): 0.04548574
-0.0
tensor(18.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11650/ 20000/ t/epoch=1.04............. Loss: 0.03644551, mean(E): -19.22486002+0.00010997j, var(E): 0.04792361
-0.0
tensor(18.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11660/ 20000/ t/epoch=1.05............. Loss: 0.16563356, mean(E): -19.22925513+0.00753277j, var(E): 0.03667174
-0.0
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11670/ 20000/ t/epoch=1.05............. Loss: -0.26925143, mean(E): -19.20209553+0.00574958j, var(E): 0.03434159
-0.0
tensor(18.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11680/ 20000/ t/epoch=1.05............. Loss: 0.28149146, mean(E): -19.22831792+0.00256349j, var(E): 0.06801834
-0.0
tensor(18.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11690/ 20000/ t/epoch=1.05............. Loss: -0.09549272, mean(E): -19.21660729+0.00938035j, var(E): 0.10142880
-0.0
tensor(18.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11700/ 20000/ t/epoch=1.05............. Loss: 0.07053116, mean(E): -19.21198482-0.00389473j, var(E): 0.03025409
-0.0
tensor(18.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11710/ 20000/ t/epoch=1.05............. Loss: 0.04206155, mean(E): -19.24825171+0.00571637j, var(E): 0.06539645
-0.0
tensor(18.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11720/ 20000/ t/epoch=1.05............. Loss: -0.07895018, mean(E): -19.23433502+0.00128537j, var(E): 0.03460023
-0.0
tensor(18.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11730/ 20000/ t/epoch=1.05............. Loss: -0.01780438, mean(E): -19.21820202+0.00089293j, var(E): 0.03360077
-0.0
tensor(18.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11740/ 20000/ t/epoch=1.04............. Loss: 0.21733361, mean(E): -19.22255767+0.00638865j, var(E): 0.04327315
-0.0
tensor(18.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11750/ 20000/ t/epoch=1.05............. Loss: -0.08988135, mean(E): -19.22093844-0.00424995j, var(E): 0.04934530
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11760/ 20000/ t/epoch=1.06............. Loss: 0.00401977, mean(E): -19.24124214+0.00026300j, var(E): 0.04166212
-0.0
tensor(18.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11770/ 20000/ t/epoch=1.05............. Loss: 0.28430534, mean(E): -19.22264659+0.00231897j, var(E): 0.05402992
-0.0
tensor(18.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11780/ 20000/ t/epoch=1.04............. Loss: 0.19304746, mean(E): -19.21220009-0.00724940j, var(E): 0.02715042
-0.0
tensor(18.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11790/ 20000/ t/epoch=1.05............. Loss: -0.02456689, mean(E): -19.20908557+0.00260100j, var(E): 0.03111284
-0.0
tensor(18.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11800/ 20000/ t/epoch=1.05............. Loss: -0.35916492, mean(E): -19.22403935+0.01204195j, var(E): 0.03014580
-0.0
tensor(18.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11810/ 20000/ t/epoch=1.05............. Loss: -0.28251155, mean(E): -19.20704794+0.00479161j, var(E): 0.03905081
-0.0
tensor(18.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11820/ 20000/ t/epoch=1.05............. Loss: -0.00891386, mean(E): -19.23423774+0.00019606j, var(E): 0.05389954
-0.0
tensor(18.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11830/ 20000/ t/epoch=1.05............. Loss: -0.09723896, mean(E): -19.23125666-0.00719163j, var(E): 0.05298384
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11840/ 20000/ t/epoch=1.06............. Loss: 0.09878146, mean(E): -19.20387130+0.00415392j, var(E): 0.04222224
-0.0
tensor(18.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11850/ 20000/ t/epoch=1.05............. Loss: 0.28373845, mean(E): -19.23990974+0.00114181j, var(E): 0.04362595
-0.0
tensor(18.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11860/ 20000/ t/epoch=1.05............. Loss: -0.06820356, mean(E): -19.22041335-0.00015380j, var(E): 0.04397139
-0.0
tensor(18.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11870/ 20000/ t/epoch=1.04............. Loss: 0.33647447, mean(E): -19.28842978-0.00663446j, var(E): 0.14368985
-0.0
tensor(18.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11880/ 20000/ t/epoch=1.04............. Loss: -0.11416654, mean(E): -19.23339467-0.00082689j, var(E): 0.03382020
-0.0
tensor(18.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11890/ 20000/ t/epoch=1.05............. Loss: -0.51905901, mean(E): -19.19929893+0.00309435j, var(E): 0.12101580
-0.0
tensor(18.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11900/ 20000/ t/epoch=1.04............. Loss: -0.00611095, mean(E): -19.22010658-0.01377912j, var(E): 0.04394677
-0.0
tensor(18.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11910/ 20000/ t/epoch=1.05............. Loss: -0.30044878, mean(E): -19.23201667+0.00199560j, var(E): 0.05617941
-0.0
tensor(18.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11920/ 20000/ t/epoch=1.05............. Loss: 0.07428197, mean(E): -19.21822007+0.01511166j, var(E): 0.03844472
-0.0
tensor(18.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11930/ 20000/ t/epoch=1.05............. Loss: -0.25609495, mean(E): -19.20851705+0.00629730j, var(E): 0.04859256
-0.0
tensor(18.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11940/ 20000/ t/epoch=1.05............. Loss: -0.10576391, mean(E): -19.21401606+0.00514899j, var(E): 0.03681188
-0.0
tensor(18.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11950/ 20000/ t/epoch=1.05............. Loss: -0.46449649, mean(E): -19.17729165+0.00520823j, var(E): 0.05655664
-0.0
tensor(18.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11960/ 20000/ t/epoch=1.05............. Loss: 0.30132368, mean(E): -19.23853176+0.00165197j, var(E): 0.04299352
-0.0
tensor(18.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11970/ 20000/ t/epoch=1.04............. Loss: 0.27856945, mean(E): -19.22729053+0.00024097j, var(E): 0.02444598
-0.0
tensor(18.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11980/ 20000/ t/epoch=1.04............. Loss: 0.01017396, mean(E): -19.23851737+0.00343929j, var(E): 0.06657818
-0.0
tensor(18.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11990/ 20000/ t/epoch=1.04............. Loss: -0.17070422, mean(E): -19.21551248-0.00574067j, var(E): 0.03322379
-0.0
tensor(18.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12000/ 20000/ t/epoch=1.05............. Loss: 0.26023924, mean(E): -19.20827713+0.00205607j, var(E): 0.05178578
-0.0
tensor(18.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12010/ 20000/ t/epoch=1.05............. Loss: -0.12931205, mean(E): -19.21808951+0.00425257j, var(E): 0.05715952
-0.0
tensor(18.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12020/ 20000/ t/epoch=1.04............. Loss: -0.13566413, mean(E): -19.23254019-0.00394532j, var(E): 0.03170068
-0.0
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12030/ 20000/ t/epoch=1.05............. Loss: 0.10419158, mean(E): -19.21670299+0.00606697j, var(E): 0.03699162
-0.0
tensor(18.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12040/ 20000/ t/epoch=1.05............. Loss: -0.25559655, mean(E): -19.23090539+0.00509681j, var(E): 0.03230114
-0.0
tensor(18.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12050/ 20000/ t/epoch=1.06............. Loss: -0.19027374, mean(E): -19.22094137+0.00284405j, var(E): 0.06272618
-0.0
tensor(18.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12060/ 20000/ t/epoch=1.05............. Loss: 0.28411712, mean(E): -19.23514484+0.00365199j, var(E): 0.02944702
-0.0
tensor(18.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12070/ 20000/ t/epoch=1.05............. Loss: -0.21304961, mean(E): -19.22654315+0.00183102j, var(E): 0.04024301
-0.0
tensor(18.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12080/ 20000/ t/epoch=1.05............. Loss: -0.18960096, mean(E): -19.22039121-0.00613281j, var(E): 0.04676731
-0.0
tensor(18.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12090/ 20000/ t/epoch=1.05............. Loss: 0.01225510, mean(E): -19.18952597+0.00242014j, var(E): 0.08601148
-0.0
tensor(18.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12100/ 20000/ t/epoch=1.05............. Loss: 0.15204988, mean(E): -19.23071771+0.00293172j, var(E): 0.05275329
-0.0
tensor(18.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12110/ 20000/ t/epoch=1.04............. Loss: -0.10838939, mean(E): -19.21391238+0.00107887j, var(E): 0.04273130
-0.0
tensor(18.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12120/ 20000/ t/epoch=1.05............. Loss: 0.23140097, mean(E): -19.24472691-0.00050357j, var(E): 0.05700348
-0.0
tensor(18.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12130/ 20000/ t/epoch=1.05............. Loss: -0.18631407, mean(E): -19.21606123+0.00399165j, var(E): 0.04001271
-0.0
tensor(18.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12140/ 20000/ t/epoch=1.04............. Loss: -0.17744654, mean(E): -19.25126680-0.00242351j, var(E): 0.02652959
-0.0
tensor(18.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12150/ 20000/ t/epoch=1.06............. Loss: 0.19263759, mean(E): -19.22133237+0.00318549j, var(E): 0.02907749
-0.0
tensor(18.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12160/ 20000/ t/epoch=1.04............. Loss: -0.05173553, mean(E): -19.19864799+0.00378003j, var(E): 0.09419460
-0.0
tensor(18.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12170/ 20000/ t/epoch=1.05............. Loss: 0.17846693, mean(E): -19.21110852-0.00180564j, var(E): 0.04065797
-0.0
tensor(18.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12180/ 20000/ t/epoch=1.04............. Loss: 0.01903392, mean(E): -19.20745143+0.00571072j, var(E): 0.08338183
-0.0
tensor(18.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12190/ 20000/ t/epoch=1.04............. Loss: -0.06924813, mean(E): -19.21239913-0.01102802j, var(E): 0.05479635
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12200/ 20000/ t/epoch=1.04............. Loss: -0.05722254, mean(E): -19.23560200-0.00971303j, var(E): 0.02950167
-0.0
tensor(18.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12210/ 20000/ t/epoch=1.06............. Loss: -0.22545187, mean(E): -19.18780231-0.00584548j, var(E): 0.07569121
-0.0
tensor(18.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12220/ 20000/ t/epoch=1.05............. Loss: -0.09622178, mean(E): -19.22602829-0.00014786j, var(E): 0.03092207
-0.0
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12230/ 20000/ t/epoch=1.05............. Loss: -0.01667510, mean(E): -19.22533665+0.00238594j, var(E): 0.04683744
-0.0
tensor(18.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12240/ 20000/ t/epoch=1.05............. Loss: 0.11342451, mean(E): -19.24174786+0.00440668j, var(E): 0.07124206
-0.0
tensor(18.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12250/ 20000/ t/epoch=1.05............. Loss: 0.23746258, mean(E): -19.23842219+0.00237678j, var(E): 0.05246319
-0.0
tensor(18.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12260/ 20000/ t/epoch=1.05............. Loss: 0.20521110, mean(E): -19.24254167-0.00341046j, var(E): 0.04508478
-0.0
tensor(18.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12270/ 20000/ t/epoch=1.05............. Loss: -0.10325999, mean(E): -19.21226607+0.00088560j, var(E): 0.05263513
-0.0
tensor(18.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12280/ 20000/ t/epoch=1.05............. Loss: -0.03510206, mean(E): -19.22239800-0.00940449j, var(E): 0.04642684
-0.0
tensor(18.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12290/ 20000/ t/epoch=1.05............. Loss: -0.27832695, mean(E): -19.22621722+0.00220553j, var(E): 0.04090509
-0.0
tensor(18.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12300/ 20000/ t/epoch=1.04............. Loss: -0.08593033, mean(E): -19.22284162+0.00886926j, var(E): 0.03839389
-0.0
tensor(18.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12310/ 20000/ t/epoch=1.05............. Loss: 0.21632012, mean(E): -19.22030671-0.00454762j, var(E): 0.02564526
-0.0
tensor(18.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12320/ 20000/ t/epoch=1.05............. Loss: 0.08487436, mean(E): -19.22722675+0.00300216j, var(E): 0.03470844
-0.0
tensor(18.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12330/ 20000/ t/epoch=1.05............. Loss: -0.08465579, mean(E): -19.21207404-0.00746171j, var(E): 0.03469492
-0.0
tensor(18.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12340/ 20000/ t/epoch=1.04............. Loss: -0.23518166, mean(E): -19.20549894-0.00159684j, var(E): 0.03958840
-0.0
tensor(18.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12350/ 20000/ t/epoch=1.05............. Loss: 0.34588193, mean(E): -19.22214531-0.00266149j, var(E): 0.03102220
-0.0
tensor(18.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12360/ 20000/ t/epoch=1.04............. Loss: 0.36108390, mean(E): -19.25295735-0.00187750j, var(E): 0.03372384
-0.0
tensor(18.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12370/ 20000/ t/epoch=1.04............. Loss: -0.05657600, mean(E): -19.24092418+0.00872333j, var(E): 0.04262102
-0.0
tensor(18.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12380/ 20000/ t/epoch=1.05............. Loss: 0.05565709, mean(E): -19.20857559+0.00920426j, var(E): 0.04427985
-0.0
tensor(18.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12390/ 20000/ t/epoch=1.04............. Loss: 0.27044496, mean(E): -19.23125951+0.00264639j, var(E): 0.04586757
-0.0
tensor(18.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12400/ 20000/ t/epoch=1.04............. Loss: 0.16495152, mean(E): -19.20821178-0.00564775j, var(E): 0.02897974
-0.0
tensor(18.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12410/ 20000/ t/epoch=1.05............. Loss: 0.12974868, mean(E): -19.22665375-0.00422646j, var(E): 0.06070995
-0.0
tensor(18.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12420/ 20000/ t/epoch=1.05............. Loss: -0.02822333, mean(E): -19.20365964-0.00340286j, var(E): 0.04596527
-0.0
tensor(18.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12430/ 20000/ t/epoch=1.04............. Loss: 0.04368579, mean(E): -19.22466537-0.00378753j, var(E): 0.02849449
-0.0
tensor(18.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12440/ 20000/ t/epoch=1.05............. Loss: -0.13320515, mean(E): -19.21724492-0.00739607j, var(E): 0.03070167
-0.0
tensor(18.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12450/ 20000/ t/epoch=1.04............. Loss: 0.15822640, mean(E): -19.21842920-0.00538778j, var(E): 0.03325446
-0.0
tensor(18.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12460/ 20000/ t/epoch=1.05............. Loss: 0.30302278, mean(E): -19.24021507-0.00253404j, var(E): 0.04561621
-0.0
tensor(18.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12470/ 20000/ t/epoch=1.05............. Loss: -0.17549791, mean(E): -19.22502178-0.00200366j, var(E): 0.03737789
-0.0
tensor(18.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12480/ 20000/ t/epoch=1.05............. Loss: 0.02104095, mean(E): -19.23944226+0.00364203j, var(E): 0.03195027
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12490/ 20000/ t/epoch=1.05............. Loss: -0.02034270, mean(E): -19.21829807+0.00075620j, var(E): 0.04107638
-0.0
tensor(18.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12500/ 20000/ t/epoch=1.05............. Loss: -0.17423877, mean(E): -19.20887062-0.00726730j, var(E): 0.04921753
-0.0
tensor(18.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12510/ 20000/ t/epoch=1.05............. Loss: -0.08619277, mean(E): -19.22149584-0.00072220j, var(E): 0.04601737
-0.0
tensor(18.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12520/ 20000/ t/epoch=1.05............. Loss: -0.01462928, mean(E): -19.23214812-0.00246443j, var(E): 0.03708426
-0.0
tensor(18.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12530/ 20000/ t/epoch=1.05............. Loss: -0.20188116, mean(E): -19.21478299-0.00037544j, var(E): 0.04180512
-0.0
tensor(18.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12540/ 20000/ t/epoch=1.05............. Loss: 0.00160547, mean(E): -19.20395640-0.00312894j, var(E): 0.02753180
-0.0
tensor(18.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12550/ 20000/ t/epoch=1.04............. Loss: -0.45950979, mean(E): -19.22234035+0.00623143j, var(E): 0.04316382
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12560/ 20000/ t/epoch=1.04............. Loss: 0.07940252, mean(E): -19.20446243+0.00377876j, var(E): 0.02353010
-0.0
tensor(18.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12570/ 20000/ t/epoch=1.04............. Loss: 0.07019721, mean(E): -19.21876809-0.00089764j, var(E): 0.02512264
-0.0
tensor(18.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12580/ 20000/ t/epoch=1.05............. Loss: -0.29503895, mean(E): -19.22289885+0.00350222j, var(E): 0.05189612
-0.0
tensor(18.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12590/ 20000/ t/epoch=1.04............. Loss: -0.16657902, mean(E): -19.19949329-0.01016397j, var(E): 0.03370280
-0.0
tensor(18.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12600/ 20000/ t/epoch=1.05............. Loss: 0.20538534, mean(E): -19.19251119-0.00409315j, var(E): 0.04736387
-0.0
tensor(18.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12610/ 20000/ t/epoch=1.04............. Loss: -0.06361313, mean(E): -19.21456962+0.00344188j, var(E): 0.04358599
-0.0
tensor(18.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12620/ 20000/ t/epoch=1.05............. Loss: -0.24127024, mean(E): -19.23236196+0.00863497j, var(E): 0.04772134
-0.0
tensor(18.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12630/ 20000/ t/epoch=1.05............. Loss: 0.18343729, mean(E): -19.24712908-0.00025212j, var(E): 0.04225778
-0.0
tensor(18.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12640/ 20000/ t/epoch=1.04............. Loss: 0.04269646, mean(E): -19.24913043+0.00211427j, var(E): 0.02701482
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12650/ 20000/ t/epoch=1.04............. Loss: 0.18301298, mean(E): -19.21989381-0.00595821j, var(E): 0.04247220
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12660/ 20000/ t/epoch=1.05............. Loss: 0.03267478, mean(E): -19.23852446-0.00515739j, var(E): 0.04983252
-0.0
tensor(18.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12670/ 20000/ t/epoch=1.06............. Loss: -0.25021642, mean(E): -19.22210923+0.00111997j, var(E): 0.04898442
-0.0
tensor(18.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12680/ 20000/ t/epoch=1.05............. Loss: -0.10603127, mean(E): -19.20180923-0.00097566j, var(E): 0.04546416
-0.0
tensor(18.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12690/ 20000/ t/epoch=1.05............. Loss: 0.02269406, mean(E): -19.21488630+0.00131525j, var(E): 0.03576224
-0.0
tensor(18.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12700/ 20000/ t/epoch=1.05............. Loss: 0.12025042, mean(E): -19.24442694+0.00338615j, var(E): 0.05154508
-0.0
tensor(18.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12710/ 20000/ t/epoch=1.05............. Loss: 0.04091548, mean(E): -19.21487605+0.00253967j, var(E): 0.03047129
-0.0
tensor(18.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12720/ 20000/ t/epoch=1.05............. Loss: 0.11413215, mean(E): -19.22316226+0.00820320j, var(E): 0.05929719
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12730/ 20000/ t/epoch=1.05............. Loss: 0.20097711, mean(E): -19.21802505+0.00861351j, var(E): 0.03620881
-0.0
tensor(18.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12740/ 20000/ t/epoch=1.05............. Loss: 0.18236631, mean(E): -19.20382197-0.00196663j, var(E): 0.03282892
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12750/ 20000/ t/epoch=1.05............. Loss: 0.06449360, mean(E): -19.21079796+0.01105640j, var(E): 0.04016717
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12760/ 20000/ t/epoch=1.05............. Loss: -0.29393113, mean(E): -19.20725614+0.00295733j, var(E): 0.05237374
-0.0
tensor(18.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12770/ 20000/ t/epoch=1.06............. Loss: 0.21897261, mean(E): -19.24687404+0.00463626j, var(E): 0.04879885
-0.0
tensor(18.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12780/ 20000/ t/epoch=1.05............. Loss: -0.04706909, mean(E): -19.23363843+0.00108530j, var(E): 0.06150591
-0.0
tensor(18.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12790/ 20000/ t/epoch=1.05............. Loss: -0.01237241, mean(E): -19.22753558+0.00668893j, var(E): 0.04417192
-0.0
tensor(18.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12800/ 20000/ t/epoch=1.05............. Loss: 0.23359926, mean(E): -19.23420210-0.00100675j, var(E): 0.03508888
-0.0
tensor(18.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12810/ 20000/ t/epoch=1.04............. Loss: -0.04878991, mean(E): -19.23127738+0.00494915j, var(E): 0.04031898
-0.0
tensor(18.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12820/ 20000/ t/epoch=1.05............. Loss: -0.10135356, mean(E): -19.22594058-0.00033013j, var(E): 0.05448407
-0.0
tensor(18.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12830/ 20000/ t/epoch=1.05............. Loss: 0.20004264, mean(E): -19.22453937-0.00047819j, var(E): 0.02860305
-0.0
tensor(18.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12840/ 20000/ t/epoch=1.05............. Loss: -0.25026031, mean(E): -19.23369874+0.00119691j, var(E): 0.05336722
-0.0
tensor(18.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12850/ 20000/ t/epoch=1.04............. Loss: 0.02266315, mean(E): -19.22807529-0.00519471j, var(E): 0.02820116
-0.0
tensor(18.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12860/ 20000/ t/epoch=1.05............. Loss: -0.05267499, mean(E): -19.22163065+0.00214248j, var(E): 0.05405077
-0.0
tensor(18.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12870/ 20000/ t/epoch=1.05............. Loss: 0.08895751, mean(E): -19.21271281+0.00640149j, var(E): 0.03714873
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12880/ 20000/ t/epoch=1.05............. Loss: -0.22470200, mean(E): -19.22243553+0.00488576j, var(E): 0.05087158
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12890/ 20000/ t/epoch=1.05............. Loss: 0.05229343, mean(E): -19.23622149+0.00785358j, var(E): 0.05088335
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12900/ 20000/ t/epoch=1.04............. Loss: 0.19933024, mean(E): -19.23515091-0.00037261j, var(E): 0.03944474
-0.0
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12910/ 20000/ t/epoch=1.05............. Loss: 0.10815357, mean(E): -19.22846863-0.00054971j, var(E): 0.05272428
-0.0
tensor(18.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12920/ 20000/ t/epoch=1.05............. Loss: 0.02328316, mean(E): -19.21575347+0.00380058j, var(E): 0.04555247
-0.0
tensor(18.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12930/ 20000/ t/epoch=1.05............. Loss: 0.03121724, mean(E): -19.22785128-0.00744130j, var(E): 0.04082639
-0.0
tensor(18.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12940/ 20000/ t/epoch=1.05............. Loss: -0.35252237, mean(E): -19.23230808-0.01065747j, var(E): 0.02862072
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12950/ 20000/ t/epoch=1.04............. Loss: -0.22331428, mean(E): -19.20350089-0.00173011j, var(E): 0.02978318
-0.0
tensor(18.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12960/ 20000/ t/epoch=1.05............. Loss: -0.07623638, mean(E): -19.22308049-0.00233752j, var(E): 0.03073797
-0.0
tensor(18.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12970/ 20000/ t/epoch=1.05............. Loss: -0.00972682, mean(E): -19.25286959-0.00254692j, var(E): 0.04317338
-0.0
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12980/ 20000/ t/epoch=1.05............. Loss: 0.21825159, mean(E): -19.22485081-0.00334423j, var(E): 0.02392991
-0.0
tensor(18.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12990/ 20000/ t/epoch=1.06............. Loss: 0.05224575, mean(E): -19.22523080+0.00061265j, var(E): 0.03125079
-0.0
tensor(18.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13000/ 20000/ t/epoch=1.05............. Loss: 0.16904769, mean(E): -19.21109959-0.00709757j, var(E): 0.05439856
-0.0
tensor(18.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13010/ 20000/ t/epoch=1.05............. Loss: 0.20107727, mean(E): -19.25494183+0.00281217j, var(E): 0.06027906
-0.0
tensor(18.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13020/ 20000/ t/epoch=1.05............. Loss: 0.30060193, mean(E): -19.26160557-0.00228386j, var(E): 0.09184060
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13030/ 20000/ t/epoch=1.04............. Loss: -0.04527897, mean(E): -19.21535809-0.00820978j, var(E): 0.04031171
-0.0
tensor(18.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13040/ 20000/ t/epoch=1.04............. Loss: -0.06399875, mean(E): -19.23046914+0.00386855j, var(E): 0.03732605
-0.0
tensor(18.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13050/ 20000/ t/epoch=1.05............. Loss: -0.17968113, mean(E): -19.21936714-0.00139639j, var(E): 0.04354844
-0.0
tensor(18.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13060/ 20000/ t/epoch=1.05............. Loss: 0.41702547, mean(E): -19.23442353+0.00264031j, var(E): 0.04356545
-0.0
tensor(18.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13070/ 20000/ t/epoch=1.04............. Loss: 0.10486941, mean(E): -19.21937980-0.00516496j, var(E): 0.05470139
-0.0
tensor(18.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13080/ 20000/ t/epoch=1.05............. Loss: 0.05919430, mean(E): -19.23218338+0.00645738j, var(E): 0.03264784
-0.0
tensor(18.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13090/ 20000/ t/epoch=1.05............. Loss: -0.41500745, mean(E): -19.21158819+0.00175931j, var(E): 0.02979813
-0.0
tensor(18.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13100/ 20000/ t/epoch=1.05............. Loss: 0.25253602, mean(E): -19.26011307+0.00402494j, var(E): 0.03352092
-0.0
tensor(18.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13110/ 20000/ t/epoch=1.05............. Loss: 0.32798541, mean(E): -19.24544634-0.00005828j, var(E): 0.08039203
-0.0
tensor(18.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13120/ 20000/ t/epoch=1.05............. Loss: -0.02549987, mean(E): -19.21702654+0.00263597j, var(E): 0.04352213
-0.0
tensor(18.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13130/ 20000/ t/epoch=1.05............. Loss: -0.20110981, mean(E): -19.19188311+0.00350371j, var(E): 0.05613321
-0.0
tensor(18.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13140/ 20000/ t/epoch=1.04............. Loss: 0.15868699, mean(E): -19.22549221+0.00865480j, var(E): 0.04701198
-0.0
tensor(18.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13150/ 20000/ t/epoch=1.05............. Loss: 0.09903874, mean(E): -19.20932624+0.00363064j, var(E): 0.02820128
-0.0
tensor(18.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13160/ 20000/ t/epoch=1.05............. Loss: -0.28844165, mean(E): -19.22038393+0.00442176j, var(E): 0.03373031
-0.0
tensor(18.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13170/ 20000/ t/epoch=1.05............. Loss: -0.07494481, mean(E): -19.22043421-0.00230883j, var(E): 0.04426970
-0.0
tensor(18.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13180/ 20000/ t/epoch=1.05............. Loss: -0.05685225, mean(E): -19.21476158+0.00297778j, var(E): 0.03101122
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13190/ 20000/ t/epoch=1.05............. Loss: -0.15950626, mean(E): -19.21158421+0.00192389j, var(E): 0.05168101
-0.0
tensor(18.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13200/ 20000/ t/epoch=1.05............. Loss: 0.10633700, mean(E): -19.21068953+0.00071805j, var(E): 0.03345775
-0.0
tensor(18.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13210/ 20000/ t/epoch=1.04............. Loss: 0.19026331, mean(E): -19.20862086-0.00668765j, var(E): 0.03096703
-0.0
tensor(18.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13220/ 20000/ t/epoch=1.04............. Loss: 0.24689782, mean(E): -19.24738552-0.00856505j, var(E): 0.04757203
-0.0
tensor(18.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13230/ 20000/ t/epoch=1.06............. Loss: -0.16229260, mean(E): -19.23469014+0.00414701j, var(E): 0.04226922
-0.0
tensor(18.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13240/ 20000/ t/epoch=1.04............. Loss: -0.31743610, mean(E): -19.23316000-0.00066787j, var(E): 0.05206033
-0.0
tensor(18.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13250/ 20000/ t/epoch=1.05............. Loss: 0.14006009, mean(E): -19.21605264+0.00387245j, var(E): 0.05947912
-0.0
tensor(18.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13260/ 20000/ t/epoch=1.05............. Loss: 0.00943671, mean(E): -19.21758696-0.01450650j, var(E): 0.06404272
-0.0
tensor(18.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13270/ 20000/ t/epoch=1.06............. Loss: 0.07508393, mean(E): -19.19633649-0.00054182j, var(E): 0.03803304
-0.0
tensor(18.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13280/ 20000/ t/epoch=1.04............. Loss: -0.11811584, mean(E): -19.23663882+0.00873782j, var(E): 0.03035798
-0.0
tensor(18.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13290/ 20000/ t/epoch=1.04............. Loss: 0.14638921, mean(E): -19.20366889-0.00157524j, var(E): 0.03269687
-0.0
tensor(18.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13300/ 20000/ t/epoch=1.04............. Loss: 0.10394516, mean(E): -19.21419704-0.00507018j, var(E): 0.02067886
-0.0
tensor(18.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13310/ 20000/ t/epoch=1.05............. Loss: -0.06746991, mean(E): -19.22778053+0.00085655j, var(E): 0.03768197
-0.0
tensor(18.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13320/ 20000/ t/epoch=1.04............. Loss: 0.37674625, mean(E): -19.21596101-0.00934947j, var(E): 0.02917067
-0.0
tensor(18.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13330/ 20000/ t/epoch=1.04............. Loss: 0.40369767, mean(E): -19.23247082+0.00271024j, var(E): 0.04422558
-0.0
tensor(18.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13340/ 20000/ t/epoch=1.05............. Loss: -0.01169128, mean(E): -19.24008963-0.00267126j, var(E): 0.04211775
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13350/ 20000/ t/epoch=1.06............. Loss: -0.15452741, mean(E): -19.22592025+0.00166086j, var(E): 0.03335475
-0.0
tensor(18.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13360/ 20000/ t/epoch=1.05............. Loss: 0.02250649, mean(E): -19.20250822+0.00191744j, var(E): 0.04320290
-0.0
tensor(18.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13370/ 20000/ t/epoch=1.05............. Loss: -0.13844944, mean(E): -19.21219789-0.01224120j, var(E): 0.02802953
-0.0
tensor(18.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13380/ 20000/ t/epoch=1.05............. Loss: -0.00995726, mean(E): -19.20715206+0.00068633j, var(E): 0.03822790
-0.0
tensor(18.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13390/ 20000/ t/epoch=1.05............. Loss: -0.16330424, mean(E): -19.21271601-0.00688721j, var(E): 0.04535605
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13400/ 20000/ t/epoch=1.04............. Loss: -0.03235274, mean(E): -19.23354047-0.00361402j, var(E): 0.04152887
-0.0
tensor(18.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13410/ 20000/ t/epoch=1.05............. Loss: 0.10689510, mean(E): -19.23936219+0.00767897j, var(E): 0.05985228
-0.0
tensor(18.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13420/ 20000/ t/epoch=1.05............. Loss: -0.18706705, mean(E): -19.22114255-0.00342556j, var(E): 0.03492327
-0.0
tensor(18.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13430/ 20000/ t/epoch=1.05............. Loss: 0.01632889, mean(E): -19.23397977+0.00993528j, var(E): 0.03333754
-0.0
tensor(18.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13440/ 20000/ t/epoch=1.05............. Loss: 0.35016731, mean(E): -19.23954890-0.00313171j, var(E): 0.04534772
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13450/ 20000/ t/epoch=1.05............. Loss: 0.22766083, mean(E): -19.23520217+0.00472817j, var(E): 0.03589724
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13460/ 20000/ t/epoch=1.05............. Loss: -0.04075903, mean(E): -19.22767609-0.00552127j, var(E): 0.03977378
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13470/ 20000/ t/epoch=1.05............. Loss: 0.04767171, mean(E): -19.21966880-0.00732654j, var(E): 0.02750561
-0.0
tensor(18.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13480/ 20000/ t/epoch=1.05............. Loss: -0.16033550, mean(E): -19.24218112+0.00152490j, var(E): 0.04352666
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13490/ 20000/ t/epoch=1.05............. Loss: 0.01490146, mean(E): -19.22541589-0.00277216j, var(E): 0.03848376
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13500/ 20000/ t/epoch=1.05............. Loss: 0.23668056, mean(E): -19.22174391-0.00177074j, var(E): 0.02500563
-0.0
tensor(18.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13510/ 20000/ t/epoch=1.05............. Loss: 0.25825575, mean(E): -19.23441151-0.00024558j, var(E): 0.04244456
-0.0
tensor(18.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13520/ 20000/ t/epoch=1.05............. Loss: -0.19756332, mean(E): -19.22284465-0.00035066j, var(E): 0.05878286
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13530/ 20000/ t/epoch=1.05............. Loss: -0.00393437, mean(E): -19.22616444+0.00234107j, var(E): 0.03409627
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13540/ 20000/ t/epoch=1.05............. Loss: 0.14346850, mean(E): -19.23119730+0.00263536j, var(E): 0.04119617
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13550/ 20000/ t/epoch=1.05............. Loss: -0.33194730, mean(E): -19.23060466+0.00070840j, var(E): 0.03447540
-0.0
tensor(18.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13560/ 20000/ t/epoch=1.05............. Loss: 0.20026382, mean(E): -19.22760782-0.00328655j, var(E): 0.04000879
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13570/ 20000/ t/epoch=1.05............. Loss: 0.17755985, mean(E): -19.23086844-0.00059412j, var(E): 0.05933234
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13580/ 20000/ t/epoch=1.05............. Loss: -0.37664792, mean(E): -19.19596625+0.00287861j, var(E): 0.11673401
-0.0
tensor(18.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13590/ 20000/ t/epoch=1.05............. Loss: -0.16087674, mean(E): -19.22215866+0.00136139j, var(E): 0.03985764
-0.0
tensor(18.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13600/ 20000/ t/epoch=1.05............. Loss: -0.03678604, mean(E): -19.20067921-0.00371270j, var(E): 0.05222679
-0.0
tensor(18.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13610/ 20000/ t/epoch=1.05............. Loss: -0.07076576, mean(E): -19.23463137-0.00411658j, var(E): 0.04865290
-0.0
tensor(18.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13620/ 20000/ t/epoch=1.05............. Loss: 0.20194569, mean(E): -19.24419224+0.00047281j, var(E): 0.03505768
-0.0
tensor(18.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13630/ 20000/ t/epoch=1.05............. Loss: -0.10082409, mean(E): -19.21671405-0.00531730j, var(E): 0.03529009
-0.0
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13640/ 20000/ t/epoch=1.05............. Loss: -0.18290316, mean(E): -19.20894315+0.00926657j, var(E): 0.05555983
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13650/ 20000/ t/epoch=1.05............. Loss: -0.01548712, mean(E): -19.23613405-0.00376753j, var(E): 0.05115362
-0.0
tensor(18.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13660/ 20000/ t/epoch=1.04............. Loss: 0.03808115, mean(E): -19.22272984-0.00944401j, var(E): 0.02778591
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13670/ 20000/ t/epoch=1.05............. Loss: -0.11449006, mean(E): -19.20318628-0.01275512j, var(E): 0.04776395
-0.0
tensor(18.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13680/ 20000/ t/epoch=1.05............. Loss: 0.11372503, mean(E): -19.23331122+0.00100785j, var(E): 0.04363989
-0.0
tensor(18.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13690/ 20000/ t/epoch=1.05............. Loss: -0.17364518, mean(E): -19.23216804-0.00848802j, var(E): 0.04829265
-0.0
tensor(18.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13700/ 20000/ t/epoch=1.05............. Loss: 0.06097603, mean(E): -19.23876106-0.00300424j, var(E): 0.02304534
-0.0
tensor(18.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13710/ 20000/ t/epoch=1.05............. Loss: 0.16492570, mean(E): -19.21377130-0.00475595j, var(E): 0.03391462
-0.0
tensor(18.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13720/ 20000/ t/epoch=1.05............. Loss: -0.15906324, mean(E): -19.20361283-0.00085699j, var(E): 0.05444977
-0.0
tensor(18.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13730/ 20000/ t/epoch=1.05............. Loss: 0.06209349, mean(E): -19.23772595-0.00448199j, var(E): 0.03247582
-0.0
tensor(18.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13740/ 20000/ t/epoch=1.05............. Loss: -0.22995395, mean(E): -19.22067597+0.00225021j, var(E): 0.03492292
-0.0
tensor(18.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13750/ 20000/ t/epoch=1.06............. Loss: 0.01543347, mean(E): -19.20954796+0.00236551j, var(E): 0.05316361
-0.0
tensor(18.6040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13760/ 20000/ t/epoch=1.05............. Loss: -0.04763283, mean(E): -19.22403450+0.00800412j, var(E): 0.03384737
-0.0
tensor(18.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13770/ 20000/ t/epoch=1.05............. Loss: -0.16003696, mean(E): -19.21870131+0.00121087j, var(E): 0.05031716
-0.0
tensor(18.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13780/ 20000/ t/epoch=1.05............. Loss: -0.05924243, mean(E): -19.21970085+0.00231760j, var(E): 0.03994196
-0.0
tensor(18.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13790/ 20000/ t/epoch=1.05............. Loss: 0.12755076, mean(E): -19.20998866+0.00457933j, var(E): 0.05090671
-0.0
tensor(18.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13800/ 20000/ t/epoch=1.05............. Loss: 0.01706548, mean(E): -19.21440996-0.00128527j, var(E): 0.03255964
-0.0
tensor(18.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13810/ 20000/ t/epoch=1.05............. Loss: 0.09729485, mean(E): -19.22315765-0.00168050j, var(E): 0.02130809
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13820/ 20000/ t/epoch=1.04............. Loss: 0.09534326, mean(E): -19.25331435-0.00595836j, var(E): 0.05201106
-0.0
tensor(18.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13830/ 20000/ t/epoch=1.04............. Loss: -0.44409347, mean(E): -19.23348192-0.00041703j, var(E): 0.03561960
-0.0
tensor(18.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13840/ 20000/ t/epoch=1.06............. Loss: 0.07087645, mean(E): -19.20905827-0.00657479j, var(E): 0.06460468
-0.0
tensor(18.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13850/ 20000/ t/epoch=1.04............. Loss: -0.13710005, mean(E): -19.20905654+0.00042473j, var(E): 0.03958035
-0.0
tensor(18.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13860/ 20000/ t/epoch=1.04............. Loss: -0.19523495, mean(E): -19.21538072-0.00304843j, var(E): 0.03819683
-0.0
tensor(18.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13870/ 20000/ t/epoch=1.04............. Loss: -0.26229304, mean(E): -19.23204461-0.00447983j, var(E): 0.04705556
-0.0
tensor(18.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13880/ 20000/ t/epoch=1.05............. Loss: -0.20057888, mean(E): -19.20415060-0.00288073j, var(E): 0.03318900
-0.0
tensor(18.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13890/ 20000/ t/epoch=1.05............. Loss: -0.14422294, mean(E): -19.22184155+0.00012855j, var(E): 0.03496367
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13900/ 20000/ t/epoch=1.06............. Loss: 0.11481062, mean(E): -19.22319384+0.00615425j, var(E): 0.04934479
-0.0
tensor(18.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13910/ 20000/ t/epoch=1.05............. Loss: 0.04332335, mean(E): -19.21197311+0.00348462j, var(E): 0.02813966
-0.0
tensor(18.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13920/ 20000/ t/epoch=1.05............. Loss: 0.18506173, mean(E): -19.24387941-0.00138866j, var(E): 0.03080323
-0.0
tensor(18.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13930/ 20000/ t/epoch=1.06............. Loss: -0.04195689, mean(E): -19.21554666+0.00427767j, var(E): 0.02752746
-0.0
tensor(18.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13940/ 20000/ t/epoch=1.05............. Loss: 0.03327014, mean(E): -19.22785612-0.00081415j, var(E): 0.02821002
-0.0
tensor(18.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13950/ 20000/ t/epoch=1.05............. Loss: 0.02696797, mean(E): -19.21742980+0.00448795j, var(E): 0.02558210
-0.0
tensor(18.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13960/ 20000/ t/epoch=1.05............. Loss: -0.05429020, mean(E): -19.21308229-0.00279366j, var(E): 0.03477682
-0.0
tensor(18.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13970/ 20000/ t/epoch=1.05............. Loss: 0.05968313, mean(E): -19.21432960-0.00454541j, var(E): 0.03589045
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13980/ 20000/ t/epoch=1.05............. Loss: -0.05574237, mean(E): -19.20609448+0.00404098j, var(E): 0.04288234
-0.0
tensor(18.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13990/ 20000/ t/epoch=1.05............. Loss: -0.01250096, mean(E): -19.21277422+0.00316649j, var(E): 0.04336715
-0.0
tensor(18.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14000/ 20000/ t/epoch=1.05............. Loss: -0.01245496, mean(E): -19.23560319+0.00963627j, var(E): 0.03422982
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14010/ 20000/ t/epoch=1.06............. Loss: 0.18591770, mean(E): -19.23045405+0.00505403j, var(E): 0.03562089
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14020/ 20000/ t/epoch=1.05............. Loss: 0.09562224, mean(E): -19.23702503+0.00034487j, var(E): 0.03746764
-0.0
tensor(18.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14030/ 20000/ t/epoch=1.06............. Loss: 0.24493596, mean(E): -19.21315195+0.00040897j, var(E): 0.03930955
-0.0
tensor(18.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14040/ 20000/ t/epoch=1.04............. Loss: -0.24079753, mean(E): -19.20538315-0.00636878j, var(E): 0.03962136
-0.0
tensor(18.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14050/ 20000/ t/epoch=1.04............. Loss: 0.18923220, mean(E): -19.22766834-0.00009574j, var(E): 0.03559310
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14060/ 20000/ t/epoch=1.05............. Loss: -0.12501827, mean(E): -19.20791159-0.00431483j, var(E): 0.03455126
-0.0
tensor(18.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14070/ 20000/ t/epoch=1.05............. Loss: -0.35634375, mean(E): -19.20618772+0.00309359j, var(E): 0.06077065
-0.0
tensor(18.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14080/ 20000/ t/epoch=1.04............. Loss: 0.02734332, mean(E): -19.22159775+0.00264143j, var(E): 0.05917928
-0.0
tensor(18.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14090/ 20000/ t/epoch=1.05............. Loss: -0.06660872, mean(E): -19.23511260-0.00714129j, var(E): 0.03962955
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14100/ 20000/ t/epoch=1.05............. Loss: -0.25561024, mean(E): -19.20698336+0.00415406j, var(E): 0.03621663
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14110/ 20000/ t/epoch=1.05............. Loss: -0.06999804, mean(E): -19.19953377-0.00963578j, var(E): 0.03404961
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14120/ 20000/ t/epoch=1.05............. Loss: 0.13599227, mean(E): -19.23921635+0.00067011j, var(E): 0.02231909
-0.0
tensor(18.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14130/ 20000/ t/epoch=1.05............. Loss: -0.06037034, mean(E): -19.19750481+0.00650910j, var(E): 0.04374781
-0.0
tensor(18.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14140/ 20000/ t/epoch=1.05............. Loss: 0.18327877, mean(E): -19.23358161+0.00087132j, var(E): 0.01840185
-0.0
tensor(18.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14150/ 20000/ t/epoch=1.05............. Loss: -0.03360703, mean(E): -19.18581257+0.00634467j, var(E): 0.04366826
-0.0
tensor(18.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14160/ 20000/ t/epoch=1.05............. Loss: -0.00749147, mean(E): -19.22021485+0.00285365j, var(E): 0.02935588
-0.0
tensor(18.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14170/ 20000/ t/epoch=1.06............. Loss: -0.05597270, mean(E): -19.18962181-0.00727148j, var(E): 0.05184060
-0.0
tensor(18.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14180/ 20000/ t/epoch=1.05............. Loss: -0.32205385, mean(E): -19.20176346+0.00875630j, var(E): 0.03640383
-0.0
tensor(18.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14190/ 20000/ t/epoch=1.05............. Loss: -0.12085824, mean(E): -19.23080133+0.00416556j, var(E): 0.04124554
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14200/ 20000/ t/epoch=1.05............. Loss: -0.09332298, mean(E): -19.22584944+0.00758865j, var(E): 0.02815869
-0.0
tensor(18.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14210/ 20000/ t/epoch=1.05............. Loss: 0.35690484, mean(E): -19.21573389-0.00425864j, var(E): 0.03821199
-0.0
tensor(18.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14220/ 20000/ t/epoch=1.05............. Loss: -0.06086039, mean(E): -19.20292531-0.00202865j, var(E): 0.08526340
-0.0
tensor(18.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14230/ 20000/ t/epoch=1.05............. Loss: -0.04180447, mean(E): -19.21911691+0.00433796j, var(E): 0.05136973
-0.0
tensor(18.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14240/ 20000/ t/epoch=1.06............. Loss: -0.09863753, mean(E): -19.20114925+0.00370781j, var(E): 0.05331138
-0.0
tensor(18.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14250/ 20000/ t/epoch=1.05............. Loss: 0.09838409, mean(E): -19.23150785-0.01228129j, var(E): 0.05315845
-0.0
tensor(18.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14260/ 20000/ t/epoch=1.05............. Loss: 0.06119954, mean(E): -19.21565374+0.00363007j, var(E): 0.02999624
-0.0
tensor(18.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14270/ 20000/ t/epoch=1.05............. Loss: 0.11124571, mean(E): -19.23603333-0.00571095j, var(E): 0.03034232
-0.0
tensor(18.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14280/ 20000/ t/epoch=1.05............. Loss: -0.02934767, mean(E): -19.22867827-0.00488767j, var(E): 0.04880335
-0.0
tensor(18.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14290/ 20000/ t/epoch=1.05............. Loss: -0.17918788, mean(E): -19.24375534+0.00418081j, var(E): 0.03397831
-0.0
tensor(18.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14300/ 20000/ t/epoch=1.05............. Loss: -0.05612601, mean(E): -19.21681359+0.00302196j, var(E): 0.06579675
-0.0
tensor(18.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14310/ 20000/ t/epoch=1.05............. Loss: 0.18597938, mean(E): -19.23026652-0.00814304j, var(E): 0.03990998
-0.0
tensor(18.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14320/ 20000/ t/epoch=1.06............. Loss: -0.02336275, mean(E): -19.23851060-0.00282943j, var(E): 0.03168147
-0.0
tensor(18.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14330/ 20000/ t/epoch=1.05............. Loss: 0.15410775, mean(E): -19.23123027-0.00373103j, var(E): 0.03218368
-0.0
tensor(18.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14340/ 20000/ t/epoch=1.04............. Loss: 0.06686780, mean(E): -19.21222364-0.00131759j, var(E): 0.04799577
-0.0
tensor(18.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14350/ 20000/ t/epoch=1.05............. Loss: 0.01580748, mean(E): -19.23802028-0.00209777j, var(E): 0.02064923
-0.0
tensor(18.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14360/ 20000/ t/epoch=1.05............. Loss: 0.05569196, mean(E): -19.20604138-0.00238934j, var(E): 0.04730707
-0.0
tensor(18.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14370/ 20000/ t/epoch=1.05............. Loss: -0.09676926, mean(E): -19.20024276-0.00597920j, var(E): 0.07129363
-0.0
tensor(18.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14380/ 20000/ t/epoch=1.05............. Loss: -0.20297809, mean(E): -19.21555598-0.00686426j, var(E): 0.02259682
-0.0
tensor(18.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14390/ 20000/ t/epoch=1.05............. Loss: -0.02948983, mean(E): -19.20794627+0.00217107j, var(E): 0.02611090
-0.0
tensor(18.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14400/ 20000/ t/epoch=1.05............. Loss: 0.18398133, mean(E): -19.23673248+0.00375777j, var(E): 0.03630947
-0.0
tensor(18.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14410/ 20000/ t/epoch=1.04............. Loss: -0.04358259, mean(E): -19.22776841+0.00393158j, var(E): 0.02695744
-0.0
tensor(18.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14420/ 20000/ t/epoch=1.04............. Loss: 0.12516382, mean(E): -19.22987315-0.00068759j, var(E): 0.03907861
-0.0
tensor(18.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14430/ 20000/ t/epoch=1.05............. Loss: 0.01020026, mean(E): -19.22464349-0.00235114j, var(E): 0.03025236
-0.0
tensor(18.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14440/ 20000/ t/epoch=1.05............. Loss: -0.05055632, mean(E): -19.21100394+0.00423905j, var(E): 0.04786620
-0.0
tensor(18.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14450/ 20000/ t/epoch=1.05............. Loss: 0.01944543, mean(E): -19.23301715-0.00313696j, var(E): 0.03695239
-0.0
tensor(18.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14460/ 20000/ t/epoch=1.05............. Loss: -0.08941980, mean(E): -19.22799592+0.00282543j, var(E): 0.04935106
-0.0
tensor(18.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14470/ 20000/ t/epoch=1.05............. Loss: 0.13731461, mean(E): -19.21673245-0.00344422j, var(E): 0.02468976
-0.0
tensor(18.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14480/ 20000/ t/epoch=1.04............. Loss: -0.15513974, mean(E): -19.23620431-0.00137678j, var(E): 0.03281040
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14490/ 20000/ t/epoch=1.05............. Loss: -0.06437456, mean(E): -19.22887537-0.00512728j, var(E): 0.04188524
-0.0
tensor(18.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14500/ 20000/ t/epoch=1.05............. Loss: 0.20382499, mean(E): -19.23659607-0.00228719j, var(E): 0.02779042
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14510/ 20000/ t/epoch=1.06............. Loss: -0.03556090, mean(E): -19.22329323+0.00636242j, var(E): 0.02593019
-0.0
tensor(18.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14520/ 20000/ t/epoch=1.06............. Loss: -0.10786852, mean(E): -19.21298502-0.00004326j, var(E): 0.02863273
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14530/ 20000/ t/epoch=1.05............. Loss: 0.08094760, mean(E): -19.22120246+0.00637735j, var(E): 0.03418588
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14540/ 20000/ t/epoch=1.05............. Loss: -0.06967492, mean(E): -19.22045565-0.00094868j, var(E): 0.03581820
-0.0
tensor(18.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14550/ 20000/ t/epoch=1.05............. Loss: 0.13113991, mean(E): -19.22421995+0.00400019j, var(E): 0.04006845
-0.0
tensor(18.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14560/ 20000/ t/epoch=1.05............. Loss: 0.06768377, mean(E): -19.21978321-0.00611014j, var(E): 0.03498760
-0.0
tensor(18.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14570/ 20000/ t/epoch=1.05............. Loss: 0.19603773, mean(E): -19.23210506-0.00641104j, var(E): 0.03789559
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14580/ 20000/ t/epoch=1.05............. Loss: -0.00154701, mean(E): -19.22054194+0.00003705j, var(E): 0.03497141
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14590/ 20000/ t/epoch=1.05............. Loss: 0.25324882, mean(E): -19.23421062+0.00932267j, var(E): 0.03393270
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14600/ 20000/ t/epoch=1.05............. Loss: 0.11898270, mean(E): -19.25362250+0.00316324j, var(E): 0.05663472
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14610/ 20000/ t/epoch=1.05............. Loss: 0.15018463, mean(E): -19.24168776+0.00234695j, var(E): 0.05984782
-0.0
tensor(18.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14620/ 20000/ t/epoch=1.05............. Loss: 0.00648114, mean(E): -19.23040011-0.00352308j, var(E): 0.03119076
-0.0
tensor(18.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14630/ 20000/ t/epoch=1.05............. Loss: -0.10727400, mean(E): -19.22344129+0.00009504j, var(E): 0.03111929
-0.0
tensor(18.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14640/ 20000/ t/epoch=1.05............. Loss: 0.00931076, mean(E): -19.23421709+0.01252174j, var(E): 0.04075267
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14650/ 20000/ t/epoch=1.06............. Loss: 0.14537856, mean(E): -19.24233180-0.00550872j, var(E): 0.02466736
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14660/ 20000/ t/epoch=1.05............. Loss: 0.15224681, mean(E): -19.23130080-0.00177321j, var(E): 0.08421675
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14670/ 20000/ t/epoch=1.05............. Loss: -0.16270563, mean(E): -19.20854940+0.00226841j, var(E): 0.02467394
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14680/ 20000/ t/epoch=1.05............. Loss: -0.21256468, mean(E): -19.21846592+0.01024722j, var(E): 0.04322761
-0.0
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14690/ 20000/ t/epoch=1.05............. Loss: -0.22215473, mean(E): -19.22476198+0.00441422j, var(E): 0.11397394
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14700/ 20000/ t/epoch=1.05............. Loss: -0.17678697, mean(E): -19.20211169-0.00568867j, var(E): 0.03210645
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14710/ 20000/ t/epoch=1.04............. Loss: 0.00926080, mean(E): -19.21314264+0.00031119j, var(E): 0.04310449
-0.0
tensor(18.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14720/ 20000/ t/epoch=1.05............. Loss: 0.11722412, mean(E): -19.22462232-0.00643869j, var(E): 0.05499360
-0.0
tensor(18.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14730/ 20000/ t/epoch=1.04............. Loss: -0.01206289, mean(E): -19.21857287+0.00137742j, var(E): 0.03146576
-0.0
tensor(18.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14740/ 20000/ t/epoch=1.04............. Loss: 0.13125135, mean(E): -19.23488239-0.00877837j, var(E): 0.03398319
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14750/ 20000/ t/epoch=1.04............. Loss: -0.09657057, mean(E): -19.22706140-0.00133576j, var(E): 0.02787238
-0.0
tensor(18.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14760/ 20000/ t/epoch=1.05............. Loss: -0.12408699, mean(E): -19.21684744+0.00290175j, var(E): 0.03240094
-0.0
tensor(18.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14770/ 20000/ t/epoch=1.05............. Loss: -0.17156619, mean(E): -19.22471076-0.00148295j, var(E): 0.02818022
-0.0
tensor(18.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14780/ 20000/ t/epoch=1.05............. Loss: 0.08657933, mean(E): -19.21297101+0.00296476j, var(E): 0.04747355
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14790/ 20000/ t/epoch=1.05............. Loss: 0.22492987, mean(E): -19.23486211-0.00028904j, var(E): 0.02939717
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14800/ 20000/ t/epoch=1.05............. Loss: -0.11996360, mean(E): -19.23596412+0.00036966j, var(E): 0.02524849
-0.0
tensor(18.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14810/ 20000/ t/epoch=1.05............. Loss: -0.14807652, mean(E): -19.19637614-0.00141914j, var(E): 0.03452291
-0.0
tensor(18.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14820/ 20000/ t/epoch=1.05............. Loss: -0.13952851, mean(E): -19.19572328+0.00313911j, var(E): 0.06364762
-0.0
tensor(18.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14830/ 20000/ t/epoch=1.05............. Loss: 0.07748518, mean(E): -19.23039323-0.00200028j, var(E): 0.03116055
-0.0
tensor(18.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14840/ 20000/ t/epoch=1.05............. Loss: 0.11734872, mean(E): -19.21845510-0.00189074j, var(E): 0.03557327
-0.0
tensor(18.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14850/ 20000/ t/epoch=1.05............. Loss: -0.02750402, mean(E): -19.22955855+0.00119672j, var(E): 0.03633826
-0.0
tensor(18.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14860/ 20000/ t/epoch=1.05............. Loss: 0.02307088, mean(E): -19.21590356-0.00280022j, var(E): 0.01869416
-0.0
tensor(18.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14870/ 20000/ t/epoch=1.05............. Loss: -0.16142262, mean(E): -19.21477090+0.00573809j, var(E): 0.04078355
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14880/ 20000/ t/epoch=1.05............. Loss: -0.16781059, mean(E): -19.22237614+0.00676883j, var(E): 0.03593598
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14890/ 20000/ t/epoch=1.05............. Loss: -0.04817109, mean(E): -19.23898361+0.00268083j, var(E): 0.02308335
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14900/ 20000/ t/epoch=1.05............. Loss: -0.00622602, mean(E): -19.21956929+0.00405805j, var(E): 0.02217633
-0.0
tensor(18.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14910/ 20000/ t/epoch=1.05............. Loss: -0.01055984, mean(E): -19.21016318+0.00414351j, var(E): 0.03215496
-0.0
tensor(18.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14920/ 20000/ t/epoch=1.06............. Loss: 0.22910634, mean(E): -19.22460703+0.00466394j, var(E): 0.02672304
-0.0
tensor(18.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14930/ 20000/ t/epoch=1.06............. Loss: -0.21816865, mean(E): -19.22464778-0.00474208j, var(E): 0.02981150
-0.0
tensor(18.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14940/ 20000/ t/epoch=1.05............. Loss: -0.17801210, mean(E): -19.20931852-0.00853665j, var(E): 0.03871091
-0.0
tensor(18.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14950/ 20000/ t/epoch=1.05............. Loss: -0.16369994, mean(E): -19.24010521+0.00255842j, var(E): 0.07150707
-0.0
tensor(18.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14960/ 20000/ t/epoch=1.05............. Loss: -0.38255577, mean(E): -19.21233356-0.00260163j, var(E): 0.05265120
-0.0
tensor(18.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14970/ 20000/ t/epoch=1.05............. Loss: 0.03709643, mean(E): -19.22587074+0.00305424j, var(E): 0.04054049
-0.0
tensor(18.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14980/ 20000/ t/epoch=1.05............. Loss: 0.14595739, mean(E): -19.24158255-0.00483238j, var(E): 0.05158840
-0.0
tensor(18.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14990/ 20000/ t/epoch=1.05............. Loss: 0.08886275, mean(E): -19.24086579-0.00604252j, var(E): 0.05548060
-0.0
tensor(18.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15000/ 20000/ t/epoch=1.05............. Loss: -0.23332474, mean(E): -19.21861750-0.00827736j, var(E): 0.03694020
-0.0
tensor(18.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15010/ 20000/ t/epoch=1.05............. Loss: 0.04963715, mean(E): -19.21090429-0.00365135j, var(E): 0.03026904
-0.0
tensor(18.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15020/ 20000/ t/epoch=1.05............. Loss: 0.12358528, mean(E): -19.22144181+0.00398347j, var(E): 0.02836106
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15030/ 20000/ t/epoch=1.06............. Loss: 0.04190058, mean(E): -19.24028123+0.00565551j, var(E): 0.02973329
-0.0
tensor(18.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15040/ 20000/ t/epoch=1.05............. Loss: -0.18595118, mean(E): -19.22407913+0.00312105j, var(E): 0.02854482
-0.0
tensor(18.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15050/ 20000/ t/epoch=1.04............. Loss: -0.17117522, mean(E): -19.24386732-0.00240759j, var(E): 0.06533086
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15060/ 20000/ t/epoch=1.05............. Loss: 0.18128026, mean(E): -19.21850855-0.00602579j, var(E): 0.09371755
-0.0
tensor(18.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15070/ 20000/ t/epoch=1.05............. Loss: 0.05321187, mean(E): -19.23260547-0.00591416j, var(E): 0.03487767
-0.0
tensor(18.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15080/ 20000/ t/epoch=1.05............. Loss: -0.14148263, mean(E): -19.23562744+0.00599010j, var(E): 0.03067592
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15090/ 20000/ t/epoch=1.05............. Loss: 0.22441236, mean(E): -19.23860262+0.00819024j, var(E): 0.03639432
-0.0
tensor(18.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15100/ 20000/ t/epoch=1.06............. Loss: 0.26053212, mean(E): -19.21177983+0.00219806j, var(E): 0.05280441
-0.0
tensor(18.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15110/ 20000/ t/epoch=1.05............. Loss: 0.17517265, mean(E): -19.22196475-0.00023510j, var(E): 0.02006516
-0.0
tensor(18.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15120/ 20000/ t/epoch=1.05............. Loss: -0.01511854, mean(E): -19.23664321+0.00527909j, var(E): 0.03795917
-0.0
tensor(18.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15130/ 20000/ t/epoch=1.05............. Loss: 0.27718857, mean(E): -19.21648661+0.00409938j, var(E): 0.02362701
-0.0
tensor(18.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15140/ 20000/ t/epoch=1.05............. Loss: 0.21904390, mean(E): -19.21261382-0.00284755j, var(E): 0.03376977
-0.0
tensor(18.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15150/ 20000/ t/epoch=1.05............. Loss: 0.03607812, mean(E): -19.22314340-0.00597699j, var(E): 0.03621263
-0.0
tensor(18.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15160/ 20000/ t/epoch=1.05............. Loss: -0.07242364, mean(E): -19.20451400-0.00193302j, var(E): 0.01946680
-0.0
tensor(18.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15170/ 20000/ t/epoch=1.05............. Loss: -0.13731798, mean(E): -19.22336912-0.00382587j, var(E): 0.03609654
-0.0
tensor(18.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15180/ 20000/ t/epoch=1.05............. Loss: -0.00694748, mean(E): -19.22572670-0.00268505j, var(E): 0.02351110
-0.0
tensor(18.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15190/ 20000/ t/epoch=1.05............. Loss: -0.30482624, mean(E): -19.18901054-0.00097610j, var(E): 0.04694331
-0.0
tensor(18.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15200/ 20000/ t/epoch=1.05............. Loss: -0.09664442, mean(E): -19.21435500-0.00707130j, var(E): 0.03137310
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15210/ 20000/ t/epoch=1.05............. Loss: 0.06280886, mean(E): -19.24622909-0.00311132j, var(E): 0.05767289
-0.0
tensor(18.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15220/ 20000/ t/epoch=1.05............. Loss: 0.18057925, mean(E): -19.22958555+0.00550990j, var(E): 0.05171932
-0.0
tensor(18.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15230/ 20000/ t/epoch=1.05............. Loss: 0.21526147, mean(E): -19.20870364-0.00083893j, var(E): 0.04833921
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15240/ 20000/ t/epoch=1.05............. Loss: -0.08033421, mean(E): -19.23373122-0.00009779j, var(E): 0.04463405
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15250/ 20000/ t/epoch=1.06............. Loss: 0.10587583, mean(E): -19.24103730-0.00201316j, var(E): 0.04010172
-0.0
tensor(18.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15260/ 20000/ t/epoch=1.05............. Loss: 0.24538064, mean(E): -19.21921116+0.00201316j, var(E): 0.02736784
-0.0
tensor(18.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15270/ 20000/ t/epoch=1.05............. Loss: 0.04751680, mean(E): -19.22146662-0.00105967j, var(E): 0.05163282
-0.0
tensor(18.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15280/ 20000/ t/epoch=1.04............. Loss: 0.08373378, mean(E): -19.21128312-0.01285417j, var(E): 0.03154638
-0.0
tensor(18.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15290/ 20000/ t/epoch=1.05............. Loss: -0.16989318, mean(E): -19.22564374+0.00477589j, var(E): 0.03786488
-0.0
tensor(18.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15300/ 20000/ t/epoch=1.05............. Loss: -0.10801283, mean(E): -19.20983753+0.00330922j, var(E): 0.02761204
-0.0
tensor(18.6736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15310/ 20000/ t/epoch=1.05............. Loss: 0.10889524, mean(E): -19.21489401+0.00576612j, var(E): 0.02877860
-0.0
tensor(18.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15320/ 20000/ t/epoch=1.05............. Loss: 0.03961231, mean(E): -19.22200296-0.00173522j, var(E): 0.03187281
-0.0
tensor(18.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15330/ 20000/ t/epoch=1.05............. Loss: 0.03461578, mean(E): -19.23314914+0.00730423j, var(E): 0.02539564
-0.0
tensor(18.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15340/ 20000/ t/epoch=1.05............. Loss: 0.15724930, mean(E): -19.23018517+0.00031679j, var(E): 0.10883265
-0.0
tensor(18.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15350/ 20000/ t/epoch=1.05............. Loss: -0.14423019, mean(E): -19.22286705+0.01029111j, var(E): 0.03323495
-0.0
tensor(18.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15360/ 20000/ t/epoch=1.05............. Loss: -0.04727492, mean(E): -19.23723022+0.00302293j, var(E): 0.03493307
-0.0
tensor(18.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15370/ 20000/ t/epoch=1.06............. Loss: -0.00948157, mean(E): -19.23706943+0.00629485j, var(E): 0.02889717
-0.0
tensor(18.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15380/ 20000/ t/epoch=1.06............. Loss: 0.23619153, mean(E): -19.23114685+0.00295808j, var(E): 0.02841472
-0.0
tensor(18.6766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15390/ 20000/ t/epoch=1.04............. Loss: -0.02279041, mean(E): -19.21971611-0.00156527j, var(E): 0.03714833
-0.0
tensor(18.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15400/ 20000/ t/epoch=1.05............. Loss: 0.11042365, mean(E): -19.21362052-0.00297724j, var(E): 0.03848102
-0.0
tensor(18.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15410/ 20000/ t/epoch=1.04............. Loss: -0.08373252, mean(E): -19.23136357+0.00141080j, var(E): 0.03577793
-0.0
tensor(18.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15420/ 20000/ t/epoch=1.06............. Loss: -0.10069221, mean(E): -19.22598668-0.00089950j, var(E): 0.02132559
-0.0
tensor(18.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15430/ 20000/ t/epoch=1.06............. Loss: -0.22455150, mean(E): -19.23139491+0.01154730j, var(E): 0.03861979
-0.0
tensor(18.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15440/ 20000/ t/epoch=1.05............. Loss: -0.24070892, mean(E): -19.21326788+0.00447996j, var(E): 0.03561489
-0.0
tensor(18.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15450/ 20000/ t/epoch=1.05............. Loss: 0.17654007, mean(E): -19.21886418-0.00056771j, var(E): 0.02525782
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15460/ 20000/ t/epoch=1.04............. Loss: 0.38387071, mean(E): -19.22872818-0.00456589j, var(E): 0.02269497
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15470/ 20000/ t/epoch=1.05............. Loss: -0.09230275, mean(E): -19.22699284+0.00373222j, var(E): 0.03228456
-0.0
tensor(18.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15480/ 20000/ t/epoch=1.05............. Loss: -0.00544406, mean(E): -19.23077685+0.00291946j, var(E): 0.07135610
-0.0
tensor(18.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15490/ 20000/ t/epoch=1.04............. Loss: -0.05174601, mean(E): -19.21778187+0.01075040j, var(E): 0.03344023
-0.0
tensor(18.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15500/ 20000/ t/epoch=1.05............. Loss: -0.06910982, mean(E): -19.22746684-0.00001558j, var(E): 0.03345423
-0.0
tensor(18.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15510/ 20000/ t/epoch=1.05............. Loss: 0.09824654, mean(E): -19.23215500+0.00466899j, var(E): 0.02840071
-0.0
tensor(18.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15520/ 20000/ t/epoch=1.05............. Loss: 0.22260341, mean(E): -19.23185299-0.00880072j, var(E): 0.03412634
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15530/ 20000/ t/epoch=1.05............. Loss: 0.14569032, mean(E): -19.21847972-0.00788446j, var(E): 0.02983485
-0.0
tensor(18.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15540/ 20000/ t/epoch=1.05............. Loss: -0.07181513, mean(E): -19.23351889+0.00139248j, var(E): 0.02610160
-0.0
tensor(18.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15550/ 20000/ t/epoch=1.04............. Loss: 0.22480813, mean(E): -19.22985360+0.00548769j, var(E): 0.02493409
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15560/ 20000/ t/epoch=1.05............. Loss: 0.01192794, mean(E): -19.23608349+0.00089236j, var(E): 0.02917257
-0.0
tensor(18.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15570/ 20000/ t/epoch=1.05............. Loss: -0.14113076, mean(E): -19.22048932+0.00069233j, var(E): 0.03607043
-0.0
tensor(18.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15580/ 20000/ t/epoch=1.05............. Loss: 0.07718353, mean(E): -19.21322880+0.00615688j, var(E): 0.03065150
-0.0
tensor(18.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15590/ 20000/ t/epoch=1.05............. Loss: 0.12131587, mean(E): -19.22014534+0.00238839j, var(E): 0.03090854
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15600/ 20000/ t/epoch=1.05............. Loss: -0.00930078, mean(E): -19.20176522-0.00619429j, var(E): 0.05203906
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15610/ 20000/ t/epoch=1.05............. Loss: 0.20258743, mean(E): -19.22246164-0.00342547j, var(E): 0.04685567
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15620/ 20000/ t/epoch=1.05............. Loss: 0.13962070, mean(E): -19.21334470+0.00341173j, var(E): 0.02920316
-0.0
tensor(18.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15630/ 20000/ t/epoch=1.05............. Loss: 0.19082746, mean(E): -19.23134974-0.00225102j, var(E): 0.02807437
-0.0
tensor(18.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15640/ 20000/ t/epoch=1.05............. Loss: -0.21035800, mean(E): -19.21726289+0.00761921j, var(E): 0.03536393
-0.0
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15650/ 20000/ t/epoch=1.05............. Loss: 0.05431362, mean(E): -19.21562148-0.00307693j, var(E): 0.02912515
-0.0
tensor(18.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15660/ 20000/ t/epoch=1.05............. Loss: 0.29929082, mean(E): -19.22596748+0.00211542j, var(E): 0.04414718
-0.0
tensor(18.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15670/ 20000/ t/epoch=1.05............. Loss: 0.15418441, mean(E): -19.24289475+0.00222835j, var(E): 0.02230739
-0.0
tensor(18.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15680/ 20000/ t/epoch=1.05............. Loss: -0.13499743, mean(E): -19.22797186+0.00204861j, var(E): 0.04437471
-0.0
tensor(18.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15690/ 20000/ t/epoch=1.05............. Loss: -0.26905349, mean(E): -19.21692716+0.00835618j, var(E): 0.02202690
-0.0
tensor(18.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15700/ 20000/ t/epoch=1.05............. Loss: 0.11365420, mean(E): -19.21665473+0.00214086j, var(E): 0.04073947
-0.0
tensor(18.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15710/ 20000/ t/epoch=1.06............. Loss: -0.02353142, mean(E): -19.22758615+0.00552412j, var(E): 0.02821534
-0.0
tensor(18.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15720/ 20000/ t/epoch=1.05............. Loss: 0.09147525, mean(E): -19.20916888-0.00300032j, var(E): 0.03068237
-0.0
tensor(18.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15730/ 20000/ t/epoch=1.05............. Loss: 0.00299482, mean(E): -19.23360345+0.00131133j, var(E): 0.07135808
-0.0
tensor(18.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15740/ 20000/ t/epoch=1.05............. Loss: 0.20389401, mean(E): -19.22046244+0.00084054j, var(E): 0.02097586
-0.0
tensor(18.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15750/ 20000/ t/epoch=1.05............. Loss: 0.00263877, mean(E): -19.22966064+0.00143918j, var(E): 0.02586230
-0.0
tensor(18.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15760/ 20000/ t/epoch=1.05............. Loss: -0.19574820, mean(E): -19.23424010+0.00064736j, var(E): 0.02839414
-0.0
tensor(18.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15770/ 20000/ t/epoch=1.05............. Loss: 0.25316671, mean(E): -19.20893512-0.00356637j, var(E): 0.03076286
-0.0
tensor(18.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15780/ 20000/ t/epoch=1.04............. Loss: 0.07546983, mean(E): -19.22967492-0.00344913j, var(E): 0.03581994
-0.0
tensor(18.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15790/ 20000/ t/epoch=1.05............. Loss: -0.11300146, mean(E): -19.24853558+0.00619181j, var(E): 0.04134676
-0.0
tensor(18.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15800/ 20000/ t/epoch=1.05............. Loss: -0.09772897, mean(E): -19.20481322-0.00564409j, var(E): 0.02771211
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15810/ 20000/ t/epoch=1.05............. Loss: 0.20568258, mean(E): -19.21704409-0.01024758j, var(E): 0.04959388
-0.0
tensor(18.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15820/ 20000/ t/epoch=1.05............. Loss: -0.12172255, mean(E): -19.23207116+0.00248870j, var(E): 0.06964368
-0.0
tensor(18.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15830/ 20000/ t/epoch=1.05............. Loss: -0.12608654, mean(E): -19.21182911-0.01119123j, var(E): 0.03304613
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15840/ 20000/ t/epoch=1.05............. Loss: -0.09544413, mean(E): -19.21990742-0.00406136j, var(E): 0.03366082
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15850/ 20000/ t/epoch=1.04............. Loss: 0.11172014, mean(E): -19.22187616-0.00455192j, var(E): 0.03120977
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15860/ 20000/ t/epoch=1.05............. Loss: -0.01788870, mean(E): -19.19447594-0.00497366j, var(E): 0.04693273
-0.0
tensor(18.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15870/ 20000/ t/epoch=1.05............. Loss: -0.13133156, mean(E): -19.22261851-0.00461067j, var(E): 0.02554593
-0.0
tensor(18.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15880/ 20000/ t/epoch=1.05............. Loss: 0.01993501, mean(E): -19.22320332+0.00664375j, var(E): 0.02519696
-0.0
tensor(18.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15890/ 20000/ t/epoch=1.04............. Loss: 0.02280890, mean(E): -19.23613563+0.00105307j, var(E): 0.02681403
-0.0
tensor(18.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15900/ 20000/ t/epoch=1.04............. Loss: 0.09166623, mean(E): -19.21112659+0.00091656j, var(E): 0.03798089
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15910/ 20000/ t/epoch=1.05............. Loss: -0.00448523, mean(E): -19.21819161-0.00485393j, var(E): 0.02820599
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15920/ 20000/ t/epoch=1.05............. Loss: -0.17312124, mean(E): -19.22382257+0.00304052j, var(E): 0.02873340
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15930/ 20000/ t/epoch=1.06............. Loss: 0.01894118, mean(E): -19.23274649-0.00095988j, var(E): 0.02102573
-0.0
tensor(18.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15940/ 20000/ t/epoch=1.05............. Loss: 0.18456322, mean(E): -19.23629769+0.00060028j, var(E): 0.02193295
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15950/ 20000/ t/epoch=1.05............. Loss: 0.04623620, mean(E): -19.21065955+0.00084977j, var(E): 0.03968098
-0.0
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15960/ 20000/ t/epoch=1.06............. Loss: -0.01441659, mean(E): -19.23522773+0.00979801j, var(E): 0.02199881
-0.0
tensor(18.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15970/ 20000/ t/epoch=1.04............. Loss: 0.04794860, mean(E): -19.21920636-0.00217248j, var(E): 0.02636199
-0.0
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15980/ 20000/ t/epoch=1.05............. Loss: -0.22286376, mean(E): -19.19817455-0.00396938j, var(E): 0.06523713
-0.0
tensor(18.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15990/ 20000/ t/epoch=1.05............. Loss: 0.00557987, mean(E): -19.23144747-0.00401478j, var(E): 0.02310048
-0.0
tensor(18.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16000/ 20000/ t/epoch=1.04............. Loss: 0.19110679, mean(E): -19.23083760-0.00235099j, var(E): 0.05092851
-0.0
tensor(18.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16010/ 20000/ t/epoch=1.05............. Loss: 0.22430230, mean(E): -19.21544788-0.00513531j, var(E): 0.02845070
-0.0
tensor(18.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16020/ 20000/ t/epoch=1.05............. Loss: 0.27303219, mean(E): -19.23961238+0.00707936j, var(E): 0.03458787
-0.0
tensor(18.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16030/ 20000/ t/epoch=1.05............. Loss: 0.07185227, mean(E): -19.22285433-0.00763582j, var(E): 0.02660175
-0.0
tensor(18.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16040/ 20000/ t/epoch=1.05............. Loss: -0.08956486, mean(E): -19.22093382+0.00343026j, var(E): 0.03624915
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16050/ 20000/ t/epoch=1.05............. Loss: -0.12869795, mean(E): -19.21259572-0.00179140j, var(E): 0.03433108
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16060/ 20000/ t/epoch=1.05............. Loss: 0.08165679, mean(E): -19.23442573+0.00048438j, var(E): 0.02105930
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16070/ 20000/ t/epoch=1.05............. Loss: 0.39162510, mean(E): -19.21972674-0.00166837j, var(E): 0.02493707
-0.0
tensor(18.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16080/ 20000/ t/epoch=1.05............. Loss: 0.03852160, mean(E): -19.20934502-0.00371077j, var(E): 0.03605533
-0.0
tensor(18.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16090/ 20000/ t/epoch=1.05............. Loss: -0.07100534, mean(E): -19.23364540-0.00256334j, var(E): 0.02256598
-0.0
tensor(18.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16100/ 20000/ t/epoch=1.05............. Loss: -0.20627928, mean(E): -19.20699427-0.00428939j, var(E): 0.04694956
-0.0
tensor(18.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16110/ 20000/ t/epoch=1.05............. Loss: 0.11057538, mean(E): -19.22690587-0.00206760j, var(E): 0.03106777
-0.0
tensor(18.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16120/ 20000/ t/epoch=1.05............. Loss: 0.13057331, mean(E): -19.22520370-0.00731090j, var(E): 0.02211043
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16130/ 20000/ t/epoch=1.04............. Loss: -0.01461966, mean(E): -19.20935024-0.00468351j, var(E): 0.08450972
-0.0
tensor(18.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16140/ 20000/ t/epoch=1.04............. Loss: 0.03365906, mean(E): -19.23049570-0.00327251j, var(E): 0.03582088
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16150/ 20000/ t/epoch=1.05............. Loss: 0.18174760, mean(E): -19.21848525-0.00361104j, var(E): 0.03074957
-0.0
tensor(18.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16160/ 20000/ t/epoch=1.06............. Loss: 0.13427554, mean(E): -19.23085605+0.00219300j, var(E): 0.04418913
-0.0
tensor(18.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16170/ 20000/ t/epoch=1.05............. Loss: -0.04224695, mean(E): -19.21840501-0.00911928j, var(E): 0.04409386
-0.0
tensor(18.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16180/ 20000/ t/epoch=1.05............. Loss: 0.03501715, mean(E): -19.20386724-0.00514553j, var(E): 0.02114785
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16190/ 20000/ t/epoch=1.05............. Loss: 0.06751191, mean(E): -19.24615938-0.00454590j, var(E): 0.03869883
-0.0
tensor(18.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16200/ 20000/ t/epoch=1.05............. Loss: 0.01566637, mean(E): -19.23279037-0.00926961j, var(E): 0.02591227
-0.0
tensor(18.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16210/ 20000/ t/epoch=1.05............. Loss: 0.16881119, mean(E): -19.22966852-0.00774985j, var(E): 0.03159026
-0.0
tensor(18.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16220/ 20000/ t/epoch=1.05............. Loss: 0.20421345, mean(E): -19.21534930+0.01285790j, var(E): 0.03895461
-0.0
tensor(18.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16230/ 20000/ t/epoch=1.04............. Loss: -0.03078792, mean(E): -19.21759137-0.00182437j, var(E): 0.03419502
-0.0
tensor(18.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16240/ 20000/ t/epoch=1.05............. Loss: -0.11046581, mean(E): -19.22684687+0.00100581j, var(E): 0.02277807
-0.0
tensor(18.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16250/ 20000/ t/epoch=1.05............. Loss: 0.01781622, mean(E): -19.23986957+0.00230508j, var(E): 0.02336140
-0.0
tensor(18.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16260/ 20000/ t/epoch=1.05............. Loss: -0.08186613, mean(E): -19.21486964-0.00070007j, var(E): 0.01785118
-0.0
tensor(18.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16270/ 20000/ t/epoch=1.05............. Loss: 0.10244046, mean(E): -19.18867432-0.00129478j, var(E): 0.05777974
-0.0
tensor(18.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16280/ 20000/ t/epoch=1.04............. Loss: 0.07578233, mean(E): -19.22283016+0.00750573j, var(E): 0.02182359
-0.0
tensor(18.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16290/ 20000/ t/epoch=1.05............. Loss: 0.19306136, mean(E): -19.23386277+0.00151864j, var(E): 0.04617515
-0.0
tensor(18.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16300/ 20000/ t/epoch=1.05............. Loss: -0.00726337, mean(E): -19.23826301+0.00440540j, var(E): 0.03106844
-0.0
tensor(18.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16310/ 20000/ t/epoch=1.04............. Loss: 0.20123964, mean(E): -19.22652474-0.01102047j, var(E): 0.03516228
-0.0
tensor(18.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16320/ 20000/ t/epoch=1.05............. Loss: 0.09192530, mean(E): -19.23681256-0.00161566j, var(E): 0.03874749
-0.0
tensor(18.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16330/ 20000/ t/epoch=1.05............. Loss: -0.16671896, mean(E): -19.23291825+0.00682172j, var(E): 0.03336919
-0.0
tensor(18.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16340/ 20000/ t/epoch=1.05............. Loss: 0.03825023, mean(E): -19.21079796-0.00591713j, var(E): 0.03290114
-0.0
tensor(18.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16350/ 20000/ t/epoch=1.05............. Loss: -0.18504583, mean(E): -19.22517360-0.00736236j, var(E): 0.02719603
-0.0
tensor(18.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16360/ 20000/ t/epoch=1.05............. Loss: -0.00398056, mean(E): -19.22306554+0.00084291j, var(E): 0.02755675
-0.0
tensor(18.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16370/ 20000/ t/epoch=1.06............. Loss: 0.16479614, mean(E): -19.21711713-0.00656393j, var(E): 0.04727928
-0.0
tensor(18.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16380/ 20000/ t/epoch=1.05............. Loss: -0.12585895, mean(E): -19.23869160-0.00006567j, var(E): 0.02816737
-0.0
tensor(18.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16390/ 20000/ t/epoch=1.05............. Loss: -0.11423877, mean(E): -19.21657469+0.00524372j, var(E): 0.02567839
-0.0
tensor(18.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16400/ 20000/ t/epoch=1.05............. Loss: 0.11889393, mean(E): -19.23196628-0.00218662j, var(E): 0.03780940
-0.0
tensor(18.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16410/ 20000/ t/epoch=1.05............. Loss: -0.00167659, mean(E): -19.23166698+0.00222566j, var(E): 0.03731064
-0.0
tensor(18.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16420/ 20000/ t/epoch=1.05............. Loss: 0.03581871, mean(E): -19.21670167+0.00076011j, var(E): 0.03847612
-0.0
tensor(18.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16430/ 20000/ t/epoch=1.05............. Loss: 0.13101152, mean(E): -19.20941035-0.00875702j, var(E): 0.04718692
-0.0
tensor(18.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16440/ 20000/ t/epoch=1.04............. Loss: 0.00561154, mean(E): -19.22370160-0.00350979j, var(E): 0.04341719
-0.0
tensor(18.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16450/ 20000/ t/epoch=1.05............. Loss: -0.22600143, mean(E): -19.21044974-0.00811435j, var(E): 0.02323545
-0.0
tensor(18.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16460/ 20000/ t/epoch=1.06............. Loss: -0.03296328, mean(E): -19.21495928-0.00125493j, var(E): 0.04151700
-0.0
tensor(18.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16470/ 20000/ t/epoch=1.05............. Loss: 0.20593589, mean(E): -19.20632405-0.00260069j, var(E): 0.03534222
-0.0
tensor(18.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16480/ 20000/ t/epoch=1.04............. Loss: -0.03008561, mean(E): -19.22632107+0.00599685j, var(E): 0.02543971
-0.0
tensor(18.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16490/ 20000/ t/epoch=1.05............. Loss: -0.12574706, mean(E): -19.24495757+0.00193224j, var(E): 0.02846229
-0.0
tensor(18.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16500/ 20000/ t/epoch=1.05............. Loss: -0.15804844, mean(E): -19.22674478-0.00160242j, var(E): 0.02772292
-0.0
tensor(18.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16510/ 20000/ t/epoch=1.05............. Loss: -0.19090515, mean(E): -19.23311142+0.00836117j, var(E): 0.02617126
-0.0
tensor(18.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16520/ 20000/ t/epoch=1.06............. Loss: -0.07208273, mean(E): -19.24890710-0.00036468j, var(E): 0.02834120
-0.0
tensor(18.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16530/ 20000/ t/epoch=1.05............. Loss: -0.30960848, mean(E): -19.21735894+0.00211249j, var(E): 0.02960127
-0.0
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16540/ 20000/ t/epoch=1.05............. Loss: 0.06691916, mean(E): -19.22692340-0.00245853j, var(E): 0.02803347
-0.0
tensor(18.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16550/ 20000/ t/epoch=1.05............. Loss: 0.17367563, mean(E): -19.23060991-0.01120260j, var(E): 0.02514573
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16560/ 20000/ t/epoch=1.05............. Loss: 0.19382715, mean(E): -19.22455617+0.00082759j, var(E): 0.03199361
-0.0
tensor(18.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16570/ 20000/ t/epoch=1.05............. Loss: -0.13142565, mean(E): -19.22846736-0.00190452j, var(E): 0.03303594
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16580/ 20000/ t/epoch=1.05............. Loss: -0.06825712, mean(E): -19.22595605+0.00532160j, var(E): 0.03427318
-0.0
tensor(18.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16590/ 20000/ t/epoch=1.04............. Loss: -0.05717684, mean(E): -19.22815887-0.00075836j, var(E): 0.02987559
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16600/ 20000/ t/epoch=1.05............. Loss: -0.06529233, mean(E): -19.20460518-0.00129682j, var(E): 0.03146341
-0.0
tensor(18.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16610/ 20000/ t/epoch=1.04............. Loss: 0.23356109, mean(E): -19.23353271+0.00450330j, var(E): 0.02801806
-0.0
tensor(18.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16620/ 20000/ t/epoch=1.05............. Loss: 0.21948513, mean(E): -19.25380887+0.00566815j, var(E): 0.03698903
-0.0
tensor(18.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16630/ 20000/ t/epoch=1.05............. Loss: 0.13019712, mean(E): -19.22015884-0.00205660j, var(E): 0.03694027
-0.0
tensor(18.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16640/ 20000/ t/epoch=1.06............. Loss: 0.23938718, mean(E): -19.24028922+0.00238695j, var(E): 0.02480096
-0.0
tensor(18.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16650/ 20000/ t/epoch=1.05............. Loss: -0.13520030, mean(E): -19.22793115-0.00627124j, var(E): 0.01637734
-0.0
tensor(18.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16660/ 20000/ t/epoch=1.04............. Loss: -0.06675613, mean(E): -19.22625471-0.00142739j, var(E): 0.02808291
-0.0
tensor(18.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16670/ 20000/ t/epoch=1.05............. Loss: -0.30586810, mean(E): -19.20329648-0.01345704j, var(E): 0.03437220
-0.0
tensor(18.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16680/ 20000/ t/epoch=1.05............. Loss: 0.26857518, mean(E): -19.24387932-0.00223625j, var(E): 0.02914304
-0.0
tensor(18.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16690/ 20000/ t/epoch=1.05............. Loss: 0.17251503, mean(E): -19.22185319-0.00591246j, var(E): 0.03614210
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16700/ 20000/ t/epoch=1.05............. Loss: -0.06100525, mean(E): -19.21464295-0.00389788j, var(E): 0.03859280
-0.0
tensor(18.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16710/ 20000/ t/epoch=1.05............. Loss: -0.26903812, mean(E): -19.19692657-0.00344021j, var(E): 0.03659827
-0.0
tensor(18.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16720/ 20000/ t/epoch=1.05............. Loss: -0.00033137, mean(E): -19.24847827+0.00733222j, var(E): 0.04408207
-0.0
tensor(18.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16730/ 20000/ t/epoch=1.05............. Loss: -0.28326400, mean(E): -19.21863434+0.00554658j, var(E): 0.02406603
-0.0
tensor(18.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16740/ 20000/ t/epoch=1.05............. Loss: -0.06833477, mean(E): -19.23437213-0.00308450j, var(E): 0.02848841
-0.0
tensor(18.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16750/ 20000/ t/epoch=1.04............. Loss: 0.04371716, mean(E): -19.20071284-0.00005756j, var(E): 0.02515000
-0.0
tensor(18.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16760/ 20000/ t/epoch=1.05............. Loss: 0.42317067, mean(E): -19.25726865+0.00717267j, var(E): 0.04465393
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16770/ 20000/ t/epoch=1.05............. Loss: 0.14043349, mean(E): -19.21461310+0.00034288j, var(E): 0.03580660
-0.0
tensor(18.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16780/ 20000/ t/epoch=1.06............. Loss: -0.04451005, mean(E): -19.23062938-0.00355271j, var(E): 0.03617860
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16790/ 20000/ t/epoch=1.06............. Loss: -0.09625882, mean(E): -19.21306085-0.00399766j, var(E): 0.02237953
-0.0
tensor(18.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16800/ 20000/ t/epoch=1.05............. Loss: 0.00868164, mean(E): -19.23286858+0.00319187j, var(E): 0.03409967
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16810/ 20000/ t/epoch=1.06............. Loss: -0.02165048, mean(E): -19.22058227-0.00313514j, var(E): 0.02876676
-0.0
tensor(18.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16820/ 20000/ t/epoch=1.04............. Loss: -0.06788010, mean(E): -19.23554702+0.00279454j, var(E): 0.04076877
-0.0
tensor(18.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16830/ 20000/ t/epoch=1.05............. Loss: 0.06477147, mean(E): -19.21268305-0.00348262j, var(E): 0.03096679
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16840/ 20000/ t/epoch=1.05............. Loss: -0.02004294, mean(E): -19.22573872+0.00171493j, var(E): 0.02325987
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16850/ 20000/ t/epoch=1.05............. Loss: -0.07000779, mean(E): -19.21181565+0.00730234j, var(E): 0.03545337
-0.0
tensor(18.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16860/ 20000/ t/epoch=1.05............. Loss: -0.09518795, mean(E): -19.24362128-0.00225142j, var(E): 0.03492384
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16870/ 20000/ t/epoch=1.05............. Loss: 0.04062797, mean(E): -19.19907589+0.01111831j, var(E): 0.05945858
-0.0
tensor(18.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16880/ 20000/ t/epoch=1.05............. Loss: -0.04434118, mean(E): -19.20715971-0.00022177j, var(E): 0.03245924
-0.0
tensor(18.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16890/ 20000/ t/epoch=1.05............. Loss: -0.07259247, mean(E): -19.21595510-0.00129438j, var(E): 0.01937043
-0.0
tensor(18.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16900/ 20000/ t/epoch=1.04............. Loss: 0.04516538, mean(E): -19.22184772+0.00205473j, var(E): 0.02971683
-0.0
tensor(18.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16910/ 20000/ t/epoch=1.04............. Loss: -0.03449344, mean(E): -19.20710020-0.00432959j, var(E): 0.01806768
-0.0
tensor(18.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16920/ 20000/ t/epoch=1.05............. Loss: -0.15927805, mean(E): -19.19996922-0.00896406j, var(E): 0.02330957
-0.0
tensor(18.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16930/ 20000/ t/epoch=1.05............. Loss: 0.13671046, mean(E): -19.23333216-0.00636108j, var(E): 0.06854389
-0.0
tensor(18.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16940/ 20000/ t/epoch=1.04............. Loss: 0.20701814, mean(E): -19.23755854-0.00219647j, var(E): 0.03014098
-0.0
tensor(18.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16950/ 20000/ t/epoch=1.05............. Loss: 0.06160977, mean(E): -19.22010400-0.00364523j, var(E): 0.03286682
-0.0
tensor(18.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16960/ 20000/ t/epoch=1.06............. Loss: 0.10108806, mean(E): -19.21437312+0.00590894j, var(E): 0.03143312
-0.0
tensor(18.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16970/ 20000/ t/epoch=1.05............. Loss: -0.04714213, mean(E): -19.22088770+0.00022342j, var(E): 0.02218770
-0.0
tensor(18.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16980/ 20000/ t/epoch=1.04............. Loss: -0.25001196, mean(E): -19.21598891+0.00974381j, var(E): 0.05392634
-0.0
tensor(18.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16990/ 20000/ t/epoch=1.05............. Loss: 0.10935718, mean(E): -19.23854176+0.00088035j, var(E): 0.02573432
-0.0
tensor(18.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17000/ 20000/ t/epoch=1.05............. Loss: -0.06516162, mean(E): -19.21843962+0.00352562j, var(E): 0.03122047
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17010/ 20000/ t/epoch=1.05............. Loss: -0.15253427, mean(E): -19.23860539-0.00307355j, var(E): 0.03809022
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17020/ 20000/ t/epoch=1.05............. Loss: -0.01875805, mean(E): -19.22714330+0.00934661j, var(E): 0.02997975
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17030/ 20000/ t/epoch=1.05............. Loss: 0.02123157, mean(E): -19.23861029-0.00029564j, var(E): 0.03664602
-0.0
tensor(18.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17040/ 20000/ t/epoch=1.05............. Loss: -0.08280605, mean(E): -19.21251683+0.00531868j, var(E): 0.05577068
-0.0
tensor(18.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17050/ 20000/ t/epoch=1.05............. Loss: -0.13484257, mean(E): -19.22793624-0.00150293j, var(E): 0.01571044
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17060/ 20000/ t/epoch=1.05............. Loss: 0.08867881, mean(E): -19.22564804-0.00015444j, var(E): 0.01610120
-0.0
tensor(18.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17070/ 20000/ t/epoch=1.04............. Loss: -0.02589490, mean(E): -19.21243535+0.00119404j, var(E): 0.03950947
-0.0
tensor(18.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17080/ 20000/ t/epoch=1.05............. Loss: 0.05733920, mean(E): -19.23313485+0.00410382j, var(E): 0.04328153
-0.0
tensor(18.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17090/ 20000/ t/epoch=1.05............. Loss: 0.10909259, mean(E): -19.23152960-0.00379323j, var(E): 0.03812207
-0.0
tensor(18.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17100/ 20000/ t/epoch=1.05............. Loss: 0.07299077, mean(E): -19.22126746+0.00519849j, var(E): 0.04243759
-0.0
tensor(18.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17110/ 20000/ t/epoch=1.05............. Loss: 0.03975827, mean(E): -19.23400359-0.00133050j, var(E): 0.03206918
-0.0
tensor(18.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17120/ 20000/ t/epoch=1.05............. Loss: -0.06874214, mean(E): -19.23224769+0.00137406j, var(E): 0.04379146
-0.0
tensor(18.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17130/ 20000/ t/epoch=1.05............. Loss: 0.06065081, mean(E): -19.22958133-0.00131013j, var(E): 0.02323909
-0.0
tensor(18.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17140/ 20000/ t/epoch=1.05............. Loss: 0.13791927, mean(E): -19.20895072+0.00724338j, var(E): 0.02368964
-0.0
tensor(18.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17150/ 20000/ t/epoch=1.05............. Loss: -0.04814909, mean(E): -19.23934883+0.00455551j, var(E): 0.05274119
-0.0
tensor(18.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17160/ 20000/ t/epoch=1.05............. Loss: -0.25309838, mean(E): -19.22127650+0.00035945j, var(E): 0.02492397
-0.0
tensor(18.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17170/ 20000/ t/epoch=1.05............. Loss: -0.11677599, mean(E): -19.21570391+0.00348106j, var(E): 0.03342578
-0.0
tensor(18.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17180/ 20000/ t/epoch=1.06............. Loss: -0.09413682, mean(E): -19.19582605-0.00944266j, var(E): 0.03830870
-0.0
tensor(18.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17190/ 20000/ t/epoch=1.05............. Loss: -0.03734951, mean(E): -19.21854809+0.00927622j, var(E): 0.02682775
-0.0
tensor(18.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17200/ 20000/ t/epoch=1.05............. Loss: 0.05187338, mean(E): -19.23060458+0.00955468j, var(E): 0.03442524
-0.0
tensor(18.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17210/ 20000/ t/epoch=1.04............. Loss: 0.14074068, mean(E): -19.22305185+0.00839249j, var(E): 0.02930965
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17220/ 20000/ t/epoch=1.05............. Loss: -0.02018181, mean(E): -19.23049085+0.00201329j, var(E): 0.02542531
-0.0
tensor(18.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17230/ 20000/ t/epoch=1.05............. Loss: -0.10221449, mean(E): -19.19929144-0.00791105j, var(E): 0.12128040
-0.0
tensor(18.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17240/ 20000/ t/epoch=1.05............. Loss: -0.16745338, mean(E): -19.22037814+0.00814880j, var(E): 0.04186501
-0.0
tensor(18.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17250/ 20000/ t/epoch=1.05............. Loss: -0.08566205, mean(E): -19.23193007+0.00139993j, var(E): 0.03187195
-0.0
tensor(18.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17260/ 20000/ t/epoch=1.05............. Loss: -0.03878841, mean(E): -19.22708862+0.00305680j, var(E): 0.03865753
-0.0
tensor(18.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17270/ 20000/ t/epoch=1.05............. Loss: 0.28245956, mean(E): -19.22474570+0.00001744j, var(E): 0.03823003
-0.0
tensor(18.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17280/ 20000/ t/epoch=1.05............. Loss: -0.01724685, mean(E): -19.22712396-0.00239381j, var(E): 0.03032692
-0.0
tensor(18.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17290/ 20000/ t/epoch=1.05............. Loss: -0.08514454, mean(E): -19.21086870+0.00571384j, var(E): 0.01982200
-0.0
tensor(18.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17300/ 20000/ t/epoch=1.05............. Loss: 0.02329675, mean(E): -19.21149797-0.00057418j, var(E): 0.02764398
-0.0
tensor(18.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17310/ 20000/ t/epoch=1.06............. Loss: -0.13591293, mean(E): -19.22339338+0.00274209j, var(E): 0.03803638
-0.0
tensor(18.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17320/ 20000/ t/epoch=1.06............. Loss: -0.04852094, mean(E): -19.22383435+0.00135868j, var(E): 0.01954113
-0.0
tensor(18.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17330/ 20000/ t/epoch=1.05............. Loss: 0.02297968, mean(E): -19.21580023+0.00274224j, var(E): 0.03838482
-0.0
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17340/ 20000/ t/epoch=1.05............. Loss: -0.25155919, mean(E): -19.23363391-0.00160026j, var(E): 0.03635145
-0.0
tensor(18.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17350/ 20000/ t/epoch=1.05............. Loss: -0.51583582, mean(E): -19.21718633+0.00407157j, var(E): 0.04095704
-0.0
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17360/ 20000/ t/epoch=1.05............. Loss: -0.11425602, mean(E): -19.22617282-0.00152597j, var(E): 0.02904522
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17370/ 20000/ t/epoch=1.06............. Loss: 0.32824546, mean(E): -19.24561542-0.00211597j, var(E): 0.01654584
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17380/ 20000/ t/epoch=1.05............. Loss: 0.33178836, mean(E): -19.22244741+0.00738438j, var(E): 0.02528110
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17390/ 20000/ t/epoch=1.05............. Loss: 0.00003783, mean(E): -19.22790394+0.00922906j, var(E): 0.02449278
-0.0
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17400/ 20000/ t/epoch=1.05............. Loss: -0.14290225, mean(E): -19.22054235-0.00304208j, var(E): 0.03960473
-0.0
tensor(18.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17410/ 20000/ t/epoch=1.05............. Loss: 0.04130717, mean(E): -19.24510997+0.00495716j, var(E): 0.02700356
-0.0
tensor(18.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17420/ 20000/ t/epoch=1.05............. Loss: -0.06549272, mean(E): -19.21889064+0.00028471j, var(E): 0.02693155
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17430/ 20000/ t/epoch=1.05............. Loss: 0.24450289, mean(E): -19.23806340-0.00052024j, var(E): 0.10162937
-0.0
tensor(18.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17440/ 20000/ t/epoch=1.05............. Loss: -0.00471168, mean(E): -19.21281094+0.00871025j, var(E): 0.03490301
-0.0
tensor(18.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17450/ 20000/ t/epoch=1.04............. Loss: 0.22610283, mean(E): -19.21997953+0.00219768j, var(E): 0.03465268
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17460/ 20000/ t/epoch=1.05............. Loss: -0.18970045, mean(E): -19.22474213+0.00271555j, var(E): 0.03656645
-0.0
tensor(18.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17470/ 20000/ t/epoch=1.05............. Loss: -0.07648563, mean(E): -19.21093869+0.00142790j, var(E): 0.03831888
-0.0
tensor(18.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17480/ 20000/ t/epoch=1.05............. Loss: -0.06005447, mean(E): -19.20942189+0.00164652j, var(E): 0.02646866
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17490/ 20000/ t/epoch=1.06............. Loss: 0.05031818, mean(E): -19.23544994-0.00485161j, var(E): 0.02161003
-0.0
tensor(18.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17500/ 20000/ t/epoch=1.04............. Loss: 0.18603315, mean(E): -19.23682837+0.00480735j, var(E): 0.02985258
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17510/ 20000/ t/epoch=1.05............. Loss: -0.21529280, mean(E): -19.21065650-0.00066900j, var(E): 0.02252961
-0.0
tensor(18.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17520/ 20000/ t/epoch=1.04............. Loss: -0.09453129, mean(E): -19.22625775-0.00336982j, var(E): 0.02047740
-0.0
tensor(18.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17530/ 20000/ t/epoch=1.05............. Loss: 0.01662165, mean(E): -19.21648061+0.00240427j, var(E): 0.03838607
-0.0
tensor(18.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17540/ 20000/ t/epoch=1.05............. Loss: 0.00898009, mean(E): -19.21423163-0.00235156j, var(E): 0.05375914
-0.0
tensor(18.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17550/ 20000/ t/epoch=1.06............. Loss: -0.09995996, mean(E): -19.21765915-0.00143333j, var(E): 0.03759895
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17560/ 20000/ t/epoch=1.05............. Loss: -0.24962360, mean(E): -19.19336297+0.00545197j, var(E): 0.05484413
-0.0
tensor(18.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17570/ 20000/ t/epoch=1.05............. Loss: 0.07703772, mean(E): -19.22958672+0.00458382j, var(E): 0.03328614
-0.0
tensor(18.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17580/ 20000/ t/epoch=1.05............. Loss: -0.18903656, mean(E): -19.19444124+0.00180389j, var(E): 0.03731387
-0.0
tensor(18.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17590/ 20000/ t/epoch=1.05............. Loss: 0.07972920, mean(E): -19.22573996-0.00321557j, var(E): 0.02204687
-0.0
tensor(18.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17600/ 20000/ t/epoch=1.05............. Loss: 0.15957499, mean(E): -19.22302120+0.00141659j, var(E): 0.01849979
-0.0
tensor(18.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17610/ 20000/ t/epoch=1.05............. Loss: -0.07868578, mean(E): -19.20696212+0.00306608j, var(E): 0.03979261
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17620/ 20000/ t/epoch=1.05............. Loss: 0.07235484, mean(E): -19.24322015+0.00390029j, var(E): 0.03893294
-0.0
tensor(18.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17630/ 20000/ t/epoch=1.05............. Loss: 0.04240459, mean(E): -19.20301057-0.00162203j, var(E): 0.02818119
-0.0
tensor(18.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17640/ 20000/ t/epoch=1.05............. Loss: 0.12408351, mean(E): -19.21433369-0.00036600j, var(E): 0.03102029
-0.0
tensor(18.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17650/ 20000/ t/epoch=1.05............. Loss: 0.27893759, mean(E): -19.22341308-0.00590206j, var(E): 0.02027474
-0.0
tensor(18.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17660/ 20000/ t/epoch=1.05............. Loss: -0.00986093, mean(E): -19.23128853-0.00538638j, var(E): 0.03861212
-0.0
tensor(18.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17670/ 20000/ t/epoch=1.05............. Loss: -0.32754664, mean(E): -19.20326698-0.00141522j, var(E): 0.03370105
-0.0
tensor(18.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17680/ 20000/ t/epoch=1.05............. Loss: -0.20442163, mean(E): -19.21580126-0.00235754j, var(E): 0.02635449
-0.0
tensor(18.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17690/ 20000/ t/epoch=1.05............. Loss: -0.41591678, mean(E): -19.18228688-0.00460948j, var(E): 0.11287096
-0.0
tensor(18.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17700/ 20000/ t/epoch=1.04............. Loss: -0.08487886, mean(E): -19.20876385+0.00065522j, var(E): 0.01875372
-0.0
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17710/ 20000/ t/epoch=1.05............. Loss: -0.11443879, mean(E): -19.23952159-0.00208333j, var(E): 0.05356755
-0.0
tensor(18.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17720/ 20000/ t/epoch=1.04............. Loss: -0.07561054, mean(E): -19.23256305-0.00960267j, var(E): 0.02641118
-0.0
tensor(18.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17730/ 20000/ t/epoch=1.05............. Loss: -0.09875944, mean(E): -19.23241789-0.00770863j, var(E): 0.03186520
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17740/ 20000/ t/epoch=1.05............. Loss: -0.03359461, mean(E): -19.21034640+0.00019283j, var(E): 0.02583075
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17750/ 20000/ t/epoch=1.05............. Loss: -0.10391941, mean(E): -19.21674913+0.00064951j, var(E): 0.02767642
-0.0
tensor(18.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17760/ 20000/ t/epoch=1.05............. Loss: 0.10876315, mean(E): -19.21203547-0.00633652j, var(E): 0.03227648
-0.0
tensor(18.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17770/ 20000/ t/epoch=1.05............. Loss: -0.09005692, mean(E): -19.20721284+0.00423762j, var(E): 0.04605626
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17780/ 20000/ t/epoch=1.05............. Loss: 0.16519564, mean(E): -19.25273378+0.00090962j, var(E): 0.04213817
-0.0
tensor(18.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17790/ 20000/ t/epoch=1.05............. Loss: -0.12714139, mean(E): -19.21052128-0.00130114j, var(E): 0.02708506
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17800/ 20000/ t/epoch=1.04............. Loss: -0.12365211, mean(E): -19.22005169-0.00143811j, var(E): 0.01979126
-0.0
tensor(18.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17810/ 20000/ t/epoch=1.05............. Loss: 0.02613856, mean(E): -19.22395442-0.00167987j, var(E): 0.01966790
-0.0
tensor(18.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17820/ 20000/ t/epoch=1.04............. Loss: -0.12354475, mean(E): -19.21337317-0.00525410j, var(E): 0.02710509
-0.0
tensor(18.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17830/ 20000/ t/epoch=1.04............. Loss: 0.14399581, mean(E): -19.23480966-0.00932946j, var(E): 0.03097013
-0.0
tensor(18.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17840/ 20000/ t/epoch=1.05............. Loss: 0.02046880, mean(E): -19.21836011-0.00254638j, var(E): 0.03139636
-0.0
tensor(18.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17850/ 20000/ t/epoch=1.05............. Loss: -0.16903143, mean(E): -19.20557114-0.00038010j, var(E): 0.04881123
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17860/ 20000/ t/epoch=1.05............. Loss: 0.10076043, mean(E): -19.20657403-0.00232232j, var(E): 0.02301095
-0.0
tensor(18.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17870/ 20000/ t/epoch=1.04............. Loss: 0.13919980, mean(E): -19.23014928-0.00414849j, var(E): 0.03464349
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17880/ 20000/ t/epoch=1.05............. Loss: -0.19249043, mean(E): -19.23555576-0.01328418j, var(E): 0.04181058
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17890/ 20000/ t/epoch=1.05............. Loss: -0.23626681, mean(E): -19.23596338-0.00136780j, var(E): 0.02434871
-0.0
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17900/ 20000/ t/epoch=1.06............. Loss: -0.08161853, mean(E): -19.23269303-0.00492859j, var(E): 0.03047340
-0.0
tensor(18.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17910/ 20000/ t/epoch=1.06............. Loss: 0.21126898, mean(E): -19.21160384-0.00607229j, var(E): 0.02463421
-0.0
tensor(18.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17920/ 20000/ t/epoch=1.05............. Loss: 0.04630186, mean(E): -19.23415484+0.00186627j, var(E): 0.03108320
-0.0
tensor(18.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17930/ 20000/ t/epoch=1.05............. Loss: -0.17715839, mean(E): -19.19689271-0.00086905j, var(E): 0.02559605
-0.0
tensor(18.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17940/ 20000/ t/epoch=1.04............. Loss: -0.03307894, mean(E): -19.22765535-0.00181693j, var(E): 0.03628822
-0.0
tensor(18.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17950/ 20000/ t/epoch=1.05............. Loss: 0.08728784, mean(E): -19.21861368-0.00484500j, var(E): 0.04075629
-0.0
tensor(18.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17960/ 20000/ t/epoch=1.05............. Loss: 0.20083073, mean(E): -19.24310889-0.01096621j, var(E): 0.02214970
-0.0
tensor(18.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17970/ 20000/ t/epoch=1.05............. Loss: -0.01246650, mean(E): -19.24469564+0.00799683j, var(E): 0.02667622
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17980/ 20000/ t/epoch=1.05............. Loss: 0.00471125, mean(E): -19.22752064+0.00605999j, var(E): 0.02650744
-0.0
tensor(18.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17990/ 20000/ t/epoch=1.06............. Loss: 0.11622210, mean(E): -19.24821865+0.00059409j, var(E): 0.10020037
-0.0
tensor(18.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18000/ 20000/ t/epoch=1.05............. Loss: 0.04713317, mean(E): -19.25308840+0.00141298j, var(E): 0.03719528
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18010/ 20000/ t/epoch=1.06............. Loss: 0.16619143, mean(E): -19.21780754+0.00100033j, var(E): 0.02738811
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18020/ 20000/ t/epoch=1.05............. Loss: 0.05287667, mean(E): -19.22012352-0.00615140j, var(E): 0.02744561
-0.0
tensor(18.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18030/ 20000/ t/epoch=1.05............. Loss: -0.03794524, mean(E): -19.24107016-0.00095652j, var(E): 0.03221052
-0.0
tensor(18.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18040/ 20000/ t/epoch=1.05............. Loss: -0.15677577, mean(E): -19.21141174-0.00215321j, var(E): 0.03748001
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18050/ 20000/ t/epoch=1.05............. Loss: -0.25777442, mean(E): -19.22926597+0.00085776j, var(E): 0.04532646
-0.0
tensor(18.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18060/ 20000/ t/epoch=1.05............. Loss: 0.02115090, mean(E): -19.22073911+0.00104777j, var(E): 0.03324253
-0.0
tensor(18.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18070/ 20000/ t/epoch=1.05............. Loss: -0.21647253, mean(E): -19.20994344-0.00632200j, var(E): 0.04031573
-0.0
tensor(18.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18080/ 20000/ t/epoch=1.05............. Loss: 0.01266851, mean(E): -19.21345989+0.00156336j, var(E): 0.02599486
-0.0
tensor(18.7680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18090/ 20000/ t/epoch=1.05............. Loss: -0.02274256, mean(E): -19.22224370-0.00079108j, var(E): 0.02591854
-0.0
tensor(18.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18100/ 20000/ t/epoch=1.05............. Loss: 0.17867049, mean(E): -19.24602096+0.00365935j, var(E): 0.05341817
-0.0
tensor(18.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18110/ 20000/ t/epoch=1.05............. Loss: 0.23389504, mean(E): -19.24910026+0.00273129j, var(E): 0.03176191
-0.0
tensor(18.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18120/ 20000/ t/epoch=1.05............. Loss: 0.11517594, mean(E): -19.21730734+0.00074088j, var(E): 0.02951252
-0.0
tensor(18.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18130/ 20000/ t/epoch=1.05............. Loss: -0.09336554, mean(E): -19.23456297-0.00011628j, var(E): 0.04237169
-0.0
tensor(18.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18140/ 20000/ t/epoch=1.04............. Loss: -0.09722083, mean(E): -19.23363361+0.00264660j, var(E): 0.02591897
-0.0
tensor(18.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18150/ 20000/ t/epoch=1.05............. Loss: -0.04775394, mean(E): -19.23362970-0.01273067j, var(E): 0.03253566
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18160/ 20000/ t/epoch=1.05............. Loss: -0.13227819, mean(E): -19.22222130-0.00712207j, var(E): 0.02147738
-0.0
tensor(18.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18170/ 20000/ t/epoch=1.05............. Loss: 0.18164806, mean(E): -19.24065641+0.00271087j, var(E): 0.02879469
-0.0
tensor(18.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18180/ 20000/ t/epoch=1.05............. Loss: 0.05692424, mean(E): -19.22824784-0.00487066j, var(E): 0.02919592
-0.0
tensor(18.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18190/ 20000/ t/epoch=1.04............. Loss: -0.08557898, mean(E): -19.21728795+0.00403765j, var(E): 0.02220713
-0.0
tensor(18.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18200/ 20000/ t/epoch=1.05............. Loss: -0.11354398, mean(E): -19.20536121+0.00299008j, var(E): 0.04492513
-0.0
tensor(18.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18210/ 20000/ t/epoch=1.05............. Loss: -0.29666229, mean(E): -19.19720777-0.00270452j, var(E): 0.05553824
-0.0
tensor(18.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18220/ 20000/ t/epoch=1.05............. Loss: 0.35700438, mean(E): -19.22975435-0.00064220j, var(E): 0.02643888
-0.0
tensor(18.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18230/ 20000/ t/epoch=1.05............. Loss: 0.28781829, mean(E): -19.22214315-0.00328715j, var(E): 0.05604086
-0.0
tensor(18.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18240/ 20000/ t/epoch=1.06............. Loss: 0.04134347, mean(E): -19.22524521-0.00052245j, var(E): 0.02910174
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18250/ 20000/ t/epoch=1.05............. Loss: -0.08842714, mean(E): -19.21131403-0.00129927j, var(E): 0.04038839
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18260/ 20000/ t/epoch=1.04............. Loss: -0.10638813, mean(E): -19.23357592-0.00235403j, var(E): 0.01712602
-0.0
tensor(18.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18270/ 20000/ t/epoch=1.05............. Loss: -0.15393739, mean(E): -19.21357536-0.01249939j, var(E): 0.02994928
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18280/ 20000/ t/epoch=1.05............. Loss: 0.10416127, mean(E): -19.25098494+0.00345087j, var(E): 0.03397861
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18290/ 20000/ t/epoch=1.06............. Loss: 0.05077514, mean(E): -19.20029072+0.00149503j, var(E): 0.03298970
-0.0
tensor(18.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18300/ 20000/ t/epoch=1.05............. Loss: -0.17115667, mean(E): -19.20959884+0.00281602j, var(E): 0.02636508
-0.0
tensor(18.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18310/ 20000/ t/epoch=1.04............. Loss: -0.20758491, mean(E): -19.23264957-0.00292408j, var(E): 0.01777093
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18320/ 20000/ t/epoch=1.05............. Loss: -0.03543131, mean(E): -19.25821151+0.00464697j, var(E): 0.02939541
-0.0
tensor(18.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18330/ 20000/ t/epoch=1.05............. Loss: 0.10275080, mean(E): -19.24074371+0.00275816j, var(E): 0.02480125
-0.0
tensor(18.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18340/ 20000/ t/epoch=1.05............. Loss: -0.16485099, mean(E): -19.22862076-0.00846000j, var(E): 0.02400628
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18350/ 20000/ t/epoch=1.06............. Loss: -0.07948194, mean(E): -19.22353732-0.00679490j, var(E): 0.03787566
-0.0
tensor(18.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18360/ 20000/ t/epoch=1.05............. Loss: 0.15845755, mean(E): -19.23128585+0.00499766j, var(E): 0.02831151
-0.0
tensor(18.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18370/ 20000/ t/epoch=1.05............. Loss: 0.07765707, mean(E): -19.22434250-0.00068986j, var(E): 0.03059885
-0.0
tensor(18.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18380/ 20000/ t/epoch=1.05............. Loss: 0.22741746, mean(E): -19.22627193+0.00543604j, var(E): 0.04057698
-0.0
tensor(18.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18390/ 20000/ t/epoch=1.05............. Loss: 0.17538322, mean(E): -19.21939915+0.00648860j, var(E): 0.02543355
-0.0
tensor(18.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18400/ 20000/ t/epoch=1.05............. Loss: -0.23637519, mean(E): -19.21785182-0.00142560j, var(E): 0.02734689
-0.0
tensor(18.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18410/ 20000/ t/epoch=1.05............. Loss: 0.08010249, mean(E): -19.23827648-0.00047344j, var(E): 0.02123704
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18420/ 20000/ t/epoch=1.05............. Loss: -0.06938505, mean(E): -19.21428446-0.00942302j, var(E): 0.04072595
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18430/ 20000/ t/epoch=1.05............. Loss: -0.04974589, mean(E): -19.23507997+0.00075417j, var(E): 0.02631049
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18440/ 20000/ t/epoch=1.05............. Loss: -0.16036217, mean(E): -19.21905318-0.00420414j, var(E): 0.02767664
-0.0
tensor(18.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18450/ 20000/ t/epoch=1.04............. Loss: -0.15324140, mean(E): -19.21976543+0.00080551j, var(E): 0.02978745
-0.0
tensor(18.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18460/ 20000/ t/epoch=1.05............. Loss: 0.13060214, mean(E): -19.23649617-0.00698048j, var(E): 0.03535788
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18470/ 20000/ t/epoch=1.05............. Loss: -0.06950923, mean(E): -19.22034222-0.00849729j, var(E): 0.02770020
-0.0
tensor(18.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18480/ 20000/ t/epoch=1.06............. Loss: -0.17054049, mean(E): -19.23079985-0.00103882j, var(E): 0.01661814
-0.0
tensor(18.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18490/ 20000/ t/epoch=1.04............. Loss: 0.02070111, mean(E): -19.20881391-0.00571663j, var(E): 0.02943303
-0.0
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18500/ 20000/ t/epoch=1.05............. Loss: 0.22031864, mean(E): -19.22430378+0.00436339j, var(E): 0.02441535
-0.0
tensor(18.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18510/ 20000/ t/epoch=1.05............. Loss: 0.10969148, mean(E): -19.21984942+0.00585871j, var(E): 0.02115501
-0.0
tensor(18.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18520/ 20000/ t/epoch=1.05............. Loss: 0.23285689, mean(E): -19.22345864-0.00514382j, var(E): 0.01777646
-0.0
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18530/ 20000/ t/epoch=1.05............. Loss: 0.03391519, mean(E): -19.23468280-0.00248886j, var(E): 0.02129571
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18540/ 20000/ t/epoch=1.05............. Loss: 0.26799006, mean(E): -19.22604091-0.00085933j, var(E): 0.05822591
-0.0
tensor(18.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18550/ 20000/ t/epoch=1.05............. Loss: 0.07473344, mean(E): -19.22572981+0.00328319j, var(E): 0.03426484
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18560/ 20000/ t/epoch=1.05............. Loss: -0.02545501, mean(E): -19.22375839-0.00235813j, var(E): 0.02426372
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18570/ 20000/ t/epoch=1.05............. Loss: -0.28200605, mean(E): -19.22422052+0.00116730j, var(E): 0.03414555
-0.0
tensor(18.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18580/ 20000/ t/epoch=1.05............. Loss: -0.07283421, mean(E): -19.23315053+0.00226349j, var(E): 0.06235799
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18590/ 20000/ t/epoch=1.05............. Loss: -0.12614138, mean(E): -19.23454360+0.00276024j, var(E): 0.03042310
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18600/ 20000/ t/epoch=1.05............. Loss: 0.03243682, mean(E): -19.22961895-0.00516277j, var(E): 0.02779238
-0.0
tensor(18.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18610/ 20000/ t/epoch=1.05............. Loss: -0.02109043, mean(E): -19.22417628+0.00976842j, var(E): 0.02302935
-0.0
tensor(18.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18620/ 20000/ t/epoch=1.04............. Loss: 0.32652841, mean(E): -19.24900291-0.00234803j, var(E): 0.04352942
-0.0
tensor(18.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18630/ 20000/ t/epoch=1.05............. Loss: 0.15710583, mean(E): -19.22845642+0.00068502j, var(E): 0.02496775
-0.0
tensor(18.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18640/ 20000/ t/epoch=1.05............. Loss: -0.14887467, mean(E): -19.21357314+0.00072763j, var(E): 0.01973028
-0.0
tensor(18.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18650/ 20000/ t/epoch=1.05............. Loss: -0.14741789, mean(E): -19.21669402+0.00139287j, var(E): 0.04432627
-0.0
tensor(18.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18660/ 20000/ t/epoch=1.05............. Loss: 0.03908364, mean(E): -19.21280601+0.00176761j, var(E): 0.02420171
-0.0
tensor(18.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18670/ 20000/ t/epoch=1.05............. Loss: 0.13633397, mean(E): -19.22304733+0.00618212j, var(E): 0.02339470
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18680/ 20000/ t/epoch=1.05............. Loss: -0.07405060, mean(E): -19.21955499-0.00162175j, var(E): 0.01271558
-0.0
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18690/ 20000/ t/epoch=1.05............. Loss: -0.14347908, mean(E): -19.23718311+0.00350196j, var(E): 0.02573027
-0.0
tensor(18.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18700/ 20000/ t/epoch=1.05............. Loss: -0.02484418, mean(E): -19.23454890-0.00173844j, var(E): 0.01767344
-0.0
tensor(18.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18710/ 20000/ t/epoch=1.05............. Loss: 0.00560841, mean(E): -19.23301473-0.00131899j, var(E): 0.03302808
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18720/ 20000/ t/epoch=1.05............. Loss: 0.16048346, mean(E): -19.22930899-0.00331637j, var(E): 0.02684959
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18730/ 20000/ t/epoch=1.05............. Loss: -0.10096052, mean(E): -19.20500367+0.00000988j, var(E): 0.02204443
-0.0
tensor(18.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18740/ 20000/ t/epoch=1.05............. Loss: -0.13039511, mean(E): -19.21273399-0.00157954j, var(E): 0.02514537
-0.0
tensor(18.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18750/ 20000/ t/epoch=1.05............. Loss: 0.00611135, mean(E): -19.22967412-0.00574709j, var(E): 0.02333959
-0.0
tensor(18.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18760/ 20000/ t/epoch=1.05............. Loss: 0.07520139, mean(E): -19.23389390-0.00728943j, var(E): 0.03070482
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18770/ 20000/ t/epoch=1.05............. Loss: 0.19974086, mean(E): -19.23756480+0.00119824j, var(E): 0.03975078
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18780/ 20000/ t/epoch=1.05............. Loss: 0.16490953, mean(E): -19.21808352-0.00482980j, var(E): 0.03259327
-0.0
tensor(18.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18790/ 20000/ t/epoch=1.05............. Loss: 0.19980537, mean(E): -19.23069130-0.00540195j, var(E): 0.03993487
-0.0
tensor(18.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18800/ 20000/ t/epoch=1.05............. Loss: 0.19365147, mean(E): -19.23415335+0.00545644j, var(E): 0.04379595
-0.0
tensor(18.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18810/ 20000/ t/epoch=1.05............. Loss: 0.09087941, mean(E): -19.23036026+0.00014749j, var(E): 0.02254449
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18820/ 20000/ t/epoch=1.05............. Loss: -0.13475318, mean(E): -19.23495732+0.00060556j, var(E): 0.02795556
-0.0
tensor(18.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18830/ 20000/ t/epoch=1.05............. Loss: 0.02327869, mean(E): -19.22291077-0.01083751j, var(E): 0.02240088
-0.0
tensor(18.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18840/ 20000/ t/epoch=1.05............. Loss: 0.15890688, mean(E): -19.24376691-0.00337734j, var(E): 0.05267526
-0.0
tensor(18.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18850/ 20000/ t/epoch=1.04............. Loss: 0.22262282, mean(E): -19.24264831-0.00139805j, var(E): 0.04216126
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18860/ 20000/ t/epoch=1.04............. Loss: -0.09136924, mean(E): -19.21990501+0.00299503j, var(E): 0.01409128
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18870/ 20000/ t/epoch=1.05............. Loss: -0.02632708, mean(E): -19.21214977+0.00201133j, var(E): 0.02397537
-0.0
tensor(18.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18880/ 20000/ t/epoch=1.05............. Loss: -0.12004725, mean(E): -19.22117389+0.00380674j, var(E): 0.02411180
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18890/ 20000/ t/epoch=1.05............. Loss: -0.28047139, mean(E): -19.21268843-0.00424570j, var(E): 0.05053777
-0.0
tensor(18.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18900/ 20000/ t/epoch=1.05............. Loss: -0.22930350, mean(E): -19.21653454-0.00173938j, var(E): 0.03852825
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18910/ 20000/ t/epoch=1.05............. Loss: -0.02018789, mean(E): -19.23935114+0.00603922j, var(E): 0.01713055
-0.0
tensor(18.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18920/ 20000/ t/epoch=1.06............. Loss: 0.09590283, mean(E): -19.20951160+0.00054572j, var(E): 0.04930828
-0.0
tensor(18.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18930/ 20000/ t/epoch=1.06............. Loss: 0.22437262, mean(E): -19.22353083+0.00465536j, var(E): 0.01881670
-0.0
tensor(18.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18940/ 20000/ t/epoch=1.05............. Loss: -0.08963721, mean(E): -19.21355930-0.00362520j, var(E): 0.02456334
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18950/ 20000/ t/epoch=1.05............. Loss: -0.15974626, mean(E): -19.22836531+0.00026199j, var(E): 0.02397787
-0.0
tensor(18.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18960/ 20000/ t/epoch=1.04............. Loss: 0.20650365, mean(E): -19.24668249-0.00010875j, var(E): 0.03826695
-0.0
tensor(18.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18970/ 20000/ t/epoch=1.04............. Loss: 0.18959607, mean(E): -19.23445905-0.00191624j, var(E): 0.02369513
-0.0
tensor(18.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18980/ 20000/ t/epoch=1.05............. Loss: 0.12354136, mean(E): -19.22233499-0.00006042j, var(E): 0.03484426
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18990/ 20000/ t/epoch=1.05............. Loss: -0.08015566, mean(E): -19.20332031-0.00562801j, var(E): 0.02387383
-0.0
tensor(18.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19000/ 20000/ t/epoch=1.05............. Loss: -0.22732781, mean(E): -19.20284803+0.00030691j, var(E): 0.04792298
-0.0
tensor(18.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19010/ 20000/ t/epoch=1.05............. Loss: 0.12434431, mean(E): -19.23173763+0.00419726j, var(E): 0.02337454
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19020/ 20000/ t/epoch=1.06............. Loss: -0.20855864, mean(E): -19.23364356-0.01005230j, var(E): 0.03296733
-0.0
tensor(18.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19030/ 20000/ t/epoch=1.05............. Loss: -0.08293889, mean(E): -19.23286112-0.00183400j, var(E): 0.02936899
-0.0
tensor(18.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19040/ 20000/ t/epoch=1.06............. Loss: 0.13969866, mean(E): -19.23048008+0.00031721j, var(E): 0.02897833
-0.0
tensor(18.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19050/ 20000/ t/epoch=1.05............. Loss: 0.19467305, mean(E): -19.22721703+0.00156580j, var(E): 0.05851748
-0.0
tensor(18.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19060/ 20000/ t/epoch=1.05............. Loss: -0.10936567, mean(E): -19.22385974+0.00493618j, var(E): 0.04873130
-0.0
tensor(18.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19070/ 20000/ t/epoch=1.05............. Loss: -0.20079542, mean(E): -19.22063192+0.00557871j, var(E): 0.01949121
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19080/ 20000/ t/epoch=1.04............. Loss: 0.09903675, mean(E): -19.23952198+0.00513192j, var(E): 0.02417684
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19090/ 20000/ t/epoch=1.05............. Loss: 0.26853502, mean(E): -19.23153072-0.00060671j, var(E): 0.02831890
-0.0
tensor(18.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19100/ 20000/ t/epoch=1.05............. Loss: 0.09291382, mean(E): -19.24240045-0.00258884j, var(E): 0.03160211
-0.0
tensor(18.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19110/ 20000/ t/epoch=1.05............. Loss: -0.18973632, mean(E): -19.20897431+0.00190485j, var(E): 0.02672739
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19120/ 20000/ t/epoch=1.06............. Loss: -0.24225717, mean(E): -19.21750903+0.00074298j, var(E): 0.03683498
-0.0
tensor(18.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19130/ 20000/ t/epoch=1.05............. Loss: 0.04781384, mean(E): -19.23422273-0.00797758j, var(E): 0.02471550
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19140/ 20000/ t/epoch=1.05............. Loss: 0.18552025, mean(E): -19.21785454-0.00104414j, var(E): 0.03368334
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19150/ 20000/ t/epoch=1.05............. Loss: -0.11548682, mean(E): -19.20827494-0.00987021j, var(E): 0.03682469
-0.0
tensor(18.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19160/ 20000/ t/epoch=1.05............. Loss: -0.07009714, mean(E): -19.22772593-0.00253739j, var(E): 0.02792099
-0.0
tensor(18.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19170/ 20000/ t/epoch=1.05............. Loss: 0.03955332, mean(E): -19.21681732-0.00350861j, var(E): 0.02842106
-0.0
tensor(18.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19180/ 20000/ t/epoch=1.04............. Loss: 0.19355052, mean(E): -19.21608759+0.00579089j, var(E): 0.03850235
-0.0
tensor(18.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19190/ 20000/ t/epoch=1.05............. Loss: -0.12241622, mean(E): -19.22878451+0.00008410j, var(E): 0.02121222
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19200/ 20000/ t/epoch=1.05............. Loss: -0.12414207, mean(E): -19.22710031+0.00600909j, var(E): 0.02280381
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19210/ 20000/ t/epoch=1.05............. Loss: -0.01146691, mean(E): -19.21863524-0.00358174j, var(E): 0.03660060
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19220/ 20000/ t/epoch=1.05............. Loss: 0.32805053, mean(E): -19.23777604-0.00571480j, var(E): 0.02323715
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19230/ 20000/ t/epoch=1.05............. Loss: -0.00860531, mean(E): -19.23267635-0.00072082j, var(E): 0.02441646
-0.0
tensor(18.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19240/ 20000/ t/epoch=1.05............. Loss: -0.01933287, mean(E): -19.21834614-0.00296722j, var(E): 0.02334087
-0.0
tensor(18.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19250/ 20000/ t/epoch=1.04............. Loss: 0.02705923, mean(E): -19.23444641+0.00028676j, var(E): 0.02792526
-0.0
tensor(18.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19260/ 20000/ t/epoch=1.05............. Loss: -0.04630186, mean(E): -19.23938311-0.00146546j, var(E): 0.04898222
-0.0
tensor(18.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19270/ 20000/ t/epoch=1.05............. Loss: 0.02080113, mean(E): -19.24332002+0.00214992j, var(E): 0.04099787
-0.0
tensor(18.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19280/ 20000/ t/epoch=1.05............. Loss: 0.03186977, mean(E): -19.22045332+0.00413280j, var(E): 0.02157210
-0.0
tensor(18.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19290/ 20000/ t/epoch=1.05............. Loss: 0.07184142, mean(E): -19.22426977+0.00232765j, var(E): 0.01665321
-0.0
tensor(18.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19300/ 20000/ t/epoch=1.05............. Loss: 0.06665194, mean(E): -19.20985307-0.00522020j, var(E): 0.02415024
-0.0
tensor(18.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19310/ 20000/ t/epoch=1.05............. Loss: 0.10125995, mean(E): -19.22672163+0.00424466j, var(E): 0.03043601
-0.0
tensor(18.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19320/ 20000/ t/epoch=1.06............. Loss: 0.06724673, mean(E): -19.23302647+0.01445818j, var(E): 0.05045056
-0.0
tensor(18.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19330/ 20000/ t/epoch=1.05............. Loss: 0.11347949, mean(E): -19.21774181-0.00677337j, var(E): 0.02020222
-0.0
tensor(18.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19340/ 20000/ t/epoch=1.05............. Loss: 0.05315614, mean(E): -19.21906524+0.00122227j, var(E): 0.02559002
-0.0
tensor(18.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19350/ 20000/ t/epoch=1.05............. Loss: -0.08492678, mean(E): -19.22441498-0.00073636j, var(E): 0.02522355
-0.0
tensor(18.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19360/ 20000/ t/epoch=1.05............. Loss: -0.10846752, mean(E): -19.22326418-0.00603927j, var(E): 0.03091529
-0.0
tensor(18.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19370/ 20000/ t/epoch=1.05............. Loss: 0.02765668, mean(E): -19.23474127+0.00622687j, var(E): 0.02206336
-0.0
tensor(18.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19380/ 20000/ t/epoch=1.05............. Loss: 0.32754400, mean(E): -19.23735523-0.00073542j, var(E): 0.03508088
-0.0
tensor(18.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19390/ 20000/ t/epoch=1.05............. Loss: 0.08459389, mean(E): -19.22421901+0.00072993j, var(E): 0.01883540
-0.0
tensor(18.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19400/ 20000/ t/epoch=1.05............. Loss: -0.05371502, mean(E): -19.21325391+0.00806368j, var(E): 0.03171214
-0.0
tensor(18.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19410/ 20000/ t/epoch=1.06............. Loss: 0.01174208, mean(E): -19.19527749+0.00863840j, var(E): 0.03694006
-0.0
tensor(18.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19420/ 20000/ t/epoch=1.05............. Loss: 0.12814381, mean(E): -19.22368961+0.00162017j, var(E): 0.02934010
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19430/ 20000/ t/epoch=1.05............. Loss: 0.21819587, mean(E): -19.23775853-0.00031053j, var(E): 0.02694406
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19440/ 20000/ t/epoch=1.05............. Loss: -0.01197987, mean(E): -19.23491682-0.00505350j, var(E): 0.02169545
-0.0
tensor(18.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19450/ 20000/ t/epoch=1.05............. Loss: -0.10729690, mean(E): -19.20644531+0.01033322j, var(E): 0.02524704
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19460/ 20000/ t/epoch=1.05............. Loss: -0.03280862, mean(E): -19.21833866-0.00187192j, var(E): 0.01956255
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19470/ 20000/ t/epoch=1.05............. Loss: -0.12989360, mean(E): -19.21659042+0.00397565j, var(E): 0.02501328
-0.0
tensor(18.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19480/ 20000/ t/epoch=1.05............. Loss: -0.06119661, mean(E): -19.22201427-0.00213042j, var(E): 0.02349145
-0.0
tensor(18.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19490/ 20000/ t/epoch=1.05............. Loss: 0.07557180, mean(E): -19.22984416-0.00414197j, var(E): 0.03781302
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19500/ 20000/ t/epoch=1.05............. Loss: -0.10797735, mean(E): -19.22656672-0.00396165j, var(E): 0.03216609
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19510/ 20000/ t/epoch=1.05............. Loss: -0.25682869, mean(E): -19.21913897+0.00102632j, var(E): 0.02160617
-0.0
tensor(18.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19520/ 20000/ t/epoch=1.05............. Loss: -0.21725859, mean(E): -19.22788143+0.00115497j, var(E): 0.02769413
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19530/ 20000/ t/epoch=1.05............. Loss: -0.04819727, mean(E): -19.23354826-0.00087104j, var(E): 0.06110638
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19540/ 20000/ t/epoch=1.05............. Loss: 0.02183129, mean(E): -19.21994990-0.00679754j, var(E): 0.03454754
-0.0
tensor(18.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19550/ 20000/ t/epoch=1.05............. Loss: -0.08880767, mean(E): -19.24444641-0.00372704j, var(E): 0.01868921
-0.0
tensor(18.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19560/ 20000/ t/epoch=1.05............. Loss: -0.14110771, mean(E): -19.20595879+0.00604247j, var(E): 0.03051617
-0.0
tensor(18.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19570/ 20000/ t/epoch=1.05............. Loss: -0.10787227, mean(E): -19.21522110+0.00337210j, var(E): 0.03138554
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19580/ 20000/ t/epoch=1.05............. Loss: -0.20985523, mean(E): -19.22413615+0.00177125j, var(E): 0.02950317
-0.0
tensor(18.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19590/ 20000/ t/epoch=1.05............. Loss: 0.11290189, mean(E): -19.22762636+0.00146309j, var(E): 0.03045153
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19600/ 20000/ t/epoch=1.06............. Loss: 0.01833322, mean(E): -19.22073890-0.00690884j, var(E): 0.02131457
-0.0
tensor(18.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19610/ 20000/ t/epoch=1.05............. Loss: -0.19800387, mean(E): -19.21109001+0.00214851j, var(E): 0.02152255
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19620/ 20000/ t/epoch=1.05............. Loss: -0.00950360, mean(E): -19.21340075-0.00279630j, var(E): 0.02387896
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19630/ 20000/ t/epoch=1.05............. Loss: -0.08380798, mean(E): -19.23729064+0.00643518j, var(E): 0.02451731
-0.0
tensor(18.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19640/ 20000/ t/epoch=1.05............. Loss: 0.04291358, mean(E): -19.22682083+0.01175597j, var(E): 0.01852110
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19650/ 20000/ t/epoch=1.05............. Loss: -0.08882550, mean(E): -19.23435025-0.00509348j, var(E): 0.03260534
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19660/ 20000/ t/epoch=1.05............. Loss: 0.05548995, mean(E): -19.21788419+0.00047646j, var(E): 0.03276289
-0.0
tensor(18.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19670/ 20000/ t/epoch=1.05............. Loss: 0.13572487, mean(E): -19.22221571-0.00181713j, var(E): 0.02655235
-0.0
tensor(18.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19680/ 20000/ t/epoch=1.05............. Loss: -0.17201437, mean(E): -19.21876284+0.00168034j, var(E): 0.03940480
-0.0
tensor(18.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19690/ 20000/ t/epoch=1.04............. Loss: -0.22376368, mean(E): -19.21252892-0.00214332j, var(E): 0.06956666
-0.0
tensor(18.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19700/ 20000/ t/epoch=1.05............. Loss: -0.20594078, mean(E): -19.23797183+0.00525338j, var(E): 0.02492440
-0.0
tensor(18.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19710/ 20000/ t/epoch=1.05............. Loss: 0.14246940, mean(E): -19.25925639-0.00062920j, var(E): 0.03063322
-0.0
tensor(18.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19720/ 20000/ t/epoch=1.05............. Loss: -0.04005249, mean(E): -19.23584386+0.00840635j, var(E): 0.03622045
-0.0
tensor(18.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19730/ 20000/ t/epoch=1.05............. Loss: -0.07079519, mean(E): -19.23825589+0.00248271j, var(E): 0.04285424
-0.0
tensor(18.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19740/ 20000/ t/epoch=1.04............. Loss: 0.03066857, mean(E): -19.22623319-0.00065732j, var(E): 0.01672085
-0.0
tensor(18.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19750/ 20000/ t/epoch=1.05............. Loss: 0.20440729, mean(E): -19.22273558+0.00481952j, var(E): 0.01718528
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19760/ 20000/ t/epoch=1.05............. Loss: 0.09480013, mean(E): -19.21510702-0.00531577j, var(E): 0.03224306
-0.0
tensor(18.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19770/ 20000/ t/epoch=1.06............. Loss: 0.14724742, mean(E): -19.25136269+0.00386205j, var(E): 0.04959181
-0.0
tensor(18.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19780/ 20000/ t/epoch=1.06............. Loss: 0.12387593, mean(E): -19.23824187+0.00223264j, var(E): 0.03205969
-0.0
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19790/ 20000/ t/epoch=1.05............. Loss: -0.00354021, mean(E): -19.20356715+0.00103222j, var(E): 0.02858058
-0.0
tensor(18.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19800/ 20000/ t/epoch=1.06............. Loss: 0.04933109, mean(E): -19.22130938+0.00182022j, var(E): 0.02054969
-0.0
tensor(18.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19810/ 20000/ t/epoch=1.05............. Loss: 0.29234408, mean(E): -19.23871781+0.00241526j, var(E): 0.06813611
-0.0
tensor(18.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19820/ 20000/ t/epoch=1.05............. Loss: 0.19233505, mean(E): -19.22501438-0.00707194j, var(E): 0.03079142
-0.0
tensor(18.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19830/ 20000/ t/epoch=1.06............. Loss: -0.02160968, mean(E): -19.22343826-0.00166452j, var(E): 0.02585063
-0.0
tensor(18.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19840/ 20000/ t/epoch=1.05............. Loss: -0.11013354, mean(E): -19.22788509+0.00466554j, var(E): 0.04175401
-0.0
tensor(18.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19850/ 20000/ t/epoch=1.05............. Loss: 0.02594370, mean(E): -19.22259389+0.00078020j, var(E): 0.01836053
-0.0
tensor(18.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19860/ 20000/ t/epoch=1.04............. Loss: -0.09304486, mean(E): -19.26069192+0.00538358j, var(E): 0.04350084
-0.0
tensor(18.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19870/ 20000/ t/epoch=1.05............. Loss: -0.08271491, mean(E): -19.21928887+0.00115267j, var(E): 0.01386804
-0.0
tensor(18.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19880/ 20000/ t/epoch=1.06............. Loss: -0.09775254, mean(E): -19.21939793+0.00270121j, var(E): 0.03432073
-0.0
tensor(18.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19890/ 20000/ t/epoch=1.04............. Loss: 0.02679521, mean(E): -19.21851419+0.00418701j, var(E): 0.01850995
-0.0
tensor(18.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19900/ 20000/ t/epoch=1.05............. Loss: 0.21539987, mean(E): -19.23033614+0.00559416j, var(E): 0.03836325
-0.0
tensor(18.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19910/ 20000/ t/epoch=1.05............. Loss: -0.07663538, mean(E): -19.22483218-0.00556049j, var(E): 0.03197157
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19920/ 20000/ t/epoch=1.05............. Loss: 0.05814744, mean(E): -19.22226074+0.00251547j, var(E): 0.02784829
-0.0
tensor(18.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19930/ 20000/ t/epoch=1.05............. Loss: -0.06210808, mean(E): -19.21515313+0.00525355j, var(E): 0.03511824
-0.0
tensor(18.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19940/ 20000/ t/epoch=1.06............. Loss: -0.01850025, mean(E): -19.21646848+0.00188872j, var(E): 0.03000575
-0.0
tensor(18.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19950/ 20000/ t/epoch=1.05............. Loss: -0.16183173, mean(E): -19.20162832+0.00607272j, var(E): 0.03811203
-0.0
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19960/ 20000/ t/epoch=1.05............. Loss: -0.02041595, mean(E): -19.20413728-0.00561297j, var(E): 0.02123929
-0.0
tensor(18.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19970/ 20000/ t/epoch=1.05............. Loss: 0.21788538, mean(E): -19.23364826-0.00909363j, var(E): 0.03143364
-0.0
tensor(18.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19980/ 20000/ t/epoch=1.04............. Loss: 0.14208312, mean(E): -19.22772528+0.00034721j, var(E): 0.03086527
-0.0
tensor(18.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19990/ 20000/ t/epoch=1.05............. Loss: 0.26471558, mean(E): -19.23382340+0.00743202j, var(E): 0.02528253
-0.0
tensor(18.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20000/ 20000/ t/epoch=1.05............. Loss: -0.00913549, mean(E): -19.21947150+0.00194952j, var(E): 0.01987451
